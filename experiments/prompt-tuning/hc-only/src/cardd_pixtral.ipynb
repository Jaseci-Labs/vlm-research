{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5405616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
      "Standard import failed for UnslothDDPOTrainer: No module named 'UnslothDDPOTrainer'. Using tempfile instead!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from unsloth import FastVisionModel\n",
    "from transformers import AutoProcessor, TextStreamer\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9080f8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image_caption_dataset(\n",
    "    image_folder: str,\n",
    "    captions_json: str,\n",
    "    caption_strategy: str = 'first'\n",
    ") -> pd.DataFrame:\n",
    "    with open(captions_json, 'r') as f:\n",
    "        captions_data = json.load(f)\n",
    "\n",
    "    data = []\n",
    "    for filename, caption_list in captions_data.items():\n",
    "        image_path = os.path.join(image_folder, filename)\n",
    "        if not os.path.exists(image_path):\n",
    "            continue\n",
    "        try:\n",
    "            image = Image.open(image_path).convert(\"RGB\")\n",
    "            caption = caption_list if caption_strategy == 'first' else random.choice(caption_list)\n",
    "            data.append({\"image\": image, \"caption\": caption, \"filename\": filename})\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Could not load {filename}: {e}\")\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bab70e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.4.7: Fast Llava patching. Transformers: 4.51.3.\n",
      "   \\\\   /|    NVIDIA A40. Num GPUs = 1. Max memory: 44.448 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 8.6. CUDA Toolkit: 12.6. Triton: 3.3.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "Unsloth: Llava does not support SDPA - switching to eager!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9606f900358842968957171630b1f9a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/214k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a302c4278304789a5742b9d2dcdccd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b74b69a9ed2b4f3dbfbea089119bff00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/4.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84de00dfcee44693836e63525fe9a2ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02640ec7e25d411db274f7c887634c63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/133 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "296459772a144ff0a8aaef7c6aa78d74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "processor_config.json:   0%|          | 0.00/162 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "763796259188491993ee164e9590694c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.json:   0%|          | 0.00/1.59k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fd850b795244129a4ec519ff8178515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb21727474554dd0916f5fa5dce80033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/177k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ec966bde933430da4657229f2a86be3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bfa2b0412cf4619b9fd1bc55862c239",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/552 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "449fbaaf558b4cfa918caeb76180dc65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "processor_config.json:   0%|          | 0.00/162 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38aca52b693643e7ad43284e181b5170",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.json:   0%|          | 0.00/1.59k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fe6298b93b4411c9b764e37806763ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d1ab81637a041a28f0156357dbe1bab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/177k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2e6b8f5de904888aa1f67d52fcce7ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d26db27ec154a95895fbe8a0aac3913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/552 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"unsloth/Pixtral-12B-2409\"  # change if needed\n",
    "\n",
    "model, tokenizer = FastVisionModel.from_pretrained(\n",
    "    model_id,\n",
    "    load_in_4bit=True,  # Use 4bit to reduce memory use. False for 16bit LoRA.\n",
    "    use_gradient_checkpointing=\"unsloth\",  # True or \"unsloth\" for long context\n",
    ")\n",
    "\n",
    "model = FastVisionModel.for_inference(model)\n",
    "processor = AutoProcessor.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71501eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 50 image-caption pairs\n"
     ]
    }
   ],
   "source": [
    "image_folder = \"/workspace/data/test_dataset\"\n",
    "captions_json = \"/workspace/data/test_set.json\"\n",
    "\n",
    "df = create_image_caption_dataset(image_folder, captions_json)\n",
    "print(f\"Loaded {len(df)} image-caption pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99d52628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 First 5 entries:\n",
      "                                               image  \\\n",
      "0  <PIL.Image.Image image mode=RGB size=1000x667 ...   \n",
      "1  <PIL.Image.Image image mode=RGB size=1000x667 ...   \n",
      "2  <PIL.Image.Image image mode=RGB size=1000x667 ...   \n",
      "3  <PIL.Image.Image image mode=RGB size=1000x750 ...   \n",
      "4  <PIL.Image.Image image mode=RGB size=1000x667 ...   \n",
      "\n",
      "                                             caption    filename  \n",
      "0  The car exhibits visible damage including a sc...  000481.jpg  \n",
      "1  The car exhibits significant damage to the win...  000433.jpg  \n",
      "2  The car exhibits a flat tire on the rear wheel...  000749.jpg  \n",
      "3  The car exhibits significant damage. The rear ...  000541.jpg  \n",
      "4  The car shows scratches along the side panel a...  000424.jpg   \n",
      "\n",
      "📋 Column types:\n",
      "image       object\n",
      "caption     object\n",
      "filename    object\n",
      "dtype: object\n",
      "\n",
      "🔎 Size\n",
      "(50, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"📌 First 5 entries:\")\n",
    "print(df.head(), \"\\n\")\n",
    "\n",
    "print(\"📋 Column types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\n🔎 Size\")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6fabf79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "from transformers import TextStreamer\n",
    "import pandas as pd\n",
    "\n",
    "streamer = TextStreamer(tokenizer, skip_prompt=True)\n",
    "\n",
    "def run_vlm_inference(prompt: str, filename: str, df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Perform inference on a given image (by filename) from the dataframe using a custom prompt.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The prompt text (can include mask tokens)\n",
    "        filename (str): Filename of the image in the DataFrame\n",
    "        df (pd.DataFrame): DataFrame with 'filename' and 'image' columns\n",
    "\n",
    "    Returns:\n",
    "        Tuple[str, float, float]: (Generated output, inference time in seconds, VRAM used in GB)\n",
    "    \"\"\"\n",
    "    row = df[df[\"filename\"] == filename]\n",
    "    if row.empty:\n",
    "        print(f\"[ERROR] No image found with filename: {filename}\")\n",
    "        return None, 0.0, 0.0\n",
    "\n",
    "    row = row.iloc[0]\n",
    "    image = row[\"image\"]\n",
    "    caption = row[\"caption\"]\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompt},\n",
    "                {\"type\": \"image\", \"image\": image}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    input_text = tokenizer.apply_chat_template(messages, add_generation_prompt=True)\n",
    "    inputs = processor(images=image, text=input_text, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    start_mem = torch.cuda.memory_allocated() / 1024**3  # in GB\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(f\"🔹 Image: {filename}\")\n",
    "    print(f\"🧾 Prompt: {prompt}\")\n",
    "    print(\"📤 Output:\")\n",
    "\n",
    "    inputs.pop(\"token_type_ids\", None)\n",
    "\n",
    "    output_ids = model.generate(\n",
    "        **inputs,\n",
    "        streamer=streamer,\n",
    "        max_new_tokens=64,\n",
    "        use_cache=True,\n",
    "        temperature=1.5,\n",
    "        min_p=0.1,\n",
    "    )\n",
    "\n",
    "    end_time = time.time()\n",
    "    end_mem = torch.cuda.max_memory_allocated() / 1024**3\n",
    "\n",
    "    time_taken = round(end_time - start_time, 3)\n",
    "    vram_used = round(end_mem - start_mem, 3)\n",
    "    decoded_output = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    print(f\"⏱️ Time taken: {time_taken} sec | 🧠 VRAM used: {vram_used} GB\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    return decoded_output, time_taken, vram_used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b21278-7d01-4918-be1a-2c1951787df2",
   "metadata": {},
   "source": [
    "### Test Images\n",
    "\n",
    "000404.jpg\n",
    "000422.jpg\n",
    "000433.jpg\n",
    "000481.jpg\n",
    "000520.jpg\n",
    "000541.jpg\n",
    "000698.jpg\n",
    "000740.jpg\n",
    "000869.jpg\n",
    "000889.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "21a6f630-0b10-49de-9b34-e2da40a4bff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Image: 000889.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The imageDYjure to the=Gor later. efekt?]\n",
      "image 1, a Uy of a close to the in schn: a li> p] to open the of the a the xtra  is a the  bef  to been the  s strongNXDoloud\n",
      "⏱️ Time taken: 4.277 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔹 Image: 000889.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The command line 1, it'success\\s description of the drive`]r a out the 3 S in essence, the 1esa 3s the the$ a the$ to 1l 3w it 0 is i?</s>\n",
      "⏱️ Time taken: 3.731 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔹 Image: 000889.jpg\n",
      "🧾 Prompt: An image of ....\n",
      "📤 Output:\n",
      "The impact glass cracking joke, a car  with a few leaded\n",
      "\n",
      " ekst-12.0</s>\n",
      "⏱️ Time taken: 1.92 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔹 Image: 000889.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "As an insurance claims adj. (Image by-vehicle under, insurance adjusters, ins izeled, aaccom/for theiPhone: Kindle ith (an the the the inus F ith a the in of UDOT find:</s>\n",
      "⏱️ Time taken: 3.709 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔹 Image: 000889.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "This is a_12 1. efektif(typeof=1: \"n,type: xtapost: bool valuse for a1and, 1ength_ and ize: on: ize is } &tatus: re ize_ x2 a: ize is the:\n",
      "⏱️ Time taken: 4.245 sec | 🧠 VRAM used: 0.607 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔹 Image: 000889.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "-# whenever i oranges, Car Glass Repair status\n",
      "\n",
      " ekst- Impala Dint- oranges- oranges- ingilizes- ing- ing- ing-2[edit- ing- ing- anga- ing- oranges- edit- oranges- edit- ing- edit- ing-\n",
      "⏱️ Time taken: 4.278 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "filename=\"000889.jpg\"\n",
    "\n",
    "row = df[df[\"filename\"] == filename]\n",
    "ground_truth = row.iloc[0][\"caption\"]\n",
    "\n",
    "inference_outputs = []\n",
    "vram_usages = []\n",
    "inference_times = []\n",
    "\n",
    "prompts = [\n",
    "    \"\",  # Prompt 1: No Prompt\n",
    "    \"Describe &&damage 12 sedan drive’ this !!image.\",  # Noisy\n",
    "    \"An image of ....\",  # Hand-crafted\n",
    "    \"You are an insurance claims assessor. Provide a detailed description of the car’s condition.\",  # Roleplay\n",
    "    \"This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\",  # Masked\n",
    "    \"Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\"  # Format-Guided\n",
    "]\n",
    "\n",
    "for prompt in prompts:\n",
    "    output, time_taken, vram = run_vlm_inference(prompt, filename, df=df)\n",
    "    inference_outputs.append(output)\n",
    "    vram_usages.append(vram)\n",
    "    inference_times.append(time_taken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d38bf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "from pycocoevalcap.cider.cider import Cider\n",
    "from pycocoevalcap.spice.spice import Spice\n",
    "from pycocoevalcap.tokenizer.ptbtokenizer import PTBTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1974cc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cosine_similarity(reference_captions, generated_caption):\n",
    "    try:\n",
    "        total_score = 0.0\n",
    "        for caption in reference_captions:\n",
    "            ref_embed = sbert_model.encode(caption, convert_to_tensor=True)\n",
    "            gen_embed = sbert_model.encode(generated_caption, convert_to_tensor=True)\n",
    "            score = util.cos_sim(gen_embed, ref_embed).item()\n",
    "            total_score += score\n",
    "        avg_score = total_score / len(reference_captions) if reference_captions else 0.0\n",
    "        return avg_score\n",
    "    except Exception as e:\n",
    "        print(f\"Error computing cosine similarity: {e}\")\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f9b8529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cider_spice_scores(reference_caption, generated_caption):\n",
    "    refs = {0: [reference_caption if reference_caption else \"\"]}\n",
    "    hypos = {0: [generated_caption if generated_caption else \"\"]}\n",
    "\n",
    "    # print(f\"Generated caption: {generated_caption}\")\n",
    "    # print(f\"Generated hypos: {hypos}\")\n",
    "\n",
    "    ptb = PTBTokenizer()\n",
    "    refs_tok = ptb.tokenize({i: [{\"caption\": c} for c in caps] for i, caps in refs.items()})\n",
    "    hypos_tok = ptb.tokenize({i: [{\"caption\": hypos[i][0]}] for i in hypos})\n",
    "\n",
    "    all_scores = {}\n",
    "\n",
    "    for scorer, name in [(Cider(), \"CIDEr\"), (Spice(), \"SPICE\")]:\n",
    "        try:\n",
    "            avg_score, _ = scorer.compute_score(refs_tok, hypos_tok)\n",
    "            if name == \"SPICE\":\n",
    "                # SPICE returns dicts per image\n",
    "                all_scores[name] = avg_score.get(\"All\", {}).get(\"f\", 0.0) if isinstance(avg_score, dict) else avg_score\n",
    "            else:\n",
    "                all_scores[name] = avg_score\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] {name} scoring failed: {e}\")\n",
    "            all_scores[name] = 0.0\n",
    "\n",
    "    return all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57f4d517-34af-4a79-bb29-25613a22c9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cider import Cider\n",
    "\n",
    "PICKLE_PATH = \"/workspace/data/cardd-df.p\"\n",
    "\n",
    "def compute_cider2_score(reference_caption, generated_caption):\n",
    "    \"\"\"\n",
    "    Computes CIDEr score using new evaluate_cider logic with precomputed DF pickle.\n",
    "\n",
    "    Args:\n",
    "        reference_caption (str or list): Ground truth caption(s)\n",
    "        generated_caption (str): Model output\n",
    "\n",
    "    Returns:\n",
    "        float: CIDEr score (averaged if multiple refs)\n",
    "    \"\"\"\n",
    "    refs = {\"0\": reference_caption if isinstance(reference_caption, list) else [reference_caption]}\n",
    "    hypos = [{\"image_id\": \"0\", \"caption\": [generated_caption]}]  # Fix: caption should be a list\n",
    "\n",
    "    cider = Cider()\n",
    "    score, _ = cider.compute_score(refs, hypos, PICKLE_PATH)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "035e2bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_all_metrics(reference_caption, generated_caption):\n",
    "    cider_spice_scores = compute_cider_spice_scores(reference_caption, generated_caption)\n",
    "    cosine_sim = compute_cosine_similarity([reference_caption], generated_caption)\n",
    "    cider2 = compute_cider2_score(reference_caption, generated_caption)\n",
    "\n",
    "    return {\n",
    "        \"cosine_similarity\": round(cosine_sim, 4),\n",
    "        #\"CIDEr\": round(cider_spice_scores.get(\"CIDEr\", 0.0), 4),\n",
    "        \"SPICE\": round(cider_spice_scores.get(\"SPICE\", 0.0), 4),\n",
    "        \"CIDEr\": round(cider2, 4)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "36332c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The car exhibits significant damage to the driver's side window, which is shattered extensively. The glass is fragmented and broken, with large pieces missing, indicating a severe impact. \n",
      "['The imageDYjure to the=Gor later. efekt?]\\nimage 1, a Uy of a close to the in schn: a li> p] to open the of the a the xtra  is a the  bef  to been the  s strongNXDoloud', \"Describe &&damage 12 sedan drive’ this !!image.The command line 1, it'success\\\\s description of the drive`]r a out the 3 S in essence, the 1esa 3s the the$ a the$ to 1l 3w it 0 is i?\", 'An image of ....The impact glass cracking joke, a car  with a few leaded\\n\\n ekst-12.0', 'You are an insurance claims assessor. Provide a detailed description of the car’s condition.As an insurance claims adj. (Image by-vehicle under, insurance adjusters, ins izeled, aaccom/for theiPhone: Kindle ith (an the the the inus F ith a the in of UDOT find:', 'This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.This is a_12 1. efektif(typeof=1: \"n,type: xtapost: bool valuse for a1and, 1ength_ and ize: on: ize is } &tatus: re ize_ x2 a: ize is the:', 'Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___-# whenever i oranges, Car Glass Repair status\\n\\n ekst- Impala Dint- oranges- oranges- ingilizes- ing- ing- ing-2[edit- ing- ing- anga- ing- oranges- edit- oranges- edit- ing- edit- ing-']\n",
      "[0.601, 0.601, 0.601, 0.604, 0.607, 0.604]\n",
      "[4.277, 3.731, 1.92, 3.709, 4.245, 4.278]\n"
     ]
    }
   ],
   "source": [
    "print(ground_truth)\n",
    "print(inference_outputs)\n",
    "print(vram_usages)\n",
    "print(inference_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e8b2100b-1268-4fe2-816a-c46a3ed0cbb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 1 Output:\n",
      "The imageDYjure to the=Gor later. efekt?]\n",
      "image 1, a Uy of a close to the in schn: a li> p] to open the of the a the xtra  is a the  bef  to been the  s strongNXDoloud\n",
      "Reference:\n",
      "The car exhibits significant damage to the driver's side window, which is shattered extensively. The glass is fragmented and broken, with large pieces missing, indicating a severe impact. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 34 tokens at 1079.48 tokens per second.\n",
      "PTBTokenizer tokenized 46 tokens at 1439.35 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 588.5 ms\n",
      "\n",
      "Prompt 2 Output:\n",
      "Describe &&damage 12 sedan drive’ this !!image.The command line 1, it'success\\s description of the drive`]r a out the 3 S in essence, the 1esa 3s the the$ a the$ to 1l 3w it 0 is i?\n",
      "Reference:\n",
      "The car exhibits significant damage to the driver's side window, which is shattered extensively. The glass is fragmented and broken, with large pieces missing, indicating a severe impact. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 34 tokens at 962.05 tokens per second.\n",
      "PTBTokenizer tokenized 52 tokens at 1578.53 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 609.6 ms\n",
      "\n",
      "Prompt 3 Output:\n",
      "An image of ....The impact glass cracking joke, a car  with a few leaded\n",
      "\n",
      " ekst-12.0\n",
      "Reference:\n",
      "The car exhibits significant damage to the driver's side window, which is shattered extensively. The glass is fragmented and broken, with large pieces missing, indicating a severe impact. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 34 tokens at 1030.50 tokens per second.\n",
      "PTBTokenizer tokenized 18 tokens at 551.27 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 617.7 ms\n",
      "\n",
      "Prompt 4 Output:\n",
      "You are an insurance claims assessor. Provide a detailed description of the car’s condition.As an insurance claims adj. (Image by-vehicle under, insurance adjusters, ins izeled, aaccom/for theiPhone: Kindle ith (an the the the inus F ith a the in of UDOT find:\n",
      "Reference:\n",
      "The car exhibits significant damage to the driver's side window, which is shattered extensively. The glass is fragmented and broken, with large pieces missing, indicating a severe impact. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 34 tokens at 1054.24 tokens per second.\n",
      "PTBTokenizer tokenized 51 tokens at 1620.47 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 618.0 ms\n",
      "\n",
      "Prompt 5 Output:\n",
      "This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.This is a_12 1. efektif(typeof=1: \"n,type: xtapost: bool valuse for a1and, 1ength_ and ize: on: ize is } &tatus: re ize_ x2 a: ize is the:\n",
      "Reference:\n",
      "The car exhibits significant damage to the driver's side window, which is shattered extensively. The glass is fragmented and broken, with large pieces missing, indicating a severe impact. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 34 tokens at 1080.67 tokens per second.\n",
      "PTBTokenizer tokenized 66 tokens at 2069.24 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 611.3 ms\n",
      "\n",
      "Prompt 6 Output:\n",
      "Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___-# whenever i oranges, Car Glass Repair status\n",
      "\n",
      " ekst- Impala Dint- oranges- oranges- ingilizes- ing- ing- ing-2[edit- ing- ing- anga- ing- oranges- edit- oranges- edit- ing- edit- ing-\n",
      "Reference:\n",
      "The car exhibits significant damage to the driver's side window, which is shattered extensively. The glass is fragmented and broken, with large pieces missing, indicating a severe impact. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 34 tokens at 1028.07 tokens per second.\n",
      "PTBTokenizer tokenized 72 tokens at 2276.34 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 600.1 ms\n"
     ]
    }
   ],
   "source": [
    "all_scores = []\n",
    "\n",
    "for i, gen in enumerate(inference_outputs):\n",
    "    print(f\"\\nPrompt {i+1} Output:\\n{gen}\\nReference:\\n{ground_truth}\")\n",
    "    scores = evaluate_all_metrics(ground_truth, gen)\n",
    "    all_scores.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "093e00a7-2a5b-4ee1-ba53-4f463205070f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cosine_similarity</th>\n",
       "      <th>SPICE</th>\n",
       "      <th>CIDEr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Prompt 1</th>\n",
       "      <td>0.1576</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3.3421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prompt 2</th>\n",
       "      <td>0.3584</td>\n",
       "      <td>0.0606</td>\n",
       "      <td>2.2063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prompt 3</th>\n",
       "      <td>0.5442</td>\n",
       "      <td>0.1538</td>\n",
       "      <td>2.1437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prompt 4</th>\n",
       "      <td>0.2248</td>\n",
       "      <td>0.0435</td>\n",
       "      <td>1.4011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prompt 5</th>\n",
       "      <td>0.4149</td>\n",
       "      <td>0.0408</td>\n",
       "      <td>3.0305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prompt 6</th>\n",
       "      <td>0.4410</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          cosine_similarity   SPICE   CIDEr\n",
       "Prompt 1             0.1576  0.0000  3.3421\n",
       "Prompt 2             0.3584  0.0606  2.2063\n",
       "Prompt 3             0.5442  0.1538  2.1437\n",
       "Prompt 4             0.2248  0.0435  1.4011\n",
       "Prompt 5             0.4149  0.0408  3.0305\n",
       "Prompt 6             0.4410  0.0000  0.0000"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df = pd.DataFrame(all_scores, index=[f\"Prompt {i+1}\" for i in range(len(inference_outputs))])\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c88d3c1d-92d1-41d0-9b3d-f1e9c36cea7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openpyxl import Workbook, load_workbook\n",
    "from openpyxl.drawing.image import Image as ExcelImage\n",
    "from openpyxl.styles import Alignment\n",
    "from PIL import Image as PILImage\n",
    "import os\n",
    "\n",
    "def log_prompt_metrics_to_excel(\n",
    "    filename: str,\n",
    "    model_name: str,\n",
    "    inference_outputs: list,\n",
    "    metrics: list,\n",
    "    inference_times: list,\n",
    "    vram_usages: list,\n",
    "    df: pd.DataFrame,\n",
    "    output_excel_path: str = \"prompt_tuning_results_cardd_pixtral.xlsx\"\n",
    "):\n",
    "    row = df[df[\"filename\"] == filename].iloc[0]\n",
    "    original_caption = row[\"caption\"]\n",
    "    image_path = os.path.join(\"/workspace/data/test_dataset\", filename)\n",
    "\n",
    "    # Load or create workbook\n",
    "    if os.path.exists(output_excel_path):\n",
    "        wb = load_workbook(output_excel_path)\n",
    "        ws = wb.active\n",
    "    else:\n",
    "        wb = Workbook()\n",
    "        ws = wb.active\n",
    "        ws.title = \"Prompt Evaluation\"\n",
    "        headers = [\n",
    "            \"Model\", \"Image Number\", \"Image\", \"Original Caption\",\n",
    "            \"Prompt\", \"Output\", \"Inference Time (s)\", \"VRAM Used (GB)\",\n",
    "            \"CIDEr\", \"SPICE\", \"Cosine Similarity\"\n",
    "        ]\n",
    "        ws.append(headers)\n",
    "\n",
    "    # Find the next empty row\n",
    "    start_row = ws.max_row + 1\n",
    "\n",
    "    # Append data\n",
    "    for i in range(6):\n",
    "        ws.append([\n",
    "            model_name,\n",
    "            filename,\n",
    "            \"\",  # placeholder for image\n",
    "            original_caption,\n",
    "            f\"Prompt {i+1}\",\n",
    "            inference_outputs[i],\n",
    "            inference_times[i],\n",
    "            vram_usages[i],\n",
    "            metrics[i][\"CIDEr\"],\n",
    "            metrics[i][\"SPICE\"],\n",
    "            metrics[i][\"cosine_similarity\"]\n",
    "        ])\n",
    "\n",
    "    # Merge A–D columns across the 6 rows\n",
    "    for col in [\"A\", \"B\", \"C\", \"D\"]:\n",
    "        ws.merge_cells(f\"{col}{start_row}:{col}{start_row + 5}\")\n",
    "\n",
    "    # Apply alignment\n",
    "    align_top_wrap = Alignment(wrap_text=True, vertical=\"top\")\n",
    "    align_top = Alignment(vertical=\"top\")\n",
    "\n",
    "    for row in range(start_row, start_row + 6):\n",
    "        for col_letter in [\"A\", \"B\", \"C\", \"E\"]:\n",
    "            ws[f\"{col_letter}{row}\"].alignment = align_top\n",
    "        for col_letter in [\"D\", \"F\"]:\n",
    "            ws[f\"{col_letter}{row}\"].alignment = align_top_wrap\n",
    "        ws.row_dimensions[row].height = 120\n",
    "\n",
    "    # Set column widths\n",
    "    ws.column_dimensions[\"D\"].width = 40  # Original Caption\n",
    "    ws.column_dimensions[\"F\"].width = 40  # Output\n",
    "\n",
    "    # Embed image\n",
    "    if os.path.exists(image_path):\n",
    "        print(f\"[INFO] Inserting image: {image_path}\")\n",
    "        try:\n",
    "            img = ExcelImage(image_path)\n",
    "            img.width = 150\n",
    "            img.height = 150\n",
    "            img.anchor = f\"C{start_row}\"\n",
    "            ws.add_image(img)\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Could not insert image: {e}\")\n",
    "\n",
    "    wb.save(output_excel_path)\n",
    "    print(f\"✅ Logged metrics for {filename} to {output_excel_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "dd7d5bfd-a9fc-4e36-89d6-238542869d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Inserting image: /workspace/data/test_dataset/000889.jpg\n",
      "✅ Logged metrics for 000889.jpg to prompt_tuning_results_cardd_pixtral.xlsx\n"
     ]
    }
   ],
   "source": [
    "log_prompt_metrics_to_excel(\n",
    "    filename=filename,\n",
    "    model_name=model_id,\n",
    "    inference_outputs=inference_outputs,\n",
    "    metrics=all_scores,\n",
    "    inference_times=inference_times,\n",
    "    vram_usages=vram_usages,\n",
    "    df=df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd783220-02a4-4fd8-a655-bb5ef7e7fb91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
