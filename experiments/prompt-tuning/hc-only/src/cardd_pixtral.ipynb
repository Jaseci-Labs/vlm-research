{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e5405616",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from unsloth import FastLanguageModel\n",
    "from transformers import AutoProcessor, TextStreamer\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9d39b1f2-179f-4fcd-b60e-dda5a1a6ca1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250515_174446-6533z672</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vlm-research/Prompting-Experiments/runs/6533z672' target=\"_blank\">Prompt-Eval-Pixtral12B-CarDD</a></strong> to <a href='https://wandb.ai/vlm-research/Prompting-Experiments' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vlm-research/Prompting-Experiments' target=\"_blank\">https://wandb.ai/vlm-research/Prompting-Experiments</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vlm-research/Prompting-Experiments/runs/6533z672' target=\"_blank\">https://wandb.ai/vlm-research/Prompting-Experiments/runs/6533z672</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/vlm-research/Prompting-Experiments/runs/6533z672?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x751667b80940>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init(\n",
    "    project=\"Prompting-Experiments\",\n",
    "    name=\"Prompt-Eval-Pixtral12B-CarDD\",\n",
    "    group=\"prompting-experiments\",\n",
    "    tags=[\"pixtral\", \"image-captioning\", \"prompting\", \"cardamage\"],\n",
    "    notes=\"Comparing handcrafted prompting strategies across multiple images and prompt types.\",\n",
    "    config={\n",
    "        \"model\": \"Pixtral-12B\",\n",
    "        \"prompting\": \"handcrafted\",\n",
    "        \"num_prompts\": 6,\n",
    "        \"num_runs_per_prompt\": 2,\n",
    "        \"dataset\": \"cardd\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9080f8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image_caption_dataset(\n",
    "    image_folder: str,\n",
    "    captions_json: str,\n",
    "    caption_strategy: str = 'first'\n",
    ") -> pd.DataFrame:\n",
    "    with open(captions_json, 'r') as f:\n",
    "        captions_data = json.load(f)\n",
    "\n",
    "    data = []\n",
    "    for filename, caption_list in captions_data.items():\n",
    "        image_path = os.path.join(image_folder, filename)\n",
    "        if not os.path.exists(image_path):\n",
    "            continue\n",
    "        try:\n",
    "            image = Image.open(image_path).convert(\"RGB\")\n",
    "            caption = caption_list if caption_strategy == 'first' else random.choice(caption_list)\n",
    "            data.append({\"image\": image, \"caption\": caption, \"filename\": filename})\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Could not load {filename}: {e}\")\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2bab70e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.5.3: Fast Mistral patching. Transformers: 4.51.3.\n",
      "   \\\\   /|    NVIDIA A40. Num GPUs = 1. Max memory: 44.448 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 8.6. CUDA Toolkit: 12.6. Triton: 3.3.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "Unsloth: Mistral does not support SDPA - switching to eager!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14bbe02878824479bc5b76797baedf93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"unsloth/Pixtral-12B-2409\"\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = model_id,\n",
    "    load_in_4bit = True, # Use 4bit to reduce memory use. False for 16bit LoRA.\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for long context\n",
    ")\n",
    "\n",
    "model = FastLanguageModel.for_inference(model)\n",
    "processor = AutoProcessor.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "71501eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 50 image-caption pairs\n"
     ]
    }
   ],
   "source": [
    "image_folder = \"/workspace/data/test_dataset\"\n",
    "captions_json = \"/workspace/data/test_set.json\"\n",
    "\n",
    "df = create_image_caption_dataset(image_folder, captions_json)\n",
    "print(f\"Loaded {len(df)} image-caption pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "99d52628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 First 5 entries:\n",
      "                                               image  \\\n",
      "0  <PIL.Image.Image image mode=RGB size=1000x667 ...   \n",
      "1  <PIL.Image.Image image mode=RGB size=1000x667 ...   \n",
      "2  <PIL.Image.Image image mode=RGB size=1000x667 ...   \n",
      "3  <PIL.Image.Image image mode=RGB size=1000x750 ...   \n",
      "4  <PIL.Image.Image image mode=RGB size=1000x667 ...   \n",
      "\n",
      "                                             caption    filename  \n",
      "0  The car exhibits visible damage including a sc...  000481.jpg  \n",
      "1  The car exhibits significant damage to the win...  000433.jpg  \n",
      "2  The car exhibits a flat tire on the rear wheel...  000749.jpg  \n",
      "3  The car exhibits significant damage. The rear ...  000541.jpg  \n",
      "4  The car shows scratches along the side panel a...  000424.jpg   \n",
      "\n",
      "📋 Column types:\n",
      "image       object\n",
      "caption     object\n",
      "filename    object\n",
      "dtype: object\n",
      "\n",
      "🔎 Size\n",
      "(50, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"📌 First 5 entries:\")\n",
    "print(df.head(), \"\\n\")\n",
    "\n",
    "print(\"📋 Column types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\n🔎 Size\")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6fabf79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "from transformers import TextStreamer\n",
    "import pandas as pd\n",
    "\n",
    "streamer = TextStreamer(tokenizer, skip_prompt=True)\n",
    "\n",
    "def run_vlm_inference(prompt: str, filename: str, df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Perform inference on a given image (by filename) from the dataframe using a custom prompt.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The prompt text (can include mask tokens)\n",
    "        filename (str): Filename of the image in the DataFrame\n",
    "        df (pd.DataFrame): DataFrame with 'filename' and 'image' columns\n",
    "\n",
    "    Returns:\n",
    "        Tuple[str, float, float]: (Generated output, inference time in seconds, VRAM used in GB)\n",
    "    \"\"\"\n",
    "    row = df[df[\"filename\"] == filename]\n",
    "    if row.empty:\n",
    "        print(f\"[ERROR] No image found with filename: {filename}\")\n",
    "        return None, 0.0, 0.0\n",
    "\n",
    "    row = row.iloc[0]\n",
    "    image = row[\"image\"]\n",
    "    caption = row[\"caption\"]\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompt},\n",
    "                {\"type\": \"image\", \"image\": image}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    input_text = tokenizer.apply_chat_template(messages, add_generation_prompt=True)\n",
    "    inputs = processor(images=image, text=input_text, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    start_mem = torch.cuda.memory_allocated() / 1024 / 1024 / 1024  # in GB\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(f\"🔹 Image: {filename}\")\n",
    "    print(f\"🧾 Prompt: {prompt}\")\n",
    "    print(\"📤 Output:\")\n",
    "    \n",
    "    # Perform inference\n",
    "    output_ids = model.generate(\n",
    "        **inputs,\n",
    "        streamer=streamer,\n",
    "        max_new_tokens=128,\n",
    "        use_cache=True,\n",
    "        temperature=1.5,\n",
    "        min_p=0.1,\n",
    "    )\n",
    "\n",
    "    end_time = time.time()\n",
    "    end_mem = torch.cuda.max_memory_allocated() / 1024**3\n",
    "\n",
    "    time_taken = round(end_time - start_time, 3)\n",
    "    vram_used = round(end_mem - start_mem, 3)\n",
    "    decoded_output = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    print(f\"⏱️ Time taken: {time_taken} sec | 🧠 VRAM used: {vram_used} GB\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    return decoded_output, time_taken, vram_used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "21a6f630-0b10-49de-9b34-e2da40a4bff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Running prompts for image: 000404.jpg\n",
      "------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: \n",
      "🔹 Image: 000404.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The hood of the hood ornamelizabethada{,} 1\n",
      "\n",
      " ekst-–––whatever your browser or the chooser: the in unreal-est and `1lea ithisize myf5. of tI [on;).\n",
      "ose inth of theinns. Def    I- the the the the the the a ized14.</s>\n",
      "⏱️ Time taken: 5.507 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: \n",
      "🔹 Image: 000404.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The hood of the hood ornamelizabethada{,} 1\n",
      "\n",
      " ekst-–––whatever your browser or the chooser: the in unreal-est and `1lea ithisize myf5. of tI [on;).\n",
      "ose inth of theinns. Def    I- the the the the the the a ized14.</s>\n",
      "⏱️ Time taken: 5.886 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "🔹 Image: 000404.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The car crash investigation as `'n s-argentinautilitiesseparated by intervening variable alexible. intervening vehicleceaonline-A only, worldwideize me toan 23. `u000emes to beenan 39Dadministration in7.</s>\n",
      "⏱️ Time taken: 4.064 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "🔹 Image: 000404.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The car crash investigation as `'n s-argentinautilitiesseparated by intervening variable alexible. intervening vehicleceaonline-A only, worldwideize me toan 23. `u000emes to beenan 39Dadministration in7.</s>\n",
      "⏱️ Time taken: 3.916 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: An image of a damaged car parked on the side of th...\n",
      "🔹 Image: 000404.jpg\n",
      "🧾 Prompt: An image of a damaged car parked on the side of the road.\n",
      "📤 Output:\n",
      "The car orv82120 in ublic Ar10 ingle International shippinginf one ear new windshield might seamlessly, &outhis canadaogg c & he\n",
      "ese are aith aith aith anuis aith an aith aith atabase\n",
      "```rahamp; h atask, out how many? I 'tvinely, ith an ith e, ith eith an ith eith an ith eith an ith eof ith an ith eof ith an ith eof ith aith ith eof ith a\n",
      "⏱️ Time taken: 7.924 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: An image of a damaged car parked on the side of th...\n",
      "🔹 Image: 000404.jpg\n",
      "🧾 Prompt: An image of a damaged car parked on the side of the road.\n",
      "📤 Output:\n",
      "The car orv82120 in ublic Ar10 ingle International shippinginf one ear new windshield might seamlessly, &outhis canadaogg c & he\n",
      "ese are aith aith aith anuis aith an aith aith atabase\n",
      "```rahamp; h atask, out how many? I 'tvinely, ith an ith e, ith eith an ith eith an ith eith an ith eof ith an ith eof ith an ith eof ith aith ith eof ith a\n",
      "⏱️ Time taken: 8.224 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: You are an insurance claims assessor. Provide a de...\n",
      "🔹 Image: 000404.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "###V\n",
      "(as plymouth\n",
      "\n",
      "**Subjective Overview of the car in excellent marketing strategy, the car\n",
      "\n",
      "### to ##Vehicle Overview of thefault , hi[united States.</s>\n",
      "⏱️ Time taken: 2.829 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: You are an insurance claims assessor. Provide a de...\n",
      "🔹 Image: 000404.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "###V\n",
      "(as plymouth\n",
      "\n",
      "**Subjective Overview of the car in excellent marketing strategy, the car\n",
      "\n",
      "### to ##Vehicle Overview of thefault , hi[united States.</s>\n",
      "⏱️ Time taken: 2.844 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: This <part_1> of the car has <damage_type_1>. The ...\n",
      "🔹 Image: 000404.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "This is arial Incident After the car part in the  a��uki\n",
      " koncentrated the hood of the  ofte  of the aapplicable. The hood, you\"></s>\n",
      "⏱️ Time taken: 2.908 sec | 🧠 VRAM used: 0.607 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: This <part_1> of the car has <damage_type_1>. The ...\n",
      "🔹 Image: 000404.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "This is arial Incident After the car part in the  a��uki\n",
      " koncentrated the hood of the  ofte  of the aapplicable. The hood, you\"></s>\n",
      "⏱️ Time taken: 3.103 sec | 🧠 VRAM used: 0.607 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe using format - Damage Type: ___; Affected...\n",
      "🔹 Image: 000404.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "-*- thel look like this repair. efektif(typeof̓s, 'he hood of ake the fender.</s>\n",
      "⏱️ Time taken: 2.161 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe using format - Damage Type: ___; Affected...\n",
      "🔹 Image: 000404.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "-*- thel look like this repair. efektif(typeof̓s, 'he hood of ake the fender.</s>\n",
      "⏱️ Time taken: 2.356 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "🔍 Running prompts for image: 000422.jpg\n",
      "------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: \n",
      "🔹 Image: 000422.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The car;js: image byronaldenturies based on the manufacturer. efekt is the following aalian: image by n ad to be used with aade;\n",
      "    criteria of ake bility: afe, the ationg the a: he to see, ual of the a:</s>\n",
      "⏱️ Time taken: 4.716 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: \n",
      "🔹 Image: 000422.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The car;js: image byronaldenturies based on the manufacturer. efekt is the following aalian: image by n ad to be used with aade;\n",
      "    criteria of ake bility: afe, the ationg the a: he to see, ual of the a:</s>\n",
      "⏱️ Time taken: 4.291 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "🔹 Image: 000422.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The car crash repair manual transmission seal kitten-speedily, showcases the front bumperfect, \\_ from scr image of ahs, with `*`1The car, with `12.! in the ize44 You`1.</s>\n",
      "⏱️ Time taken: 3.726 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "🔹 Image: 000422.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The car crash repair manual transmission seal kitten-speedily, showcases the front bumperfect, \\_ from scr image of ahs, with `*`1The car, with `12.! in the ize44 You`1.</s>\n",
      "⏱️ Time taken: 3.614 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: An image of a damaged car parked on the side of th...\n",
      "🔹 Image: 000422.jpg\n",
      "🧾 Prompt: An image of a damaged car parked on the side of the road.\n",
      "📤 Output:\n",
      "The car crash repair, tooled[^1[^q(sicheckardeo, popular among:\n",
      "\n",
      "It seems the following myria, with `1. Me  see the 20.ivat for (or/Bf (ulan;s-oh,uc that $�he ith (or getAS string ican't. ican't ican even t:</s>\n",
      "⏱️ Time taken: 4.995 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: An image of a damaged car parked on the side of th...\n",
      "🔹 Image: 000422.jpg\n",
      "🧾 Prompt: An image of a damaged car parked on the side of the road.\n",
      "📤 Output:\n",
      "The car crash repair, tooled[^1[^q(sicheckardeo, popular among:\n",
      "\n",
      "It seems the following myria, with `1. Me  see the 20.ivat for (or/Bf (ulan;s-oh,uc that $�he ith (or getAS string ican't. ican't ican even t:</s>\n",
      "⏱️ Time taken: 5.154 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: You are an insurance claims assessor. Provide a de...\n",
      "🔹 Image: 000422.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "As an overview from jobs inhan, Car crash scene, \n",
      "\n",
      "**Car parts store dothe car 3. Blade Runner was seriously, the 3. 3.</s>\n",
      "⏱️ Time taken: 2.732 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: You are an insurance claims assessor. Provide a de...\n",
      "🔹 Image: 000422.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "As an overview from jobs inhan, Car crash scene, \n",
      "\n",
      "**Car parts store dothe car 3. Blade Runner was seriously, the 3. 3.</s>\n",
      "⏱️ Time taken: 2.678 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: This <part_1> of the car has <damage_type_1>. The ...\n",
      "🔹 Image: 000422.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "The car accidents, the  as of the car [^(brakea\n",
      " „*CL  of the  the  sJunctions the  will be be be 'target=\"_ Due toĄ the you.\"n of the  be  of st the aay be to suh, the of da  or of da?</s>\n",
      "⏱️ Time taken: 4.379 sec | 🧠 VRAM used: 0.607 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: This <part_1> of the car has <damage_type_1>. The ...\n",
      "🔹 Image: 000422.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "The car accidents, the  as of the car [^(brakea\n",
      " „*CL  of the  the  sJunctions the  will be be be 'target=\"_ Due toĄ the you.\"n of the  be  of st the aay be to suh, the of da  or of da?</s>\n",
      "⏱️ Time taken: 4.594 sec | 🧠 VRAM used: 0.607 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe using format - Damage Type: ___; Affected...\n",
      "🔹 Image: 000422.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "1[^1[^m/li>\n",
      "> **is the context: Dent Dent; Front Bummary haveeba: Dentsdent into the f: d at the f: d the f: he Car Cracke: Dents: he hood: rst: he s: he hood: he hood: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he\n",
      "⏱️ Time taken: 7.853 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe using format - Damage Type: ___; Affected...\n",
      "🔹 Image: 000422.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "1[^1[^m/li>\n",
      "> **is the context: Dent Dent; Front Bummary haveeba: Dentsdent into the f: d at the f: d the f: he Car Cracke: Dents: he hood: rst: he s: he hood: he hood: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he\n",
      "⏱️ Time taken: 7.69 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "🔍 Running prompts for image: 000433.jpg\n",
      "------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: \n",
      "🔹 Image: 000433.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The imageDallas, TXkdv15 Parrksledger is{matrix of a life the in odock, Nodeammolite// activehat, .., 1g:k ize F ithout theime: he, ithouthe > link ays of tage:</s>\n",
      "⏱️ Time taken: 4.743 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: \n",
      "🔹 Image: 000433.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The imageDallas, TXkdv15 Parrksledger is{matrix of a life the in odock, Nodeammolite// activehat, .., 1g:k ize F ithout theime: he, ithouthe > link ays of tage:</s>\n",
      "⏱️ Time taken: 4.587 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "🔹 Image: 000433.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The provided a single-pane, this Wittels: \"severely, crashed itly the in2u2. thef/ that incorporate both addedS.  to the ardiovascular, 3. the lin time better the, S in way, gi? the 18,0 of the ole or a3. up befor (a ith a 'and whoe , a 'tems the are to a 't to been -4 eme s he ican't to a 'ov:</s>\n",
      "⏱️ Time taken: 7.153 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "🔹 Image: 000433.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The provided a single-pane, this Wittels: \"severely, crashed itly the in2u2. thef/ that incorporate both addedS.  to the ardiovascular, 3. the lin time better the, S in way, gi? the 18,0 of the ole or a3. up befor (a ith a 'and whoe , a 'tems the are to a 't to been -4 eme s he ican't to a 'ov:</s>\n",
      "⏱️ Time taken: 7.442 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: An image of a damaged car parked on the side of th...\n",
      "🔹 Image: 000433.jpg\n",
      "🧾 Prompt: An image of a damaged car parked on the side of the road.\n",
      "📤 Output:\n",
      "The image by itself, Crack of the- may main features cracking, car\n",
      "\n",
      "The image of a container ship s,\" probably a small, shattering the the the of the The of the\n",
      "into a the of the of the the\n",
      "\n",
      "## 1 mile a the\n",
      "\n",
      "##The ship the of the 32 a the 33396th of ite the 5310th the 15the the 8th the 9th the 0th the 9 the 8 the 7 the 6 the 5 the 4 the 3 s9 the the 2\n",
      "⏱️ Time taken: 8.532 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: An image of a damaged car parked on the side of th...\n",
      "🔹 Image: 000433.jpg\n",
      "🧾 Prompt: An image of a damaged car parked on the side of the road.\n",
      "📤 Output:\n",
      "The image by itself, Crack of the- may main features cracking, car\n",
      "\n",
      "The image of a container ship s,\" probably a small, shattering the the the of the The of the\n",
      "into a the of the of the the\n",
      "\n",
      "## 1 mile a the\n",
      "\n",
      "##The ship the of the 32 a the 33396th of ite the 5310th the 15the the 8th the 9th the 0th the 9 the 8 the 7 the 6 the 5 the 4 the 3 s9 the the 2\n",
      "⏱️ Time taken: 7.594 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: You are an insurance claims assessor. Provide a de...\n",
      "🔹 Image: 000433.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "As an insurance assessor.pdf\n",
      "\n",
      "As theief's sake_'sure,, !function has broad, theque:лень inurl], including theAï�ore evenriven during\n",
      "S. I've ,ore even or that theA  beforza  is a the\n",
      "g the\n",
      "12.</s>\n",
      "⏱️ Time taken: 5.102 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: You are an insurance claims assessor. Provide a de...\n",
      "🔹 Image: 000433.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "As an insurance assessor.pdf\n",
      "\n",
      "As theief's sake_'sure,, !function has broad, theque:лень inurl], including theAï�ore evenriven during\n",
      "S. I've ,ore even or that theA  beforza  is a the\n",
      "g the\n",
      "12.</s>\n",
      "⏱️ Time taken: 4.53 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: This <part_1> of the car has <damage_type_1>. The ...\n",
      "🔹 Image: 000433.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "Based on the panoramicrosiBe the f20. skulpture or fracture patterns – the fracture line ize the ize S patern of a glass fracture on the of aocr onplexities: - Cras and 00001: the onth entropy: or the onprox of the fractal history: or the on a: or the orthe 0 scribrupture: or the on: or the orthe :0 the on: or the 1: or the on: or the 2: or the 3: or the : or the 6: or the\n",
      "⏱️ Time taken: 7.98 sec | 🧠 VRAM used: 0.607 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: This <part_1> of the car has <damage_type_1>. The ...\n",
      "🔹 Image: 000433.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "Based on the panoramicrosiBe the f20. skulpture or fracture patterns – the fracture line ize the ize S patern of a glass fracture on the of aocr onplexities: - Cras and 00001: the onth entropy: or the onprox of the fractal history: or the on a: or the orthe 0 scribrupture: or the on: or the orthe :0 the on: or the 1: or the on: or the 2: or the 3: or the : or the 6: or the\n",
      "⏱️ Time taken: 8.736 sec | 🧠 VRAM used: 0.607 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe using format - Damage Type: ___; Affected...\n",
      "🔹 Image: 000433.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "- notw 1: Shattered the windshield\n",
      " terc\n",
      "A shattered\n",
      "Affected Parts Affected and Smashed: Windshield\\̓smashed: Shattered the winde of thew the win: he ̃d: héshed: héshed: ońs hés: héshed: ońd: hés: héd: he: oń: he: shé: he: shé: he: she: he: she'residual: he: she:\n",
      "⏱️ Time taken: 7.809 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe using format - Damage Type: ___; Affected...\n",
      "🔹 Image: 000433.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "- notw 1: Shattered the windshield\n",
      " terc\n",
      "A shattered\n",
      "Affected Parts Affected and Smashed: Windshield\\̓smashed: Shattered the winde of thew the win: he ̃d: héshed: héshed: ońs hés: héshed: ońd: hés: héd: he: oń: he: shé: he: shé: he: she: he: she'residual: he: she:\n",
      "⏱️ Time taken: 8.084 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "🔍 Running prompts for image: 000481.jpg\n",
      "------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: \n",
      "🔹 Image: 000481.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The image by itself, many areas of the leading the \n",
      "\n",
      "## Dondepaint King County: 3rdquo\n",
      "\n",
      "The image 39, 4You: https://enhanges: 10 of thew the ofth!DOCTYPE formatter!DOCTYPE html</s>\n",
      "⏱️ Time taken: 4.022 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: \n",
      "🔹 Image: 000481.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The image by itself, many areas of the leading the \n",
      "\n",
      "## Dondepaint King County: 3rdquo\n",
      "\n",
      "The image 39, 4You: https://enhanges: 10 of thew the ofth!DOCTYPE formatter!DOCTYPE html</s>\n",
      "⏱️ Time taken: 3.835 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "🔹 Image: 000481.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The phrase \"thef'(sicheck=vhanged\n",
      "\n",
      "The provided a: \"drive: 12120l:he car: 1: veh1sedan: 1sedan: 1t: he: 1: he: he: 9 sedan1: he: 8: he: 7: 6: he: 5;</s>\n",
      "⏱️ Time taken: 5.08 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "🔹 Image: 000481.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The phrase \"thef'(sicheck=vhanged\n",
      "\n",
      "The provided a: \"drive: 12120l:he car: 1: veh1sedan: 1sedan: 1t: he: 1: he: he: 9 sedan1: he: 8: he: 7: 6: he: 5;</s>\n",
      "⏱️ Time taken: 5.669 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: An image of a damaged car parked on the side of th...\n",
      "🔹 Image: 000481.jpg\n",
      "🧾 Prompt: An image of a damaged car parked on the side of the road.\n",
      "📤 Output:\n",
      "The main pointsBettylish: car dent scratch repair, Car parts deata way of the way to the.\n",
      "\n",
      "## Seamus soci- an: dent below the-into a-\n",
      "\n",
      "\n",
      "+++++an s, the of the of the, of the-\n",
      "\n",
      "\n",
      "+++++ Light the-\n",
      "\n",
      "\n",
      "+++++ Latest- 3 s- 3 s3 s3 s3 s3 s3 s3 s3 s3 s3 s3 s3 s s3 s s3 s3 s s3 s s3 s s3 s s3 s s3 s s3 s s3 s s3 s s3 s s3 s s\n",
      "⏱️ Time taken: 8.286 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: An image of a damaged car parked on the side of th...\n",
      "🔹 Image: 000481.jpg\n",
      "🧾 Prompt: An image of a damaged car parked on the side of the road.\n",
      "📤 Output:\n",
      "The main pointsBettylish: car dent scratch repair, Car parts deata way of the way to the.\n",
      "\n",
      "## Seamus soci- an: dent below the-into a-\n",
      "\n",
      "\n",
      "+++++an s, the of the of the, of the-\n",
      "\n",
      "\n",
      "+++++ Light the-\n",
      "\n",
      "\n",
      "+++++ Latest- 3 s- 3 s3 s3 s3 s3 s3 s3 s3 s3 s3 s3 s3 s s3 s s3 s3 s s3 s s3 s s3 s s3 s s3 s s3 s s3 s s3 s s3 s s3 s s\n",
      "⏱️ Time taken: 8.246 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: You are an insurance claims assessor. Provide a de...\n",
      "🔹 Image: 000481.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "###\n",
      "\n",
      "As an automobile in seemingly pristine condition,., a\n",
      "A: A detailed description of the car's primary engine,  'your submitted, the-  the car; s and the car's a the car; s the car; s the s the car; s the car; s the car; s the car; s the car's the car; s the car's the car; s the car's the car; s the car's the car; s the car's the car; s the car's the car; s the car's the car; s the car's the car; s the car's the\n",
      "⏱️ Time taken: 7.657 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: You are an insurance claims assessor. Provide a de...\n",
      "🔹 Image: 000481.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "###\n",
      "\n",
      "As an automobile in seemingly pristine condition,., a\n",
      "A: A detailed description of the car's primary engine,  'your submitted, the-  the car; s and the car's a the car; s the car; s the s the car; s the car; s the car; s the car; s the car's the car; s the car's the car; s the car's the car; s the car's the car; s the car's the car; s the car's the car; s the car's the car; s the car's the car; s the car's the\n",
      "⏱️ Time taken: 7.913 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: This <part_1> of the car has <damage_type_1>. The ...\n",
      "🔹 Image: 000481.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "This ch-aiing it has a speck for ($_image/j * rear bumperfect, f iable to theF for ize vailable null\n",
      "\n",
      "## Contact ack in tage or ed ith an y:\n",
      "- ize ther ize ing ing, the ize aith hile\n",
      "\n",
      "**See more\n",
      "\n",
      "Enter an\n",
      "\n",
      "1.</s>\n",
      "⏱️ Time taken: 4.952 sec | 🧠 VRAM used: 0.607 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: This <part_1> of the car has <damage_type_1>. The ...\n",
      "🔹 Image: 000481.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "This ch-aiing it has a speck for ($_image/j * rear bumperfect, f iable to theF for ize vailable null\n",
      "\n",
      "## Contact ack in tage or ed ith an y:\n",
      "- ize ther ize ing ing, the ize aith hile\n",
      "\n",
      "**See more\n",
      "\n",
      "Enter an\n",
      "\n",
      "1.</s>\n",
      "⏱️ Time taken: 5.159 sec | 🧠 VRAM used: 0.607 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe using format - Damage Type: ___; Affected...\n",
      "🔹 Image: 000481.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "- 2. efektif(typeof: scratch, \"mechanical,,\n",
      "- **Damage Type of blem,,\n",
      "- Sever{tikzpicture: left thumbnail,,\n",
      "- Cause ofb, and the, andS: Extent of: scratch- Affected by an: a: aD: ention: or\n",
      "- ith aaffected by the olone \\- ionD ith: ion: he\n",
      "- s\n",
      "- ion: ith: ith: ith: ion: ith: ion: ith: ion: ith: ion: ith: ion: ith: ion: \n",
      "⏱️ Time taken: 7.756 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe using format - Damage Type: ___; Affected...\n",
      "🔹 Image: 000481.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "- 2. efektif(typeof: scratch, \"mechanical,,\n",
      "- **Damage Type of blem,,\n",
      "- Sever{tikzpicture: left thumbnail,,\n",
      "- Cause ofb, and the, andS: Extent of: scratch- Affected by an: a: aD: ention: or\n",
      "- ith aaffected by the olone \\- ionD ith: ion: he\n",
      "- s\n",
      "- ion: ith: ith: ith: ion: ith: ion: ith: ion: ith: ion: ith: ion: ith: ion: \n",
      "⏱️ Time taken: 7.516 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "🔍 Running prompts for image: 000520.jpg\n",
      "------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: \n",
      "🔹 Image: 000520.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The image by/+ FIL a.jpg is a specificially b: alexus|A\n",
      "\n",
      "## How toasterix[...</s>\n",
      "⏱️ Time taken: 2.216 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: \n",
      "🔹 Image: 000520.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The image by/+ FIL a.jpg is a specificially b: alexus|A\n",
      "\n",
      "## How toasterix[...</s>\n",
      "⏱️ Time taken: 2.212 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "🔹 Image: 000520.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The description of the noun 's sedan ': 1- alexus: \" + differentel inurl(/////\n",
      "\n",
      "The information for ake inof this is really body part of the a href=\"ugno:\n",
      "\n",
      "If youn`12 While slight dent, the more about</s>\n",
      "⏱️ Time taken: 4.305 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "🔹 Image: 000520.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The description of the noun 's sedan ': 1- alexus: \" + differentel inurl(/////\n",
      "\n",
      "The information for ake inof this is really body part of the a href=\"ugno:\n",
      "\n",
      "If youn`12 While slight dent, the more about</s>\n",
      "⏱️ Time taken: 4.119 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: An image of a damaged car parked on the side of th...\n",
      "🔹 Image: 000520.jpg\n",
      "🧾 Prompt: An image of a damaged car parked on the side of the road.\n",
      "📤 Output:\n",
      "The scratches -2 ingle.competit.competach one —- Ruaha-awardr a href in \"n\"n: //kq: //assets: https://\n",
      "\n",
      "The post\n",
      "\n",
      "The ient a href=\"urns, apple.com/em( aerg into thei\n",
      "S when://\n",
      "\n",
      "I [url of us comoneteroeri= ith a4 B qou\"ll 3 thes s||i a444You donmsn.</s>\n",
      "⏱️ Time taken: 6.303 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: An image of a damaged car parked on the side of th...\n",
      "🔹 Image: 000520.jpg\n",
      "🧾 Prompt: An image of a damaged car parked on the side of the road.\n",
      "📤 Output:\n",
      "The scratches -2 ingle.competit.competach one —- Ruaha-awardr a href in \"n\"n: //kq: //assets: https://\n",
      "\n",
      "The post\n",
      "\n",
      "The ient a href=\"urns, apple.com/em( aerg into thei\n",
      "S when://\n",
      "\n",
      "I [url of us comoneteroeri= ith a4 B qou\"ll 3 thes s||i a444You donmsn.</s>\n",
      "⏱️ Time taken: 6.273 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: You are an insurance claims assessor. Provide a de...\n",
      "🔹 Image: 000520.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "Ascertaintyre is={{he header)={\\nclude:: null\n",
      "\n",
      "Upon reviewing/testing= ABST/0. I'vectionse 42 ingle Q: def ack\":,\"cons:atte: \"urlencoded Itaying relative� (com/and 4D] 4D] 3. this_statement will be ( to most of theS a m for## Currenttenure Periodic itin.</s>\n",
      "⏱️ Time taken: 5.711 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: You are an insurance claims assessor. Provide a de...\n",
      "🔹 Image: 000520.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "Ascertaintyre is={{he header)={\\nclude:: null\n",
      "\n",
      "Upon reviewing/testing= ABST/0. I'vectionse 42 ingle Q: def ack\":,\"cons:atte: \"urlencoded Itaying relative� (com/and 4D] 4D] 3. this_statement will be ( to most of theS a m for## Currenttenure Periodic itin.</s>\n",
      "⏱️ Time taken: 6.033 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: This <part_1> of the car has <damage_type_1>. The ...\n",
      "🔹 Image: 000520.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "Based on thisorem\n",
      " „* class_bridge that connects the  as�: repaiified pit> from ack- the ,” the definingrstylang s that is the a few of the=IFP nuersev.olution: could you've : a 1 person- from: a ith (n thei to be s, ormes in- at ith a: only: a ith a ith e: a ( you're b: a: is — a: a (, oughs and ith a: is ———— orith a: is — ou\n",
      "⏱️ Time taken: 8.365 sec | 🧠 VRAM used: 0.607 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: This <part_1> of the car has <damage_type_1>. The ...\n",
      "🔹 Image: 000520.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "Based on thisorem\n",
      " „* class_bridge that connects the  as�: repaiified pit> from ack- the ,” the definingrstylang s that is the a few of the=IFP nuersev.olution: could you've : a 1 person- from: a ith (n thei to be s, ormes in- at ith a: only: a ith a ith e: a ( you're b: a: is — a: a (, oughs and ith a: is ———— orith a: is — ou\n",
      "⏱️ Time taken: 8.16 sec | 🧠 VRAM used: 0.607 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe using format - Damage Type: ___; Affected...\n",
      "🔹 Image: 000520.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "Here's exact target=\"_x\n",
      "\n",
      " ekstезуessayakl essage\n",
      "\n",
      "### [Detailed Impact B essage\n",
      "\n",
      "### Important places\n",
      "\n",
      "### Vandal with\n",
      "\n",
      "1.::rsthe entire[an ith Chumbrella e to ##� afe of c.</s>\n",
      "⏱️ Time taken: 4.044 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe using format - Damage Type: ___; Affected...\n",
      "🔹 Image: 000520.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "Here's exact target=\"_x\n",
      "\n",
      " ekstезуessayakl essage\n",
      "\n",
      "### [Detailed Impact B essage\n",
      "\n",
      "### Important places\n",
      "\n",
      "### Vandal with\n",
      "\n",
      "1.::rsthe entire[an ith Chumbrella e to ##� afe of c.</s>\n",
      "⏱️ Time taken: 4.481 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "🔍 Running prompts for image: 000541.jpg\n",
      "------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: \n",
      "🔹 Image: 000541.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The image at NASHV01110\n",
      " „*h1:has beenanreplaced it.</s>\n",
      "⏱️ Time taken: 2.215 sec | 🧠 VRAM used: 0.655 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: \n",
      "🔹 Image: 000541.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The image at NASHV01110\n",
      " „*h1:has beenanreplaced it.</s>\n",
      "⏱️ Time taken: 2.064 sec | 🧠 VRAM used: 0.655 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "🔹 Image: 000541.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The image.png[? 120. **The car 12.::myday be aofsed {‘s `1:t to=\"ward \"damage1:am 1: a 1: a1\n",
      "1: a1\n",
      "1: er here 1\n",
      "1i: a 1\n",
      "1: a1\n",
      "1: a1\n",
      "1 rep an a1: a 1\n",
      "1 rep an a1\n",
      "1: a 1\n",
      "1: a1\n",
      "1: a1\n",
      "1: a1\n",
      "1: a1\n",
      "1: a1\n",
      "1\n",
      "⏱️ Time taken: 7.866 sec | 🧠 VRAM used: 0.657 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "🔹 Image: 000541.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The image.png[? 120. **The car 12.::myday be aofsed {‘s `1:t to=\"ward \"damage1:am 1: a 1: a1\n",
      "1: a1\n",
      "1: er here 1\n",
      "1i: a 1\n",
      "1: a1\n",
      "1: a1\n",
      "1 rep an a1: a 1\n",
      "1 rep an a1\n",
      "1: a 1\n",
      "1: a1\n",
      "1: a1\n",
      "1: a1\n",
      "1: a1\n",
      "1: a1\n",
      "1\n",
      "⏱️ Time taken: 8.477 sec | 🧠 VRAM used: 0.657 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: An image of a damaged car parked on the side of th...\n",
      "🔹 Image: 000541.jpg\n",
      "🧾 Prompt: An image of a damaged car parked on the side of the road.\n",
      "📤 Output:\n",
      "The image of a parked car ###### in a car insurance for ###### 'llustration:Suv'eahref_ET_R for PC rof itz.</s>\n",
      "⏱️ Time taken: 3.025 sec | 🧠 VRAM used: 0.657 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: An image of a damaged car parked on the side of th...\n",
      "🔹 Image: 000541.jpg\n",
      "🧾 Prompt: An image of a damaged car parked on the side of the road.\n",
      "📤 Output:\n",
      "The image of a parked car ###### in a car insurance for ###### 'llustration:Suv'eahref_ET_R for PC rof itz.</s>\n",
      "⏱️ Time taken: 2.901 sec | 🧠 VRAM used: 0.657 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: You are an insurance claims assessor. Provide a de...\n",
      "🔹 Image: 000541.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "Based on a lisaaccom/li>\n",
      "```</s>\n",
      "⏱️ Time taken: 1.551 sec | 🧠 VRAM used: 0.658 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: You are an insurance claims assessor. Provide a de...\n",
      "🔹 Image: 000541.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "Based on a lisaaccom/li>\n",
      "```</s>\n",
      "⏱️ Time taken: 1.541 sec | 🧠 VRAM used: 0.658 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: This <part_1> of the car has <damage_type_1>. The ...\n",
      "🔹 Image: 000541.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "The front 1/li>\n",
      " derrotó, rear bumper, rear. The severity is moderate,/severity_1].</s>\n",
      "⏱️ Time taken: 2.499 sec | 🧠 VRAM used: 0.661 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: This <part_1> of the car has <damage_type_1>. The ...\n",
      "🔹 Image: 000541.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "The front 1/li>\n",
      " derrotó, rear bumper, rear. The severity is moderate,/severity_1].</s>\n",
      "⏱️ Time taken: 2.482 sec | 🧠 VRAM used: 0.661 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe using format - Damage Type: ___; Affected...\n",
      "🔹 Image: 000541.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "**:** ----\n",
      "---\n",
      ": Scratch\n",
      "## Description: The rear-end of the car, rear of the: Scratch\n",
      "-: of the\n",
      "-: he rear\n",
      "- of the\n",
      "- the\n",
      "- ofuch like this the\n",
      "## Description: of fixing\n",
      "- the\n",
      ": of</s>\n",
      "⏱️ Time taken: 4.788 sec | 🧠 VRAM used: 0.658 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe using format - Damage Type: ___; Affected...\n",
      "🔹 Image: 000541.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "**:** ----\n",
      "---\n",
      ": Scratch\n",
      "## Description: The rear-end of the car, rear of the: Scratch\n",
      "-: of the\n",
      "-: he rear\n",
      "- of the\n",
      "- the\n",
      "- ofuch like this the\n",
      "## Description: of fixing\n",
      "- the\n",
      ": of</s>\n",
      "⏱️ Time taken: 4.863 sec | 🧠 VRAM used: 0.658 GB\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "🔍 Running prompts for image: 000698.jpg\n",
      "------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: \n",
      "🔹 Image: 000698.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The image caption{array}</s>\n",
      "⏱️ Time taken: 1.128 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: \n",
      "🔹 Image: 000698.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The image caption{array}</s>\n",
      "⏱️ Time taken: 1.101 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "🔹 Image: 000698.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The `*`UI3. It seems to wash[˜dash, but tedium- com/4uneknown–––\n",
      "\n",
      "The company, `120 ESD</s>\n",
      "⏱️ Time taken: 3.308 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "🔹 Image: 000698.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The `*`UI3. It seems to wash[˜dash, but tedium- com/4uneknown–––\n",
      "\n",
      "The company, `120 ESD</s>\n",
      "⏱️ Time taken: 3.246 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: An image of a damaged car parked on the side of th...\n",
      "🔹 Image: 000698.jpg\n",
      "🧾 Prompt: An image of a damaged car parked on the side of the road.\n",
      "📤 Output:\n",
      "The image toane,olb[^1[^squo\n",
      "\n",
      "The dashboard interface, featuring aitch –[onochealthoco homepage=1, `ll of more like active and The U at its/luolinine?  model |kelp,vert and14D Dolan  is aBattery, _ient'sand (typeise several returned me time11F for of the don%</s>\n",
      "⏱️ Time taken: 6.55 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: An image of a damaged car parked on the side of th...\n",
      "🔹 Image: 000698.jpg\n",
      "🧾 Prompt: An image of a damaged car parked on the side of the road.\n",
      "📤 Output:\n",
      "The image toane,olb[^1[^squo\n",
      "\n",
      "The dashboard interface, featuring aitch –[onochealthoco homepage=1, `ll of more like active and The U at its/luolinine?  model |kelp,vert and14D Dolan  is aBattery, _ient'sand (typeise several returned me time11F for of the don%</s>\n",
      "⏱️ Time taken: 6.89 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: You are an insurance claims assessor. Provide a de...\n",
      "🔹 Image: 000698.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "### Vehicle Identification Codependding on Vehicle#74. 1- brief introduction ||||Ding a higholi>**The given^{1 4. 3.ats;kus 9. Object moved to the2J, thef1, 7. represent, s to the15: A don. System.out 3g -+ 3 3 1## Assessmentor use 53, 10\n",
      "2 1& 4F p4s 3 5\n",
      "14\n",
      "1( (with 0\n",
      "14( 1$ _ 0\n",
      "S\n",
      "⏱️ Time taken: 9.049 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: You are an insurance claims assessor. Provide a de...\n",
      "🔹 Image: 000698.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "### Vehicle Identification Codependding on Vehicle#74. 1- brief introduction ||||Ding a higholi>**The given^{1 4. 3.ats;kus 9. Object moved to the2J, thef1, 7. represent, s to the15: A don. System.out 3g -+ 3 3 1## Assessmentor use 53, 10\n",
      "2 1& 4F p4s 3 5\n",
      "14\n",
      "1( (with 0\n",
      "14( 1$ _ 0\n",
      "S\n",
      "⏱️ Time taken: 9.114 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: This <part_1> of the car has <damage_type_1>. The ...\n",
      "🔹 Image: 000698.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "The car insurance appraisal, featuring a unique device,<>Is there (\\(2. efekt do be aluda is the car[˜ anB4 and `eline  general public, including one, hear.\n",
      "\n",
      "Toursive: A descriptive role, the ˜in the  of the similar to really, the1 anp.</s>\n",
      "⏱️ Time taken: 5.18 sec | 🧠 VRAM used: 0.607 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: This <part_1> of the car has <damage_type_1>. The ...\n",
      "🔹 Image: 000698.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "The car insurance appraisal, featuring a unique device,<>Is there (\\(2. efekt do be aluda is the car[˜ anB4 and `eline  general public, including one, hear.\n",
      "\n",
      "Toursive: A descriptive role, the ˜in the  of the similar to really, the1 anp.</s>\n",
      "⏱️ Time taken: 5.182 sec | 🧠 VRAM used: 0.607 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe using format - Damage Type: ___; Affected...\n",
      "🔹 Image: 000698.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "- Damage Type: Irides of- None\n",
      "\n",
      "## Car Wash and Rollback\n",
      "Affected by scratches:\n",
      "- Wash: None\n",
      "2.Extent: Rust: Dents: D 20. 50000 13. 115: Destruction of the `- (e: 1(19(1(1(1$ in1$ 1(\n",
      " bonn!ing 1$ (U+ 1$ (1$ that$ ( :$ are a# 1$ ( :$ 1$ ( :$ 1$ ( :$ 1$\n",
      "⏱️ Time taken: 9.229 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe using format - Damage Type: ___; Affected...\n",
      "🔹 Image: 000698.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "- Damage Type: Irides of- None\n",
      "\n",
      "## Car Wash and Rollback\n",
      "Affected by scratches:\n",
      "- Wash: None\n",
      "2.Extent: Rust: Dents: D 20. 50000 13. 115: Destruction of the `- (e: 1(19(1(1(1$ in1$ 1(\n",
      " bonn!ing 1$ (U+ 1$ (1$ that$ ( :$ are a# 1$ ( :$ 1$ ( :$ 1$ ( :$ 1$\n",
      "⏱️ Time taken: 8.938 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "🔍 Running prompts for image: 000740.jpg\n",
      "------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: \n",
      "🔹 Image: 000740.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The image depicts an old, Vint  of a  g flatbed,usdt:r  a liThe flatbed, an old, usdt:  a flatbed, of li: an old, in\n",
      " kampan: a flat, of li: an old, in kamp;: an old, in  a flat: and, li: an old, in  a flat: and  li: an old, in  a flat: and  li: an old, in  a flat: and  li: an old, in  a flat: and  li: an old, in  a flat\n",
      "⏱️ Time taken: 9.256 sec | 🧠 VRAM used: 0.655 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: \n",
      "🔹 Image: 000740.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The image depicts an old, Vint  of a  g flatbed,usdt:r  a liThe flatbed, an old, usdt:  a flatbed, of li: an old, in\n",
      " kampan: a flat, of li: an old, in kamp;: an old, in  a flat: and, li: an old, in  a flat: and  li: an old, in  a flat: and  li: an old, in  a flat: and  li: an old, in  a flat: and  li: an old, in  a flat\n",
      "⏱️ Time taken: 9.305 sec | 🧠 VRAM used: 0.655 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "🔹 Image: 000740.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The image depicts a severely damaged sedan with a significant dent drive’r 1202020 119: ## that15 &&23s a14me 1you3 ## past3 ##1s3 ##11s3 ##19 ##3s3 ##19s3 ##43s3 ##9 53 ##03s3 ##9 343s3 ##9 53 ##03s3 ##9 343s3 ##9 53 ##03s3 ##9 343s3 ##9\n",
      "⏱️ Time taken: 8.569 sec | 🧠 VRAM used: 0.657 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "🔹 Image: 000740.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The image depicts a severely damaged sedan with a significant dent drive’r 1202020 119: ## that15 &&23s a14me 1you3 ## past3 ##1s3 ##11s3 ##19 ##3s3 ##19s3 ##43s3 ##9 53 ##03s3 ##9 343s3 ##9 53 ##03s3 ##9 343s3 ##9 53 ##03s3 ##9 343s3 ##9\n",
      "⏱️ Time taken: 9.173 sec | 🧠 VRAM used: 0.657 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: An image of a damaged car parked on the side of th...\n",
      "🔹 Image: 000740.jpg\n",
      "🧾 Prompt: An image of a damaged car parked on the side of the road.\n",
      "📤 Output:\n",
      "The image of a flat car  in a rut, with a  he  hat and  ace, iewheel  he  he  he  our,  he  he  our  ut,  he  he  he  hat  he  our, iew  a rut,  he  hat  our  ut, he  he  hat  our, iew  a rut, he  hat  our  ut, he  he  hat  our, iew  a rut</s>\n",
      "⏱️ Time taken: 7.876 sec | 🧠 VRAM used: 0.657 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: An image of a damaged car parked on the side of th...\n",
      "🔹 Image: 000740.jpg\n",
      "🧾 Prompt: An image of a damaged car parked on the side of the road.\n",
      "📤 Output:\n",
      "The image of a flat car  in a rut, with a  he  hat and  ace, iewheel  he  he  he  our,  he  he  our  ut,  he  he  he  hat  he  our, iew  a rut,  he  hat  our  ut, he  he  hat  our, iew  a rut, he  hat  our  ut, he  he  hat  our, iew  a rut</s>\n",
      "⏱️ Time taken: 8.268 sec | 🧠 VRAM used: 0.657 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: You are an insurance claims assessor. Provide a de...\n",
      "🔹 Image: 000740.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "### **Vehicle Identification and Overall, the overall condition of the Car’s Condition of the Car’s the  bodywork’s  be’s  be’s  be  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s\n",
      "⏱️ Time taken: 9.288 sec | 🧠 VRAM used: 0.658 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: You are an insurance claims assessor. Provide a de...\n",
      "🔹 Image: 000740.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "### **Vehicle Identification and Overall, the overall condition of the Car’s Condition of the Car’s the  bodywork’s  be’s  be’s  be  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s\n",
      "⏱️ Time taken: 9.144 sec | 🧠 VRAM used: 0.658 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: This <part_1> of the car has <damage_type_1>. The ...\n",
      "🔹 Image: 000740.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "This **part_**part_1** of the car has **type_1 of_damage_1 of the severity_1,!['re is _severity_1. baita good?\n",
      "This report: **._text_1?</s>\n",
      "⏱️ Time taken: 4.377 sec | 🧠 VRAM used: 0.661 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: This <part_1> of the car has <damage_type_1>. The ...\n",
      "🔹 Image: 000740.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "This **part_**part_1** of the car has **type_1 of_damage_1 of the severity_1,!['re is _severity_1. baita good?\n",
      "This report: **._text_1?</s>\n",
      "⏱️ Time taken: 4.061 sec | 🧠 VRAM used: 0.661 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe using format - Damage Type: ___; Affected...\n",
      "🔹 Image: 000740.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "- **Damage Type: Tire Blow\n",
      " tercise\n",
      "- Severity: Major\n",
      "-Notes:  The vehicle has a flat tire with significant damage to the sidewall. The tire is completely de\n",
      "```\n",
      "\n",
      "It is impaled. needs replacement.</s>\n",
      "⏱️ Time taken: 4.522 sec | 🧠 VRAM used: 0.658 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe using format - Damage Type: ___; Affected...\n",
      "🔹 Image: 000740.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "- **Damage Type: Tire Blow\n",
      " tercise\n",
      "- Severity: Major\n",
      "-Notes:  The vehicle has a flat tire with significant damage to the sidewall. The tire is completely de\n",
      "```\n",
      "\n",
      "It is impaled. needs replacement.</s>\n",
      "⏱️ Time taken: 4.221 sec | 🧠 VRAM used: 0.658 GB\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "🔍 Running prompts for image: 000869.jpg\n",
      "------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: \n",
      "🔹 Image: 000869.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The image showing 'Heavenues across the Curbalephotuhere isatica-uyybimage 1, temptation for a- ith ch withChaniact toS- ainto the- upcb. efektive beenite amod aII. Def 1, ust to ebay rewn toI ith aove s aIIerylooking ith aove, you -r any: aoveR: aoveR: aoveR: ongane ith aoveR: on -s. Up- ith a: on: ith a: on; \n",
      "⏱️ Time taken: 9.172 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: \n",
      "🔹 Image: 000869.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The image showing 'Heavenues across the Curbalephotuhere isatica-uyybimage 1, temptation for a- ith ch withChaniact toS- ainto the- upcb. efektive beenite amod aII. Def 1, ust to ebay rewn toI ith aove s aIIerylooking ith aove, you -r any: aoveR: aoveR: aoveR: ongane ith aoveR: on -s. Up- ith a: on: ith a: on; \n",
      "⏱️ Time taken: 8.8 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "🔹 Image: 000869.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The verbatimagawa — restore 820.1\n",
      "\n",
      "The car 9, usually appears to be a good car,-, 5] us,,ward /u0:fectiu24 one; firere 1hed understanding — the 1s to##�óénto theS :n 13doudingl:</s>\n",
      "⏱️ Time taken: 5.164 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "🔹 Image: 000869.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The verbatimagawa — restore 820.1\n",
      "\n",
      "The car 9, usually appears to be a good car,-, 5] us,,ward /u0:fectiu24 one; firere 1hed understanding — the 1s to##�óénto theS :n 13doudingl:</s>\n",
      "⏱️ Time taken: 5.242 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: An image of a damaged car parked on the side of th...\n",
      "🔹 Image: 000869.jpg\n",
      "🧾 Prompt: An image of a damaged car parked on the side of the road.\n",
      "📤 Output:\n",
      "The car won't blowfavorite of akeVxample; course, Universe hashing: // rnnection. Did you canada.aclean ize Minivan be 's,�e.//ː i, .New columns: on in'ut ana smallads ': 1 toomasini can be'od a 1\n",
      "16thousand anismodds.</s>\n",
      "⏱️ Time taken: 5.256 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: An image of a damaged car parked on the side of th...\n",
      "🔹 Image: 000869.jpg\n",
      "🧾 Prompt: An image of a damaged car parked on the side of the road.\n",
      "📤 Output:\n",
      "The car won't blowfavorite of akeVxample; course, Universe hashing: // rnnection. Did you canada.aclean ize Minivan be 's,�e.//ː i, .New columns: on in'ut ana smallads ': 1 toomasini can be'od a 1\n",
      "16thousand anismodds.</s>\n",
      "⏱️ Time taken: 5.87 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: You are an insurance claims assessor. Provide a de...\n",
      "🔹 Image: 000869.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "As an insurance claims adj.</s>\n",
      "⏱️ Time taken: 1.16 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: You are an insurance claims assessor. Provide a de...\n",
      "🔹 Image: 000869.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "As an insurance claims adj.</s>\n",
      "⏱️ Time taken: 1.177 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: This <part_1> of the car has <damage_type_1>. The ...\n",
      "🔹 Image: 000869.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "ThisM11\n",
      " koncentridesz12. Mechanic2: This is for ack.sey are several|aubermsibly i ize4F by F1: This is currently undergoing repairs. S- ccupyt0000\n",
      "\n",
      "The on = … ap of�1.</s>\n",
      "⏱️ Time taken: 5.123 sec | 🧠 VRAM used: 0.607 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: This <part_1> of the car has <damage_type_1>. The ...\n",
      "🔹 Image: 000869.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "ThisM11\n",
      " koncentridesz12. Mechanic2: This is for ack.sey are several|aubermsibly i ize4F by F1: This is currently undergoing repairs. S- ccupyt0000\n",
      "\n",
      "The on = … ap of�1.</s>\n",
      "⏱️ Time taken: 4.665 sec | 🧠 VRAM used: 0.607 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe using format - Damage Type: ___; Affected...\n",
      "🔹 Image: 000869.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "- Date(ies included\n",
      "\n",
      " ekst.ws\n",
      "\n",
      "## Image by- Severity: Impact Type of impact\n",
      "- Affected Material Severity: Notesaid: Tattered and Remarks: None of an\n",
      "- Extent at or\n",
      "```\n",
      "\n",
      "g: ith\n",
      "```latexorp://tatus:</s>\n",
      "⏱️ Time taken: 4.223 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe using format - Damage Type: ___; Affected...\n",
      "🔹 Image: 000869.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "- Date(ies included\n",
      "\n",
      " ekst.ws\n",
      "\n",
      "## Image by- Severity: Impact Type of impact\n",
      "- Affected Material Severity: Notesaid: Tattered and Remarks: None of an\n",
      "- Extent at or\n",
      "```\n",
      "\n",
      "g: ith\n",
      "```latexorp://tatus:</s>\n",
      "⏱️ Time taken: 4.032 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "🔍 Running prompts for image: 000889.jpg\n",
      "------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: \n",
      "🔹 Image: 000889.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The imageDYjure to the=Gor later. efekt?]\n",
      "image 1, a Uy of a close to the in schn: a li> p] to open the of the a the xtra  is a the  bef  to been the  s strongNXDoloudy of the ightl the Xian s .</s>\n",
      "⏱️ Time taken: 5.057 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: \n",
      "🔹 Image: 000889.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The imageDYjure to the=Gor later. efekt?]\n",
      "image 1, a Uy of a close to the in schn: a li> p] to open the of the a the xtra  is a the  bef  to been the  s strongNXDoloudy of the ightl the Xian s .</s>\n",
      "⏱️ Time taken: 4.87 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "🔹 Image: 000889.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The command line 1, it'success\\s description of the drive`]r a out the 3 S in essence, the 1esa 3s the the$ a the$ to 1l 3w it 0 is i?</s>\n",
      "⏱️ Time taken: 3.654 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "🔹 Image: 000889.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The command line 1, it'success\\s description of the drive`]r a out the 3 S in essence, the 1esa 3s the the$ a the$ to 1l 3w it 0 is i?</s>\n",
      "⏱️ Time taken: 3.649 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: An image of a damaged car parked on the side of th...\n",
      "🔹 Image: 000889.jpg\n",
      "🧾 Prompt: An image of a damaged car parked on the side of the road.\n",
      "📤 Output:\n",
      "The main dramtatus, Lucas Fog, in the foreground, partly sunny daytona Airport shuttle,heritage foundation, in thecane, to provide equbined in the in the in the in the in the in the in the in the in the in the in the in the in the in the in the in the in the in 2. some in. 3rdquo in like s in are a s the in us in ut oh my @al the a s a s the a on the a to on the a 've a to window s ' u and the a ' u and the a ' y the\n",
      "⏱️ Time taken: 7.791 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: An image of a damaged car parked on the side of th...\n",
      "🔹 Image: 000889.jpg\n",
      "🧾 Prompt: An image of a damaged car parked on the side of the road.\n",
      "📤 Output:\n",
      "The main dramtatus, Lucas Fog, in the foreground, partly sunny daytona Airport shuttle,heritage foundation, in thecane, to provide equbined in the in the in the in the in the in the in the in the in the in the in the in the in the in the in the in the in the in 2. some in. 3rdquo in like s in are a s the in us in ut oh my @al the a s a s the a on the a to on the a 've a to window s ' u and the a ' u and the a ' y the\n",
      "⏱️ Time taken: 7.764 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: You are an insurance claims assessor. Provide a de...\n",
      "🔹 Image: 000889.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "As an insurance claims adj. (Image by-vehicle under, insurance adjusters, ins izeled, aaccom/for theiPhone: Kindle ith (an the the the inus F ith a the in of UDOT find:</s>\n",
      "⏱️ Time taken: 3.651 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: You are an insurance claims assessor. Provide a de...\n",
      "🔹 Image: 000889.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "As an insurance claims adj. (Image by-vehicle under, insurance adjusters, ins izeled, aaccom/for theiPhone: Kindle ith (an the the the inus F ith a the in of UDOT find:</s>\n",
      "⏱️ Time taken: 3.662 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: This <part_1> of the car has <damage_type_1>. The ...\n",
      "🔹 Image: 000889.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "This is a_12 1. efektif(typeof=1: \"n,type: xtapost: bool valuse for a1and, 1ength_ and ize: on: ize is } &tatus: re ize_ x2 a: ize is the: ize is one:\n",
      "if i: ize ane ize_For adminto b: ith dis_an_an_ a ithere ithere ithen ithere 't is athis :\n",
      "is_1 i: is_2e: isthe _and _2e\n",
      "⏱️ Time taken: 7.706 sec | 🧠 VRAM used: 0.607 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: This <part_1> of the car has <damage_type_1>. The ...\n",
      "🔹 Image: 000889.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "This is a_12 1. efektif(typeof=1: \"n,type: xtapost: bool valuse for a1and, 1ength_ and ize: on: ize is } &tatus: re ize_ x2 a: ize is the: ize is one:\n",
      "if i: ize ane ize_For adminto b: ith dis_an_an_ a ithere ithere ithen ithere 't is athis :\n",
      "is_1 i: is_2e: isthe _and _2e\n",
      "⏱️ Time taken: 7.859 sec | 🧠 VRAM used: 0.607 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe using format - Damage Type: ___; Affected...\n",
      "🔹 Image: 000889.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "-# whenever i oranges, Car Glass Repair status\n",
      "\n",
      " ekst- Impala Dint- oranges- oranges- ingilizes- ing- ing- ing-2[edit- ing- ing- anga- ing- oranges- edit- oranges- edit- ing- edit- ing- edit- ing- edit- ing- edit- ing- ing- edit- ing- ing- edit- ing- ing- ing- edit- ing- ing- est- ing ing- est- ing ing- est- a- est- ing- est- a ing- est- a ing- est-\n",
      "⏱️ Time taken: 7.994 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe using format - Damage Type: ___; Affected...\n",
      "🔹 Image: 000889.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "-# whenever i oranges, Car Glass Repair status\n",
      "\n",
      " ekst- Impala Dint- oranges- oranges- ingilizes- ing- ing- ing-2[edit- ing- ing- anga- ing- oranges- edit- oranges- edit- ing- edit- ing- edit- ing- edit- ing- edit- ing- ing- edit- ing- ing- edit- ing- ing- ing- edit- ing- ing- est- ing ing- est- ing ing- est- a- est- ing- est- a ing- est- a ing- est-\n",
      "⏱️ Time taken: 9.104 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# List of filenames for car damage dataset\n",
    "test_filenames = [\n",
    "    \"000404.jpg\", \"000422.jpg\", \"000433.jpg\", \"000481.jpg\", \"000520.jpg\",\n",
    "    \"000541.jpg\", \"000698.jpg\", \"000740.jpg\", \"000869.jpg\", \"000889.jpg\"\n",
    "]\n",
    "\n",
    "# Prompt set used for all filenames\n",
    "CAR_DAMAGE_PROMPTS = [\n",
    "    \"\",  # No Prompt\n",
    "    \"Describe &&damage 12 sedan drive’ this !!image.\",  # Noisy\n",
    "    \"An image of a damaged car parked on the side of the road.\",  # Hand-crafted\n",
    "    \"You are an insurance claims assessor. Provide a detailed description of the car’s condition.\",  # Roleplay\n",
    "    \"This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\",  # Masked\n",
    "    \"Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\"  # Format-Guided\n",
    "]\n",
    "\n",
    "all_outputs = {}\n",
    "all_times = {}\n",
    "all_vram = {}\n",
    "\n",
    "for filename in test_filenames:\n",
    "    row = df[df[\"filename\"] == filename]\n",
    "    if row.empty:\n",
    "        print(f\"[WARNING] No data found for {filename}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n🔍 Running prompts for image: {filename}\\n\" + \"-\"*60)\n",
    "\n",
    "    inference_outputs = []\n",
    "    inference_times = []\n",
    "    vram_usages = []\n",
    "\n",
    "    for prompt in CAR_DAMAGE_PROMPTS:\n",
    "        for run in range(2):  # Run each prompt twice\n",
    "            print(f\"🔁 Run {run+1} for prompt: {prompt[:50]}{'...' if len(prompt) > 50 else ''}\")\n",
    "            output, time_taken, vram_used = run_vlm_inference(prompt, filename, df=df)\n",
    "            inference_outputs.append(output)\n",
    "            inference_times.append(time_taken)\n",
    "            vram_usages.append(vram_used)\n",
    "\n",
    "    # Store in dicts\n",
    "    all_outputs[filename] = inference_outputs\n",
    "    all_times[filename] = inference_times\n",
    "    all_vram[filename] = vram_usages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3d38bf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "from pycocoevalcap.cider.cider import Cider\n",
    "from pycocoevalcap.spice.spice import Spice\n",
    "from pycocoevalcap.tokenizer.ptbtokenizer import PTBTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1974cc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cosine_similarity(reference_captions, generated_caption):\n",
    "    try:\n",
    "        total_score = 0.0\n",
    "        for caption in reference_captions:\n",
    "            ref_embed = sbert_model.encode(caption, convert_to_tensor=True)\n",
    "            gen_embed = sbert_model.encode(generated_caption, convert_to_tensor=True)\n",
    "            score = util.cos_sim(gen_embed, ref_embed).item()\n",
    "            total_score += score\n",
    "        avg_score = total_score / len(reference_captions) if reference_captions else 0.0\n",
    "        return avg_score\n",
    "    except Exception as e:\n",
    "        print(f\"Error computing cosine similarity: {e}\")\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3f9b8529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cider_spice_scores(reference_caption, generated_caption):\n",
    "    refs = {0: [reference_caption if reference_caption else \"\"]}\n",
    "    hypos = {0: [generated_caption if generated_caption else \"\"]}\n",
    "\n",
    "    # print(f\"Generated caption: {generated_caption}\")\n",
    "    # print(f\"Generated hypos: {hypos}\")\n",
    "\n",
    "    ptb = PTBTokenizer()\n",
    "    refs_tok = ptb.tokenize({i: [{\"caption\": c} for c in caps] for i, caps in refs.items()})\n",
    "    hypos_tok = ptb.tokenize({i: [{\"caption\": hypos[i][0]}] for i in hypos})\n",
    "\n",
    "    all_scores = {}\n",
    "\n",
    "    for scorer, name in [(Cider(), \"CIDEr\"), (Spice(), \"SPICE\")]:\n",
    "        try:\n",
    "            avg_score, _ = scorer.compute_score(refs_tok, hypos_tok)\n",
    "            if name == \"SPICE\":\n",
    "                # SPICE returns dicts per image\n",
    "                all_scores[name] = avg_score.get(\"All\", {}).get(\"f\", 0.0) if isinstance(avg_score, dict) else avg_score\n",
    "            else:\n",
    "                all_scores[name] = avg_score\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] {name} scoring failed: {e}\")\n",
    "            all_scores[name] = 0.0\n",
    "\n",
    "    return all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "57f4d517-34af-4a79-bb29-25613a22c9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cider import Cider\n",
    "\n",
    "PICKLE_PATH = \"/workspace/data/cardd-df.p\"\n",
    "\n",
    "def compute_cider2_score(reference_caption, generated_caption):\n",
    "    \"\"\"\n",
    "    Computes CIDEr score using new evaluate_cider logic with precomputed DF pickle.\n",
    "\n",
    "    Args:\n",
    "        reference_caption (str or list): Ground truth caption(s)\n",
    "        generated_caption (str): Model output\n",
    "\n",
    "    Returns:\n",
    "        float: CIDEr score (averaged if multiple refs)\n",
    "    \"\"\"\n",
    "    refs = {\"0\": reference_caption if isinstance(reference_caption, list) else [reference_caption]}\n",
    "    hypos = [{\"image_id\": \"0\", \"caption\": [generated_caption]}]  # Fix: caption should be a list\n",
    "\n",
    "    cider = Cider()\n",
    "    score, _ = cider.compute_score(refs, hypos, PICKLE_PATH)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "035e2bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_all_metrics(reference_caption, generated_caption):\n",
    "    cider_spice_scores = compute_cider_spice_scores(reference_caption, generated_caption)\n",
    "    cosine_sim = compute_cosine_similarity([reference_caption], generated_caption)\n",
    "    cider2 = compute_cider2_score(reference_caption, generated_caption)\n",
    "\n",
    "    return {\n",
    "        \"cosine_similarity\": round(cosine_sim, 4),\n",
    "        #\"CIDEr\": round(cider_spice_scores.get(\"CIDEr\", 0.0), 4),\n",
    "        \"SPICE\": round(cider_spice_scores.get(\"SPICE\", 0.0), 4),\n",
    "        \"CIDEr\": round(cider2, 4)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e8b2100b-1268-4fe2-816a-c46a3ed0cbb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Evaluating image: 000404.jpg | Reference Caption:\n",
      "The car exhibits significant damage. The front hood area shows a large dent with visible deformation and creasing. The headlight on the passenger's side is broken, with the lamp housing shattered and the bulb exposed. The front bumper also has a dent near the grille, and the grille itself appears to be slightly misaligned. The passenger side headlight is intact but the surrounding area has a dent. The tire on the driver's side appears to be flat. No scratches, cracks, or shattered glass are present. The overall condition of the car is severely compromised due to these damages.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 112 tokens at 1308.55 tokens per second.\n",
      "PTBTokenizer tokenized 54 tokens at 1248.22 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.7 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [5.430 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"the car exhibits significant damage the front hood area shows a large dent with visible deformation and creasing the headlight on the passenger 's side is broken with the lamp housing shattered and the bulb exposed the front bumper also has a dent near the grille and the grille itself appears to be slightly misaligned the passenger side headlight is intact but the surrounding area has a dent the tire on the driver 's side appears to be flat no scratches cracks or shattered glass are present the overall condition of the car is severely compromised due to these damages\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [1.73 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.26 s\n",
      "📝 Prompt Run 1 | CIDEr: 5.3422 | SPICE: 0.0 | CosSim: 0.185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 112 tokens at 2757.11 tokens per second.\n",
      "PTBTokenizer tokenized 54 tokens at 1402.41 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [5.947 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"the car exhibits significant damage the front hood area shows a large dent with visible deformation and creasing the headlight on the passenger 's side is broken with the lamp housing shattered and the bulb exposed the front bumper also has a dent near the grille and the grille itself appears to be slightly misaligned the passenger side headlight is intact but the surrounding area has a dent the tire on the driver 's side appears to be flat no scratches cracks or shattered glass are present the overall condition of the car is severely compromised due to these damages\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 11.46 s\n",
      "📝 Prompt Run 2 | CIDEr: 5.3422 | SPICE: 0.0 | CosSim: 0.185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 112 tokens at 2425.58 tokens per second.\n",
      "PTBTokenizer tokenized 39 tokens at 1024.56 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [5.654 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"the car exhibits significant damage the front hood area shows a large dent with visible deformation and creasing the headlight on the passenger 's side is broken with the lamp housing shattered and the bulb exposed the front bumper also has a dent near the grille and the grille itself appears to be slightly misaligned the passenger side headlight is intact but the surrounding area has a dent the tire on the driver 's side appears to be flat no scratches cracks or shattered glass are present the overall condition of the car is severely compromised due to these damages\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [0.278 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 11.75 s\n",
      "📝 Prompt Run 3 | CIDEr: 0.5702 | SPICE: 0.0317 | CosSim: 0.4061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 112 tokens at 2815.74 tokens per second.\n",
      "PTBTokenizer tokenized 39 tokens at 869.45 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.4 sec].\n",
      "Threads( StanfordCoreNLP ) [5.945 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"the car exhibits significant damage the front hood area shows a large dent with visible deformation and creasing the headlight on the passenger 's side is broken with the lamp housing shattered and the bulb exposed the front bumper also has a dent near the grille and the grille itself appears to be slightly misaligned the passenger side headlight is intact but the surrounding area has a dent the tire on the driver 's side appears to be flat no scratches cracks or shattered glass are present the overall condition of the car is severely compromised due to these damages\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 11.19 s\n",
      "📝 Prompt Run 4 | CIDEr: 0.5702 | SPICE: 0.0317 | CosSim: 0.4061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 112 tokens at 2780.49 tokens per second.\n",
      "PTBTokenizer tokenized 90 tokens at 2348.21 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [6.407 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"the car exhibits significant damage the front hood area shows a large dent with visible deformation and creasing the headlight on the passenger 's side is broken with the lamp housing shattered and the bulb exposed the front bumper also has a dent near the grille and the grille itself appears to be slightly misaligned the passenger side headlight is intact but the surrounding area has a dent the tire on the driver 's side appears to be flat no scratches cracks or shattered glass are present the overall condition of the car is severely compromised due to these damages\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [4.93 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.38 s\n",
      "📝 Prompt Run 5 | CIDEr: 1.1607 | SPICE: 0.0455 | CosSim: 0.3116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 112 tokens at 2070.83 tokens per second.\n",
      "PTBTokenizer tokenized 90 tokens at 2280.74 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [6.75 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"the car exhibits significant damage the front hood area shows a large dent with visible deformation and creasing the headlight on the passenger 's side is broken with the lamp housing shattered and the bulb exposed the front bumper also has a dent near the grille and the grille itself appears to be slightly misaligned the passenger side headlight is intact but the surrounding area has a dent the tire on the driver 's side appears to be flat no scratches cracks or shattered glass are present the overall condition of the car is severely compromised due to these damages\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 11.97 s\n",
      "📝 Prompt Run 6 | CIDEr: 1.1607 | SPICE: 0.0455 | CosSim: 0.3116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 112 tokens at 2769.10 tokens per second.\n",
      "PTBTokenizer tokenized 48 tokens at 976.79 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [5.893 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"the car exhibits significant damage the front hood area shows a large dent with visible deformation and creasing the headlight on the passenger 's side is broken with the lamp housing shattered and the bulb exposed the front bumper also has a dent near the grille and the grille itself appears to be slightly misaligned the passenger side headlight is intact but the surrounding area has a dent the tire on the driver 's side appears to be flat no scratches cracks or shattered glass are present the overall condition of the car is severely compromised due to these damages\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [0.815 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 12.22 s\n",
      "📝 Prompt Run 7 | CIDEr: 3.3462 | SPICE: 0.0274 | CosSim: 0.2931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 112 tokens at 2601.21 tokens per second.\n",
      "PTBTokenizer tokenized 48 tokens at 1251.25 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [6.261 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"the car exhibits significant damage the front hood area shows a large dent with visible deformation and creasing the headlight on the passenger 's side is broken with the lamp housing shattered and the bulb exposed the front bumper also has a dent near the grille and the grille itself appears to be slightly misaligned the passenger side headlight is intact but the surrounding area has a dent the tire on the driver 's side appears to be flat no scratches cracks or shattered glass are present the overall condition of the car is severely compromised due to these damages\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 12.11 s\n",
      "📝 Prompt Run 8 | CIDEr: 3.3462 | SPICE: 0.0274 | CosSim: 0.2931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 112 tokens at 2655.50 tokens per second.\n",
      "May 15, 2025 6:14:38 PM edu.stanford.nlp.process.PTBLexer next\n",
      "WARNING: Untokenizable: � (U+FFFD, decimal: 65533)\n",
      "PTBTokenizer tokenized 48 tokens at 873.70 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [5.706 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"the car exhibits significant damage the front hood area shows a large dent with visible deformation and creasing the headlight on the passenger 's side is broken with the lamp housing shattered and the bulb exposed the front bumper also has a dent near the grille and the grille itself appears to be slightly misaligned the passenger side headlight is intact but the surrounding area has a dent the tire on the driver 's side appears to be flat no scratches cracks or shattered glass are present the overall condition of the car is severely compromised due to these damages\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [0.594 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 12.31 s\n",
      "📝 Prompt Run 9 | CIDEr: 5.8958 | SPICE: 0.0286 | CosSim: 0.5898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 112 tokens at 2053.44 tokens per second.\n",
      "May 15, 2025 6:14:51 PM edu.stanford.nlp.process.PTBLexer next\n",
      "WARNING: Untokenizable: � (U+FFFD, decimal: 65533)\n",
      "PTBTokenizer tokenized 48 tokens at 822.55 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [6.61 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"the car exhibits significant damage the front hood area shows a large dent with visible deformation and creasing the headlight on the passenger 's side is broken with the lamp housing shattered and the bulb exposed the front bumper also has a dent near the grille and the grille itself appears to be slightly misaligned the passenger side headlight is intact but the surrounding area has a dent the tire on the driver 's side appears to be flat no scratches cracks or shattered glass are present the overall condition of the car is severely compromised due to these damages\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 12.07 s\n",
      "📝 Prompt Run 10 | CIDEr: 5.8958 | SPICE: 0.0286 | CosSim: 0.5898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 112 tokens at 2783.94 tokens per second.\n",
      "PTBTokenizer tokenized 42 tokens at 709.60 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [5.879 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"the car exhibits significant damage the front hood area shows a large dent with visible deformation and creasing the headlight on the passenger 's side is broken with the lamp housing shattered and the bulb exposed the front bumper also has a dent near the grille and the grille itself appears to be slightly misaligned the passenger side headlight is intact but the surrounding area has a dent the tire on the driver 's side appears to be flat no scratches cracks or shattered glass are present the overall condition of the car is severely compromised due to these damages\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [0.309 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 12.27 s\n",
      "📝 Prompt Run 11 | CIDEr: 1.1225 | SPICE: 0.0 | CosSim: 0.5004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 112 tokens at 2748.72 tokens per second.\n",
      "PTBTokenizer tokenized 42 tokens at 736.67 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [5.416 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"the car exhibits significant damage the front hood area shows a large dent with visible deformation and creasing the headlight on the passenger 's side is broken with the lamp housing shattered and the bulb exposed the front bumper also has a dent near the grille and the grille itself appears to be slightly misaligned the passenger side headlight is intact but the surrounding area has a dent the tire on the driver 's side appears to be flat no scratches cracks or shattered glass are present the overall condition of the car is severely compromised due to these damages\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 11.14 s\n",
      "📝 Prompt Run 12 | CIDEr: 1.1225 | SPICE: 0.0 | CosSim: 0.5004\n",
      "\n",
      "🔍 Evaluating image: 000422.jpg | Reference Caption:\n",
      "The car exhibits significant damage to its front section. The front fender and door area show extensive dents and deformation, indicating a severe impact. The front bumper is detached and damaged, with visible internal components exposed. A scratch is present on the lower part of the fender. The front wheel well area is also compromised, with structural damage evident. \n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 67 tokens at 1705.09 tokens per second.\n",
      "PTBTokenizer tokenized 49 tokens at 1260.86 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.6 sec].\n",
      "Threads( StanfordCoreNLP ) [0.954 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.500 s\n",
      "📝 Prompt Run 1 | CIDEr: 2.9109 | SPICE: 0.0 | CosSim: 0.1561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 67 tokens at 1655.34 tokens per second.\n",
      "PTBTokenizer tokenized 49 tokens at 981.56 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 695.7 ms\n",
      "📝 Prompt Run 2 | CIDEr: 2.9109 | SPICE: 0.0 | CosSim: 0.1561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 67 tokens at 1675.96 tokens per second.\n",
      "PTBTokenizer tokenized 51 tokens at 1309.24 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [0.901 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.508 s\n",
      "📝 Prompt Run 3 | CIDEr: 2.2678 | SPICE: 0.0323 | CosSim: 0.471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 67 tokens at 1363.08 tokens per second.\n",
      "PTBTokenizer tokenized 51 tokens at 1284.09 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 707.5 ms\n",
      "📝 Prompt Run 4 | CIDEr: 2.2678 | SPICE: 0.0323 | CosSim: 0.471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 67 tokens at 1423.14 tokens per second.\n",
      "May 15, 2025 6:15:45 PM edu.stanford.nlp.process.PTBLexer next\n",
      "WARNING: Untokenizable: � (U+FFFD, decimal: 65533)\n",
      "PTBTokenizer tokenized 72 tokens at 1326.79 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [2.306 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 8.712 s\n",
      "📝 Prompt Run 5 | CIDEr: 2.0353 | SPICE: 0.0294 | CosSim: 0.2461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 67 tokens at 1772.67 tokens per second.\n",
      "May 15, 2025 6:15:55 PM edu.stanford.nlp.process.PTBLexer next\n",
      "WARNING: Untokenizable: � (U+FFFD, decimal: 65533)\n",
      "PTBTokenizer tokenized 72 tokens at 1270.39 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 804.6 ms\n",
      "📝 Prompt Run 6 | CIDEr: 2.0353 | SPICE: 0.0294 | CosSim: 0.2461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 67 tokens at 1298.36 tokens per second.\n",
      "PTBTokenizer tokenized 44 tokens at 979.11 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [1.293 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.833 s\n",
      "📝 Prompt Run 7 | CIDEr: 1.0282 | SPICE: 0.0702 | CosSim: 0.3189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 67 tokens at 1545.36 tokens per second.\n",
      "PTBTokenizer tokenized 44 tokens at 1050.70 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 773.2 ms\n",
      "📝 Prompt Run 8 | CIDEr: 1.0282 | SPICE: 0.0702 | CosSim: 0.3189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 67 tokens at 1217.23 tokens per second.\n",
      "PTBTokenizer tokenized 75 tokens at 1770.38 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [2.438 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 9.241 s\n",
      "📝 Prompt Run 9 | CIDEr: 2.3648 | SPICE: 0.0328 | CosSim: 0.4621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 67 tokens at 1653.13 tokens per second.\n",
      "PTBTokenizer tokenized 75 tokens at 1803.78 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 732.0 ms\n",
      "📝 Prompt Run 10 | CIDEr: 2.3648 | SPICE: 0.0328 | CosSim: 0.4621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 67 tokens at 1620.98 tokens per second.\n",
      "PTBTokenizer tokenized 137 tokens at 3646.55 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [4.691 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 10.62 s\n",
      "📝 Prompt Run 11 | CIDEr: 0.248 | SPICE: 0.0308 | CosSim: 0.5205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 67 tokens at 1691.96 tokens per second.\n",
      "PTBTokenizer tokenized 137 tokens at 3382.47 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 768.7 ms\n",
      "📝 Prompt Run 12 | CIDEr: 0.248 | SPICE: 0.0308 | CosSim: 0.5205\n",
      "\n",
      "🔍 Evaluating image: 000433.jpg | Reference Caption:\n",
      "The car exhibits significant damage to the windshield, which is extensively shattered. The roof also shows signs of damage, with a noticeable dent present. \n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 28 tokens at 696.57 tokens per second.\n",
      "PTBTokenizer tokenized 40 tokens at 1056.45 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [0.859 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.795 s\n",
      "📝 Prompt Run 1 | CIDEr: 2.2237 | SPICE: 0.0 | CosSim: 0.1072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 28 tokens at 716.33 tokens per second.\n",
      "PTBTokenizer tokenized 40 tokens at 1058.20 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 777.3 ms\n",
      "📝 Prompt Run 2 | CIDEr: 2.2237 | SPICE: 0.0 | CosSim: 0.1072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 28 tokens at 651.97 tokens per second.\n",
      "PTBTokenizer tokenized 91 tokens at 1934.92 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [2.910 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 9.764 s\n",
      "📝 Prompt Run 3 | CIDEr: 2.7416 | SPICE: 0.0 | CosSim: 0.4018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 28 tokens at 366.11 tokens per second.\n",
      "PTBTokenizer tokenized 91 tokens at 1915.31 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 702.5 ms\n",
      "📝 Prompt Run 4 | CIDEr: 2.7416 | SPICE: 0.0 | CosSim: 0.4018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 28 tokens at 732.07 tokens per second.\n",
      "PTBTokenizer tokenized 102 tokens at 1737.72 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [6.435 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 12.25 s\n",
      "📝 Prompt Run 5 | CIDEr: 3.103 | SPICE: 0.0435 | CosSim: 0.5085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 28 tokens at 710.08 tokens per second.\n",
      "PTBTokenizer tokenized 102 tokens at 2543.71 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 666.4 ms\n",
      "📝 Prompt Run 6 | CIDEr: 3.103 | SPICE: 0.0435 | CosSim: 0.5085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 28 tokens at 628.88 tokens per second.\n",
      "May 15, 2025 6:17:03 PM edu.stanford.nlp.process.PTBLexer next\n",
      "WARNING: Untokenizable: � (U+FFFD, decimal: 65533)\n",
      "PTBTokenizer tokenized 61 tokens at 1149.93 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [1.698 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 7.187 s\n",
      "📝 Prompt Run 7 | CIDEr: 1.8511 | SPICE: 0.0417 | CosSim: 0.3277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 28 tokens at 717.26 tokens per second.\n",
      "May 15, 2025 6:17:11 PM edu.stanford.nlp.process.PTBLexer next\n",
      "WARNING: Untokenizable: � (U+FFFD, decimal: 65533)\n",
      "PTBTokenizer tokenized 61 tokens at 1161.76 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 705.6 ms\n",
      "📝 Prompt Run 8 | CIDEr: 1.8511 | SPICE: 0.0417 | CosSim: 0.3277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 28 tokens at 712.14 tokens per second.\n",
      "PTBTokenizer tokenized 114 tokens at 2801.72 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [6.283 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 12.10 s\n",
      "📝 Prompt Run 9 | CIDEr: 2.2158 | SPICE: 0.0328 | CosSim: 0.5993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 28 tokens at 710.68 tokens per second.\n",
      "PTBTokenizer tokenized 114 tokens at 2646.26 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 715.4 ms\n",
      "📝 Prompt Run 10 | CIDEr: 2.2158 | SPICE: 0.0328 | CosSim: 0.5993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 28 tokens at 712.63 tokens per second.\n",
      "PTBTokenizer tokenized 93 tokens at 2269.83 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [2.685 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 8.954 s\n",
      "📝 Prompt Run 11 | CIDEr: 0.7191 | SPICE: 0.0417 | CosSim: 0.5297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 28 tokens at 780.91 tokens per second.\n",
      "PTBTokenizer tokenized 93 tokens at 2532.08 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 655.7 ms\n",
      "📝 Prompt Run 12 | CIDEr: 0.7191 | SPICE: 0.0417 | CosSim: 0.5297\n",
      "\n",
      "🔍 Evaluating image: 000481.jpg | Reference Caption:\n",
      "The car exhibits visible damage including a scratch on the lower side panel near the front wheel, with moderate severity affecting the paint and surface. Additionally, a more extensive scratch is present on the lower front bumper, also near the front wheel, showing significant paint damage.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 52 tokens at 1043.97 tokens per second.\n",
      "PTBTokenizer tokenized 31 tokens at 937.61 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [0.764 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.593 s\n",
      "📝 Prompt Run 1 | CIDEr: 2.9354 | SPICE: 0.0 | CosSim: 0.0707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 52 tokens at 1396.90 tokens per second.\n",
      "PTBTokenizer tokenized 31 tokens at 834.22 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 689.6 ms\n",
      "📝 Prompt Run 2 | CIDEr: 2.9354 | SPICE: 0.0 | CosSim: 0.0707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 52 tokens at 1277.63 tokens per second.\n",
      "PTBTokenizer tokenized 64 tokens at 1665.28 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [0.815 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.766 s\n",
      "📝 Prompt Run 3 | CIDEr: 0.1348 | SPICE: 0.0377 | CosSim: 0.3319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 52 tokens at 1284.82 tokens per second.\n",
      "PTBTokenizer tokenized 64 tokens at 1557.11 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 705.5 ms\n",
      "📝 Prompt Run 4 | CIDEr: 0.1348 | SPICE: 0.0377 | CosSim: 0.3319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 52 tokens at 1108.99 tokens per second.\n",
      "PTBTokenizer tokenized 116 tokens at 2771.37 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [12.70 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.31 s\n",
      "📝 Prompt Run 5 | CIDEr: 1.231 | SPICE: 0.0615 | CosSim: 0.4369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 52 tokens at 1079.92 tokens per second.\n",
      "PTBTokenizer tokenized 116 tokens at 2643.16 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 703.8 ms\n",
      "📝 Prompt Run 6 | CIDEr: 1.231 | SPICE: 0.0615 | CosSim: 0.4369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 52 tokens at 902.17 tokens per second.\n",
      "PTBTokenizer tokenized 142 tokens at 3504.78 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [12.953 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 18.74 s\n",
      "📝 Prompt Run 7 | CIDEr: 4.2462 | SPICE: 0.0377 | CosSim: 0.2275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 52 tokens at 1306.10 tokens per second.\n",
      "PTBTokenizer tokenized 142 tokens at 3582.30 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 713.5 ms\n",
      "📝 Prompt Run 8 | CIDEr: 4.2462 | SPICE: 0.0377 | CosSim: 0.2275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 52 tokens at 1152.98 tokens per second.\n",
      "PTBTokenizer tokenized 72 tokens at 1084.85 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [2.190 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 9.039 s\n",
      "📝 Prompt Run 9 | CIDEr: 1.917 | SPICE: 0.0645 | CosSim: 0.5621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 52 tokens at 1297.96 tokens per second.\n",
      "PTBTokenizer tokenized 72 tokens at 1800.57 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 820.8 ms\n",
      "📝 Prompt Run 10 | CIDEr: 1.917 | SPICE: 0.0645 | CosSim: 0.5621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 52 tokens at 1280.28 tokens per second.\n",
      "PTBTokenizer tokenized 123 tokens at 2953.46 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [4.529 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 11.22 s\n",
      "📝 Prompt Run 11 | CIDEr: 0.4076 | SPICE: 0.0286 | CosSim: 0.3424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 52 tokens at 1340.07 tokens per second.\n",
      "PTBTokenizer tokenized 123 tokens at 3222.04 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 815.5 ms\n",
      "📝 Prompt Run 12 | CIDEr: 0.4076 | SPICE: 0.0286 | CosSim: 0.3424\n",
      "\n",
      "🔍 Evaluating image: 000520.jpg | Reference Caption:\n",
      "The car exhibits multiple areas of damage. A significant dent is present on the front fender, extending from the headlight area towards the wheel well. A smaller dent is located near the front bumper, adjacent to the headlight. A scratch is visible on the lower part of the front bumper. \n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 56 tokens at 1456.12 tokens per second.\n",
      "PTBTokenizer tokenized 20 tokens at 529.86 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [0.679 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.655 s\n",
      "📝 Prompt Run 1 | CIDEr: 1.0301 | SPICE: 0.0 | CosSim: 0.0567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 56 tokens at 1350.40 tokens per second.\n",
      "PTBTokenizer tokenized 20 tokens at 466.75 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 675.4 ms\n",
      "📝 Prompt Run 2 | CIDEr: 1.0301 | SPICE: 0.0 | CosSim: 0.0567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 56 tokens at 1454.93 tokens per second.\n",
      "PTBTokenizer tokenized 62 tokens at 1416.51 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [1.224 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 7.100 s\n",
      "📝 Prompt Run 3 | CIDEr: 3.7905 | SPICE: 0.0833 | CosSim: 0.4014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 56 tokens at 1420.52 tokens per second.\n",
      "PTBTokenizer tokenized 62 tokens at 1623.45 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 700.6 ms\n",
      "📝 Prompt Run 4 | CIDEr: 3.7905 | SPICE: 0.0833 | CosSim: 0.4014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 56 tokens at 1225.75 tokens per second.\n",
      "PTBTokenizer tokenized 82 tokens at 2069.75 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [4.597 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 10.55 s\n",
      "📝 Prompt Run 5 | CIDEr: 2.8149 | SPICE: 0.0645 | CosSim: 0.3681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 56 tokens at 1429.01 tokens per second.\n",
      "PTBTokenizer tokenized 82 tokens at 2036.26 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 694.7 ms\n",
      "📝 Prompt Run 6 | CIDEr: 2.8149 | SPICE: 0.0645 | CosSim: 0.3681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 56 tokens at 1078.38 tokens per second.\n",
      "May 15, 2025 6:19:27 PM edu.stanford.nlp.process.PTBLexer next\n",
      "WARNING: Untokenizable: � (U+FFFD, decimal: 65533)\n",
      "PTBTokenizer tokenized 78 tokens at 1489.58 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [2.553 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 9.432 s\n",
      "📝 Prompt Run 7 | CIDEr: 1.5304 | SPICE: 0.0308 | CosSim: 0.2219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 56 tokens at 1425.33 tokens per second.\n",
      "May 15, 2025 6:19:37 PM edu.stanford.nlp.process.PTBLexer next\n",
      "WARNING: Untokenizable: � (U+FFFD, decimal: 65533)\n",
      "PTBTokenizer tokenized 78 tokens at 1430.10 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 722.1 ms\n",
      "📝 Prompt Run 8 | CIDEr: 1.5304 | SPICE: 0.0308 | CosSim: 0.2219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 56 tokens at 1118.14 tokens per second.\n",
      "May 15, 2025 6:19:38 PM edu.stanford.nlp.process.PTBLexer next\n",
      "WARNING: Untokenizable: � (U+FFFD, decimal: 65533)\n",
      "PTBTokenizer tokenized 119 tokens at 2244.57 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [4.379 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 10.37 s\n",
      "📝 Prompt Run 9 | CIDEr: 3.7073 | SPICE: 0.0303 | CosSim: 0.3431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 56 tokens at 1341.69 tokens per second.\n",
      "May 15, 2025 6:19:49 PM edu.stanford.nlp.process.PTBLexer next\n",
      "WARNING: Untokenizable: � (U+FFFD, decimal: 65533)\n",
      "PTBTokenizer tokenized 119 tokens at 2096.98 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 809.1 ms\n",
      "📝 Prompt Run 10 | CIDEr: 3.7073 | SPICE: 0.0303 | CosSim: 0.3431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 56 tokens at 1409.86 tokens per second.\n",
      "May 15, 2025 6:19:51 PM edu.stanford.nlp.process.PTBLexer next\n",
      "WARNING: Untokenizable: � (U+FFFD, decimal: 65533)\n",
      "PTBTokenizer tokenized 58 tokens at 900.18 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [1.231 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 7.197 s\n",
      "📝 Prompt Run 11 | CIDEr: 0.3826 | SPICE: 0.0 | CosSim: 0.3467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 56 tokens at 1351.17 tokens per second.\n",
      "May 15, 2025 6:19:58 PM edu.stanford.nlp.process.PTBLexer next\n",
      "WARNING: Untokenizable: � (U+FFFD, decimal: 65533)\n",
      "PTBTokenizer tokenized 58 tokens at 959.46 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 766.3 ms\n",
      "📝 Prompt Run 12 | CIDEr: 0.3826 | SPICE: 0.0 | CosSim: 0.3467\n",
      "\n",
      "🔍 Evaluating image: 000541.jpg | Reference Caption:\n",
      "The car exhibits significant damage. The rear bumper shows multiple scratches along its lower edge, indicating surface-level abrasions. The rear fender also displays a dent, suggesting a moderate impact that has deformed the panel. The damage to the taillight and fender is severe, affecting both the aesthetics and structural integrity of the vehicle.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 60 tokens at 1327.25 tokens per second.\n",
      "PTBTokenizer tokenized 12 tokens at 276.46 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [0.337 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.245 s\n",
      "📝 Prompt Run 1 | CIDEr: 1.6398 | SPICE: 0.0 | CosSim: 0.129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 60 tokens at 1165.73 tokens per second.\n",
      "PTBTokenizer tokenized 12 tokens at 251.77 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 726.5 ms\n",
      "📝 Prompt Run 2 | CIDEr: 1.6398 | SPICE: 0.0 | CosSim: 0.129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 60 tokens at 1183.19 tokens per second.\n",
      "PTBTokenizer tokenized 95 tokens at 2268.07 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [2.87 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 7.801 s\n",
      "📝 Prompt Run 3 | CIDEr: 0.5302 | SPICE: 0.0377 | CosSim: 0.3268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 60 tokens at 1453.80 tokens per second.\n",
      "PTBTokenizer tokenized 95 tokens at 1853.80 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 688.8 ms\n",
      "📝 Prompt Run 4 | CIDEr: 0.5302 | SPICE: 0.0377 | CosSim: 0.3268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 60 tokens at 1488.69 tokens per second.\n",
      "PTBTokenizer tokenized 36 tokens at 922.59 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [1.14 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.901 s\n",
      "📝 Prompt Run 5 | CIDEr: 2.8484 | SPICE: 0.0364 | CosSim: 0.3393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 60 tokens at 1529.53 tokens per second.\n",
      "PTBTokenizer tokenized 36 tokens at 932.54 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 702.1 ms\n",
      "📝 Prompt Run 6 | CIDEr: 2.8484 | SPICE: 0.0364 | CosSim: 0.3393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 60 tokens at 1554.00 tokens per second.\n",
      "PTBTokenizer tokenized 22 tokens at 548.70 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [0.603 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.499 s\n",
      "📝 Prompt Run 7 | CIDEr: 2.1828 | SPICE: 0.0465 | CosSim: 0.2624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 60 tokens at 1109.62 tokens per second.\n",
      "PTBTokenizer tokenized 22 tokens at 585.03 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 681.4 ms\n",
      "📝 Prompt Run 8 | CIDEr: 2.1828 | SPICE: 0.0465 | CosSim: 0.2624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 60 tokens at 1549.83 tokens per second.\n",
      "PTBTokenizer tokenized 40 tokens at 842.55 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [0.919 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.366 s\n",
      "📝 Prompt Run 9 | CIDEr: 3.7626 | SPICE: 0.0377 | CosSim: 0.6124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 60 tokens at 1048.63 tokens per second.\n",
      "PTBTokenizer tokenized 40 tokens at 1004.37 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 707.4 ms\n",
      "📝 Prompt Run 10 | CIDEr: 3.7626 | SPICE: 0.0377 | CosSim: 0.6124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 60 tokens at 1580.26 tokens per second.\n",
      "PTBTokenizer tokenized 69 tokens at 1832.76 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [1.836 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 7.401 s\n",
      "📝 Prompt Run 11 | CIDEr: 3.3542 | SPICE: 0.0377 | CosSim: 0.5492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 60 tokens at 1552.21 tokens per second.\n",
      "PTBTokenizer tokenized 69 tokens at 1763.86 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 689.5 ms\n",
      "📝 Prompt Run 12 | CIDEr: 3.3542 | SPICE: 0.0377 | CosSim: 0.5492\n",
      "\n",
      "🔍 Evaluating image: 000698.jpg | Reference Caption:\n",
      "The car exhibits significant damage. The front right headlight is broken, exposing internal components. A dent is present on the front right fender, with visible deformation. Multiple scratches are scattered across the front left fender and the front bumper, varying in length and depth. A crack is located on the front right fender, near the headlight.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 65 tokens at 1627.18 tokens per second.\n",
      "PTBTokenizer tokenized 6 tokens at 161.35 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [0.297 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.122 s\n",
      "📝 Prompt Run 1 | CIDEr: 1.063 | SPICE: 0.0 | CosSim: 0.0644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 65 tokens at 1448.12 tokens per second.\n",
      "PTBTokenizer tokenized 6 tokens at 125.85 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 677.9 ms\n",
      "📝 Prompt Run 2 | CIDEr: 1.063 | SPICE: 0.0 | CosSim: 0.0644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 65 tokens at 1329.18 tokens per second.\n",
      "PTBTokenizer tokenized 36 tokens at 849.37 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [0.505 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.154 s\n",
      "📝 Prompt Run 3 | CIDEr: 0.4224 | SPICE: 0.0 | CosSim: 0.3501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 65 tokens at 1718.92 tokens per second.\n",
      "PTBTokenizer tokenized 36 tokens at 927.97 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 691.2 ms\n",
      "📝 Prompt Run 4 | CIDEr: 0.4224 | SPICE: 0.0 | CosSim: 0.3501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 65 tokens at 1668.30 tokens per second.\n",
      "PTBTokenizer tokenized 73 tokens at 1877.28 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [2.858 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 9.503 s\n",
      "📝 Prompt Run 5 | CIDEr: 2.9708 | SPICE: 0.0286 | CosSim: 0.2731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 65 tokens at 1599.30 tokens per second.\n",
      "PTBTokenizer tokenized 73 tokens at 1506.20 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 620.4 ms\n",
      "📝 Prompt Run 6 | CIDEr: 2.9708 | SPICE: 0.0286 | CosSim: 0.2731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 65 tokens at 1352.43 tokens per second.\n",
      "PTBTokenizer tokenized 104 tokens at 2714.71 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [6.170 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 11.64 s\n",
      "📝 Prompt Run 7 | CIDEr: 1.0423 | SPICE: 0.0303 | CosSim: 0.2116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 65 tokens at 1515.46 tokens per second.\n",
      "PTBTokenizer tokenized 104 tokens at 2641.06 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 754.5 ms\n",
      "📝 Prompt Run 8 | CIDEr: 1.0423 | SPICE: 0.0303 | CosSim: 0.2116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 65 tokens at 1464.99 tokens per second.\n",
      "PTBTokenizer tokenized 78 tokens at 1909.75 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [1.961 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 8.492 s\n",
      "📝 Prompt Run 9 | CIDEr: 3.6598 | SPICE: 0.0299 | CosSim: 0.3526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 65 tokens at 1393.90 tokens per second.\n",
      "PTBTokenizer tokenized 78 tokens at 1928.13 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 777.4 ms\n",
      "📝 Prompt Run 10 | CIDEr: 3.6598 | SPICE: 0.0299 | CosSim: 0.3526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 65 tokens at 1566.51 tokens per second.\n",
      "PTBTokenizer tokenized 116 tokens at 2419.15 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [19.659 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 25.30 s\n",
      "📝 Prompt Run 11 | CIDEr: 0.6315 | SPICE: 0.0323 | CosSim: 0.4422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 65 tokens at 1625.32 tokens per second.\n",
      "PTBTokenizer tokenized 116 tokens at 2453.90 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 715.2 ms\n",
      "📝 Prompt Run 12 | CIDEr: 0.6315 | SPICE: 0.0323 | CosSim: 0.4422\n",
      "\n",
      "🔍 Evaluating image: 000740.jpg | Reference Caption:\n",
      "The car exhibits significant wear and tear. The tire is flat, indicating a loss of air pressure and rendering it unusable. The bodywork around the wheel well shows extensive paint chipping and rust, suggesting prolonged exposure to the elements and lack of maintenance. The wheel itself appears to be in a worn condition, with visible dirt and grime. The overall condition of the car is poor, with clear signs of neglect and deterioration.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 82 tokens at 1967.00 tokens per second.\n",
      "PTBTokenizer tokenized 106 tokens at 2461.80 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.3 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.6 sec].\n",
      "Threads( StanfordCoreNLP ) [4.860 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 10.04 s\n",
      "📝 Prompt Run 1 | CIDEr: 2.583 | SPICE: 0.0 | CosSim: 0.2378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 82 tokens at 1519.82 tokens per second.\n",
      "PTBTokenizer tokenized 106 tokens at 2754.28 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 720.2 ms\n",
      "📝 Prompt Run 2 | CIDEr: 2.583 | SPICE: 0.0 | CosSim: 0.2378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 82 tokens at 2013.46 tokens per second.\n",
      "PTBTokenizer tokenized 74 tokens at 1863.37 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [3.50 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 8.795 s\n",
      "📝 Prompt Run 3 | CIDEr: 0.5277 | SPICE: 0.0 | CosSim: 0.2976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 82 tokens at 2021.32 tokens per second.\n",
      "PTBTokenizer tokenized 74 tokens at 1487.14 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 711.7 ms\n",
      "📝 Prompt Run 4 | CIDEr: 0.5277 | SPICE: 0.0 | CosSim: 0.2976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 82 tokens at 2041.10 tokens per second.\n",
      "PTBTokenizer tokenized 78 tokens at 1418.28 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [3.321 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 9.243 s\n",
      "📝 Prompt Run 5 | CIDEr: 1.7606 | SPICE: 0.0357 | CosSim: 0.3304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 82 tokens at 2011.24 tokens per second.\n",
      "PTBTokenizer tokenized 78 tokens at 1810.73 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 621.2 ms\n",
      "📝 Prompt Run 6 | CIDEr: 1.7606 | SPICE: 0.0357 | CosSim: 0.3304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 82 tokens at 1863.02 tokens per second.\n",
      "PTBTokenizer tokenized 108 tokens at 2458.68 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [3.917 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 9.684 s\n",
      "📝 Prompt Run 7 | CIDEr: 0.8814 | SPICE: 0.1754 | CosSim: 0.2488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 82 tokens at 2063.71 tokens per second.\n",
      "PTBTokenizer tokenized 108 tokens at 2249.55 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 717.4 ms\n",
      "📝 Prompt Run 8 | CIDEr: 0.8814 | SPICE: 0.1754 | CosSim: 0.2488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 82 tokens at 1951.61 tokens per second.\n",
      "PTBTokenizer tokenized 56 tokens at 1195.42 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [1.416 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 7.084 s\n",
      "📝 Prompt Run 9 | CIDEr: 4.0754 | SPICE: 0.0299 | CosSim: 0.2695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 82 tokens at 1582.40 tokens per second.\n",
      "PTBTokenizer tokenized 56 tokens at 1316.91 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 784.8 ms\n",
      "📝 Prompt Run 10 | CIDEr: 4.0754 | SPICE: 0.0299 | CosSim: 0.2695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 82 tokens at 1983.19 tokens per second.\n",
      "PTBTokenizer tokenized 63 tokens at 1647.62 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [1.477 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 7.279 s\n",
      "📝 Prompt Run 11 | CIDEr: 2.6275 | SPICE: 0.0606 | CosSim: 0.4512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 82 tokens at 1631.70 tokens per second.\n",
      "PTBTokenizer tokenized 63 tokens at 1549.16 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 781.6 ms\n",
      "📝 Prompt Run 12 | CIDEr: 2.6275 | SPICE: 0.0606 | CosSim: 0.4512\n",
      "\n",
      "🔍 Evaluating image: 000869.jpg | Reference Caption:\n",
      "The car exhibits a flat tire, with the tire visibly deflated and resting on the ground. The wheel rim is exposed, showing signs of wear and dirt. The surrounding area of the tire, including the fender and adjacent body panels, shows significant deformation and damage. The fender is bent and misaligned, with visible creases and dents. The body panel near the tire also displays extensive damage, with parts of the metal peeled away and hanging loosely.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 87 tokens at 1754.59 tokens per second.\n",
      "PTBTokenizer tokenized 75 tokens at 1827.18 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [2.342 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 8.389 s\n",
      "📝 Prompt Run 1 | CIDEr: 0.9431 | SPICE: 0.0 | CosSim: 0.2412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 87 tokens at 2258.02 tokens per second.\n",
      "PTBTokenizer tokenized 75 tokens at 1862.19 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 705.1 ms\n",
      "📝 Prompt Run 2 | CIDEr: 0.9431 | SPICE: 0.0 | CosSim: 0.2412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 87 tokens at 2155.11 tokens per second.\n",
      "May 15, 2025 6:23:25 PM edu.stanford.nlp.process.PTBLexer next\n",
      "WARNING: Untokenizable: � (U+FFFD, decimal: 65533)\n",
      "PTBTokenizer tokenized 55 tokens at 814.86 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.6 sec].\n",
      "Threads( StanfordCoreNLP ) [0.964 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.652 s\n",
      "📝 Prompt Run 3 | CIDEr: 1.5505 | SPICE: 0.0308 | CosSim: 0.3566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 87 tokens at 2010.28 tokens per second.\n",
      "May 15, 2025 6:23:32 PM edu.stanford.nlp.process.PTBLexer next\n",
      "WARNING: Untokenizable: � (U+FFFD, decimal: 65533)\n",
      "PTBTokenizer tokenized 55 tokens at 988.70 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 759.9 ms\n",
      "📝 Prompt Run 4 | CIDEr: 1.5505 | SPICE: 0.0308 | CosSim: 0.3566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 87 tokens at 2029.34 tokens per second.\n",
      "May 15, 2025 6:23:33 PM edu.stanford.nlp.process.PTBLexer next\n",
      "WARNING: Untokenizable: � (U+FFFD, decimal: 65533)\n",
      "PTBTokenizer tokenized 64 tokens at 1182.64 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [1.591 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 7.219 s\n",
      "📝 Prompt Run 5 | CIDEr: 2.4877 | SPICE: 0.0278 | CosSim: 0.3856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 87 tokens at 2263.88 tokens per second.\n",
      "May 15, 2025 6:23:41 PM edu.stanford.nlp.process.PTBLexer next\n",
      "WARNING: Untokenizable: � (U+FFFD, decimal: 65533)\n",
      "PTBTokenizer tokenized 64 tokens at 1180.54 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 691.9 ms\n",
      "📝 Prompt Run 6 | CIDEr: 2.4877 | SPICE: 0.0278 | CosSim: 0.3856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 87 tokens at 2097.75 tokens per second.\n",
      "PTBTokenizer tokenized 20 tokens at 521.71 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [0.585 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.304 s\n",
      "📝 Prompt Run 7 | CIDEr: 1.4809 | SPICE: 0.0377 | CosSim: 0.3107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 87 tokens at 2266.45 tokens per second.\n",
      "PTBTokenizer tokenized 20 tokens at 513.82 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 742.2 ms\n",
      "📝 Prompt Run 8 | CIDEr: 1.4809 | SPICE: 0.0377 | CosSim: 0.3107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 87 tokens at 2318.14 tokens per second.\n",
      "May 15, 2025 6:23:50 PM edu.stanford.nlp.process.PTBLexer next\n",
      "WARNING: Untokenizable: � (U+FFFD, decimal: 65533)\n",
      "PTBTokenizer tokenized 55 tokens at 911.37 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [1.394 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.874 s\n",
      "📝 Prompt Run 9 | CIDEr: 2.5397 | SPICE: 0.0303 | CosSim: 0.4458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 87 tokens at 2218.92 tokens per second.\n",
      "May 15, 2025 6:23:58 PM edu.stanford.nlp.process.PTBLexer next\n",
      "WARNING: Untokenizable: � (U+FFFD, decimal: 65533)\n",
      "PTBTokenizer tokenized 55 tokens at 812.08 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 619.3 ms\n",
      "📝 Prompt Run 10 | CIDEr: 2.5397 | SPICE: 0.0303 | CosSim: 0.4458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 87 tokens at 1982.22 tokens per second.\n",
      "PTBTokenizer tokenized 68 tokens at 1684.08 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [1.911 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 7.620 s\n",
      "📝 Prompt Run 11 | CIDEr: 1.1609 | SPICE: 0.0 | CosSim: 0.3323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 87 tokens at 2296.52 tokens per second.\n",
      "PTBTokenizer tokenized 68 tokens at 1327.41 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 681.1 ms\n",
      "📝 Prompt Run 12 | CIDEr: 1.1609 | SPICE: 0.0 | CosSim: 0.3323\n",
      "\n",
      "🔍 Evaluating image: 000889.jpg | Reference Caption:\n",
      "The car exhibits significant damage to the driver's side window, which is shattered extensively. The glass is fragmented and broken, with large pieces missing, indicating a severe impact. \n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 34 tokens at 868.44 tokens per second.\n",
      "PTBTokenizer tokenized 53 tokens at 1240.99 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [1.525 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.922 s\n",
      "📝 Prompt Run 1 | CIDEr: 3.1375 | SPICE: 0.0 | CosSim: 0.1464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 34 tokens at 870.71 tokens per second.\n",
      "PTBTokenizer tokenized 53 tokens at 1214.19 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 684.8 ms\n",
      "📝 Prompt Run 2 | CIDEr: 3.1375 | SPICE: 0.0 | CosSim: 0.1464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 34 tokens at 873.54 tokens per second.\n",
      "PTBTokenizer tokenized 52 tokens at 1279.73 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [1.4 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.791 s\n",
      "📝 Prompt Run 3 | CIDEr: 2.2063 | SPICE: 0.0606 | CosSim: 0.3584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 34 tokens at 742.90 tokens per second.\n",
      "PTBTokenizer tokenized 52 tokens at 1307.88 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 695.1 ms\n",
      "📝 Prompt Run 4 | CIDEr: 2.2063 | SPICE: 0.0606 | CosSim: 0.3584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 34 tokens at 711.79 tokens per second.\n",
      "PTBTokenizer tokenized 126 tokens at 3309.46 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [7.796 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.13 s\n",
      "📝 Prompt Run 5 | CIDEr: 2.0147 | SPICE: 0.0769 | CosSim: 0.2865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 34 tokens at 738.36 tokens per second.\n",
      "PTBTokenizer tokenized 126 tokens at 3275.17 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 712.9 ms\n",
      "📝 Prompt Run 6 | CIDEr: 2.0147 | SPICE: 0.0769 | CosSim: 0.2865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 34 tokens at 761.68 tokens per second.\n",
      "PTBTokenizer tokenized 51 tokens at 1165.71 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.3 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [1.647 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 7.604 s\n",
      "📝 Prompt Run 7 | CIDEr: 1.4011 | SPICE: 0.0435 | CosSim: 0.2248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 34 tokens at 820.47 tokens per second.\n",
      "PTBTokenizer tokenized 51 tokens at 971.57 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 685.4 ms\n",
      "📝 Prompt Run 8 | CIDEr: 1.4011 | SPICE: 0.0435 | CosSim: 0.2248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 34 tokens at 813.59 tokens per second.\n",
      "PTBTokenizer tokenized 102 tokens at 2497.97 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [3.809 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 9.715 s\n",
      "📝 Prompt Run 9 | CIDEr: 2.8918 | SPICE: 0.0308 | CosSim: 0.3675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 34 tokens at 883.39 tokens per second.\n",
      "PTBTokenizer tokenized 102 tokens at 2467.31 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 669.1 ms\n",
      "📝 Prompt Run 10 | CIDEr: 2.8918 | SPICE: 0.0308 | CosSim: 0.3675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 34 tokens at 737.15 tokens per second.\n",
      "PTBTokenizer tokenized 136 tokens at 2517.20 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [6.322 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 12.17 s\n",
      "📝 Prompt Run 11 | CIDEr: 0.132 | SPICE: 0.0 | CosSim: 0.4119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 34 tokens at 829.78 tokens per second.\n",
      "PTBTokenizer tokenized 136 tokens at 3216.18 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 706.8 ms\n",
      "📝 Prompt Run 12 | CIDEr: 0.132 | SPICE: 0.0 | CosSim: 0.4119\n"
     ]
    }
   ],
   "source": [
    "all_metrics_scores = {}\n",
    "\n",
    "for filename, outputs in all_outputs.items():  # filename is used instead of img_id\n",
    "    row = df[df[\"filename\"] == filename]\n",
    "    if row.empty:\n",
    "        print(f\"[WARNING] No ground truth found for filename {filename}\")\n",
    "        continue\n",
    "\n",
    "    ground_truth = row.iloc[0][\"caption\"]  # Single caption only\n",
    "    print(f\"\\n🔍 Evaluating image: {filename} | Reference Caption:\\n{ground_truth}\\n{'-'*80}\")\n",
    "    \n",
    "    scores_for_image = []\n",
    "\n",
    "    for idx, gen_output in enumerate(outputs):  # Expecting 2 runs per image\n",
    "        metrics = evaluate_all_metrics(ground_truth, gen_output)\n",
    "        avg_metrics = {\n",
    "            \"CIDEr\": round(metrics[\"CIDEr\"], 4),\n",
    "            \"SPICE\": round(metrics[\"SPICE\"], 4),\n",
    "            \"cosine_similarity\": round(metrics[\"cosine_similarity\"], 4)\n",
    "        }\n",
    "\n",
    "        print(f\"📝 Prompt Run {idx+1} | CIDEr: {avg_metrics['CIDEr']} | SPICE: {avg_metrics['SPICE']} | CosSim: {avg_metrics['cosine_similarity']}\")\n",
    "        scores_for_image.append(avg_metrics)\n",
    "\n",
    "    all_metrics_scores[filename] = scores_for_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b3dd6bfc-68aa-42d7-be1c-a03006d690db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📸 Image ID: 000404.jpg\n",
      "------------------------------------------------------------\n",
      "                   CIDEr   SPICE  cosine_similarity\n",
      "Prompt 1 (Run 1)  5.3422  0.0000             0.1850\n",
      "Prompt 1 (Run 2)  5.3422  0.0000             0.1850\n",
      "Prompt 2 (Run 1)  0.5702  0.0317             0.4061\n",
      "Prompt 2 (Run 2)  0.5702  0.0317             0.4061\n",
      "Prompt 3 (Run 1)  1.1607  0.0455             0.3116\n",
      "Prompt 3 (Run 2)  1.1607  0.0455             0.3116\n",
      "Prompt 4 (Run 1)  3.3462  0.0274             0.2931\n",
      "Prompt 4 (Run 2)  3.3462  0.0274             0.2931\n",
      "Prompt 5 (Run 1)  5.8958  0.0286             0.5898\n",
      "Prompt 5 (Run 2)  5.8958  0.0286             0.5898\n",
      "Prompt 6 (Run 1)  1.1225  0.0000             0.5004\n",
      "Prompt 6 (Run 2)  1.1225  0.0000             0.5004\n",
      "============================================================\n",
      "\n",
      "📸 Image ID: 000422.jpg\n",
      "------------------------------------------------------------\n",
      "                   CIDEr   SPICE  cosine_similarity\n",
      "Prompt 1 (Run 1)  2.9109  0.0000             0.1561\n",
      "Prompt 1 (Run 2)  2.9109  0.0000             0.1561\n",
      "Prompt 2 (Run 1)  2.2678  0.0323             0.4710\n",
      "Prompt 2 (Run 2)  2.2678  0.0323             0.4710\n",
      "Prompt 3 (Run 1)  2.0353  0.0294             0.2461\n",
      "Prompt 3 (Run 2)  2.0353  0.0294             0.2461\n",
      "Prompt 4 (Run 1)  1.0282  0.0702             0.3189\n",
      "Prompt 4 (Run 2)  1.0282  0.0702             0.3189\n",
      "Prompt 5 (Run 1)  2.3648  0.0328             0.4621\n",
      "Prompt 5 (Run 2)  2.3648  0.0328             0.4621\n",
      "Prompt 6 (Run 1)  0.2480  0.0308             0.5205\n",
      "Prompt 6 (Run 2)  0.2480  0.0308             0.5205\n",
      "============================================================\n",
      "\n",
      "📸 Image ID: 000433.jpg\n",
      "------------------------------------------------------------\n",
      "                   CIDEr   SPICE  cosine_similarity\n",
      "Prompt 1 (Run 1)  2.2237  0.0000             0.1072\n",
      "Prompt 1 (Run 2)  2.2237  0.0000             0.1072\n",
      "Prompt 2 (Run 1)  2.7416  0.0000             0.4018\n",
      "Prompt 2 (Run 2)  2.7416  0.0000             0.4018\n",
      "Prompt 3 (Run 1)  3.1030  0.0435             0.5085\n",
      "Prompt 3 (Run 2)  3.1030  0.0435             0.5085\n",
      "Prompt 4 (Run 1)  1.8511  0.0417             0.3277\n",
      "Prompt 4 (Run 2)  1.8511  0.0417             0.3277\n",
      "Prompt 5 (Run 1)  2.2158  0.0328             0.5993\n",
      "Prompt 5 (Run 2)  2.2158  0.0328             0.5993\n",
      "Prompt 6 (Run 1)  0.7191  0.0417             0.5297\n",
      "Prompt 6 (Run 2)  0.7191  0.0417             0.5297\n",
      "============================================================\n",
      "\n",
      "📸 Image ID: 000481.jpg\n",
      "------------------------------------------------------------\n",
      "                   CIDEr   SPICE  cosine_similarity\n",
      "Prompt 1 (Run 1)  2.9354  0.0000             0.0707\n",
      "Prompt 1 (Run 2)  2.9354  0.0000             0.0707\n",
      "Prompt 2 (Run 1)  0.1348  0.0377             0.3319\n",
      "Prompt 2 (Run 2)  0.1348  0.0377             0.3319\n",
      "Prompt 3 (Run 1)  1.2310  0.0615             0.4369\n",
      "Prompt 3 (Run 2)  1.2310  0.0615             0.4369\n",
      "Prompt 4 (Run 1)  4.2462  0.0377             0.2275\n",
      "Prompt 4 (Run 2)  4.2462  0.0377             0.2275\n",
      "Prompt 5 (Run 1)  1.9170  0.0645             0.5621\n",
      "Prompt 5 (Run 2)  1.9170  0.0645             0.5621\n",
      "Prompt 6 (Run 1)  0.4076  0.0286             0.3424\n",
      "Prompt 6 (Run 2)  0.4076  0.0286             0.3424\n",
      "============================================================\n",
      "\n",
      "📸 Image ID: 000520.jpg\n",
      "------------------------------------------------------------\n",
      "                   CIDEr   SPICE  cosine_similarity\n",
      "Prompt 1 (Run 1)  1.0301  0.0000             0.0567\n",
      "Prompt 1 (Run 2)  1.0301  0.0000             0.0567\n",
      "Prompt 2 (Run 1)  3.7905  0.0833             0.4014\n",
      "Prompt 2 (Run 2)  3.7905  0.0833             0.4014\n",
      "Prompt 3 (Run 1)  2.8149  0.0645             0.3681\n",
      "Prompt 3 (Run 2)  2.8149  0.0645             0.3681\n",
      "Prompt 4 (Run 1)  1.5304  0.0308             0.2219\n",
      "Prompt 4 (Run 2)  1.5304  0.0308             0.2219\n",
      "Prompt 5 (Run 1)  3.7073  0.0303             0.3431\n",
      "Prompt 5 (Run 2)  3.7073  0.0303             0.3431\n",
      "Prompt 6 (Run 1)  0.3826  0.0000             0.3467\n",
      "Prompt 6 (Run 2)  0.3826  0.0000             0.3467\n",
      "============================================================\n",
      "\n",
      "📸 Image ID: 000541.jpg\n",
      "------------------------------------------------------------\n",
      "                   CIDEr   SPICE  cosine_similarity\n",
      "Prompt 1 (Run 1)  1.6398  0.0000             0.1290\n",
      "Prompt 1 (Run 2)  1.6398  0.0000             0.1290\n",
      "Prompt 2 (Run 1)  0.5302  0.0377             0.3268\n",
      "Prompt 2 (Run 2)  0.5302  0.0377             0.3268\n",
      "Prompt 3 (Run 1)  2.8484  0.0364             0.3393\n",
      "Prompt 3 (Run 2)  2.8484  0.0364             0.3393\n",
      "Prompt 4 (Run 1)  2.1828  0.0465             0.2624\n",
      "Prompt 4 (Run 2)  2.1828  0.0465             0.2624\n",
      "Prompt 5 (Run 1)  3.7626  0.0377             0.6124\n",
      "Prompt 5 (Run 2)  3.7626  0.0377             0.6124\n",
      "Prompt 6 (Run 1)  3.3542  0.0377             0.5492\n",
      "Prompt 6 (Run 2)  3.3542  0.0377             0.5492\n",
      "============================================================\n",
      "\n",
      "📸 Image ID: 000698.jpg\n",
      "------------------------------------------------------------\n",
      "                   CIDEr   SPICE  cosine_similarity\n",
      "Prompt 1 (Run 1)  1.0630  0.0000             0.0644\n",
      "Prompt 1 (Run 2)  1.0630  0.0000             0.0644\n",
      "Prompt 2 (Run 1)  0.4224  0.0000             0.3501\n",
      "Prompt 2 (Run 2)  0.4224  0.0000             0.3501\n",
      "Prompt 3 (Run 1)  2.9708  0.0286             0.2731\n",
      "Prompt 3 (Run 2)  2.9708  0.0286             0.2731\n",
      "Prompt 4 (Run 1)  1.0423  0.0303             0.2116\n",
      "Prompt 4 (Run 2)  1.0423  0.0303             0.2116\n",
      "Prompt 5 (Run 1)  3.6598  0.0299             0.3526\n",
      "Prompt 5 (Run 2)  3.6598  0.0299             0.3526\n",
      "Prompt 6 (Run 1)  0.6315  0.0323             0.4422\n",
      "Prompt 6 (Run 2)  0.6315  0.0323             0.4422\n",
      "============================================================\n",
      "\n",
      "📸 Image ID: 000740.jpg\n",
      "------------------------------------------------------------\n",
      "                   CIDEr   SPICE  cosine_similarity\n",
      "Prompt 1 (Run 1)  2.5830  0.0000             0.2378\n",
      "Prompt 1 (Run 2)  2.5830  0.0000             0.2378\n",
      "Prompt 2 (Run 1)  0.5277  0.0000             0.2976\n",
      "Prompt 2 (Run 2)  0.5277  0.0000             0.2976\n",
      "Prompt 3 (Run 1)  1.7606  0.0357             0.3304\n",
      "Prompt 3 (Run 2)  1.7606  0.0357             0.3304\n",
      "Prompt 4 (Run 1)  0.8814  0.1754             0.2488\n",
      "Prompt 4 (Run 2)  0.8814  0.1754             0.2488\n",
      "Prompt 5 (Run 1)  4.0754  0.0299             0.2695\n",
      "Prompt 5 (Run 2)  4.0754  0.0299             0.2695\n",
      "Prompt 6 (Run 1)  2.6275  0.0606             0.4512\n",
      "Prompt 6 (Run 2)  2.6275  0.0606             0.4512\n",
      "============================================================\n",
      "\n",
      "📸 Image ID: 000869.jpg\n",
      "------------------------------------------------------------\n",
      "                   CIDEr   SPICE  cosine_similarity\n",
      "Prompt 1 (Run 1)  0.9431  0.0000             0.2412\n",
      "Prompt 1 (Run 2)  0.9431  0.0000             0.2412\n",
      "Prompt 2 (Run 1)  1.5505  0.0308             0.3566\n",
      "Prompt 2 (Run 2)  1.5505  0.0308             0.3566\n",
      "Prompt 3 (Run 1)  2.4877  0.0278             0.3856\n",
      "Prompt 3 (Run 2)  2.4877  0.0278             0.3856\n",
      "Prompt 4 (Run 1)  1.4809  0.0377             0.3107\n",
      "Prompt 4 (Run 2)  1.4809  0.0377             0.3107\n",
      "Prompt 5 (Run 1)  2.5397  0.0303             0.4458\n",
      "Prompt 5 (Run 2)  2.5397  0.0303             0.4458\n",
      "Prompt 6 (Run 1)  1.1609  0.0000             0.3323\n",
      "Prompt 6 (Run 2)  1.1609  0.0000             0.3323\n",
      "============================================================\n",
      "\n",
      "📸 Image ID: 000889.jpg\n",
      "------------------------------------------------------------\n",
      "                   CIDEr   SPICE  cosine_similarity\n",
      "Prompt 1 (Run 1)  3.1375  0.0000             0.1464\n",
      "Prompt 1 (Run 2)  3.1375  0.0000             0.1464\n",
      "Prompt 2 (Run 1)  2.2063  0.0606             0.3584\n",
      "Prompt 2 (Run 2)  2.2063  0.0606             0.3584\n",
      "Prompt 3 (Run 1)  2.0147  0.0769             0.2865\n",
      "Prompt 3 (Run 2)  2.0147  0.0769             0.2865\n",
      "Prompt 4 (Run 1)  1.4011  0.0435             0.2248\n",
      "Prompt 4 (Run 2)  1.4011  0.0435             0.2248\n",
      "Prompt 5 (Run 1)  2.8918  0.0308             0.3675\n",
      "Prompt 5 (Run 2)  2.8918  0.0308             0.3675\n",
      "Prompt 6 (Run 1)  0.1320  0.0000             0.4119\n",
      "Prompt 6 (Run 2)  0.1320  0.0000             0.4119\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "for img_id, scores in all_metrics_scores.items():\n",
    "    print(f\"\\n📸 Image ID: {img_id}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    df_temp = pd.DataFrame(scores)\n",
    "    prompt_labels = []\n",
    "    for i in range(len(scores)):\n",
    "        prompt_num = (i // 2) + 1  # Prompts 1–6\n",
    "        run_num = (i % 2) + 1      # Run 1 or Run 2\n",
    "        prompt_labels.append(f\"Prompt {prompt_num} (Run {run_num})\")\n",
    "\n",
    "    df_temp.index = prompt_labels\n",
    "    print(df_temp.round(4))\n",
    "    print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d6b1b4f0-8cfc-4442-b982-908fba41a7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log results table\n",
    "table = wandb.Table(columns=[\"filename\", \"prompt_type\", \"run\", \"image\", \"ground_truth\", \"prediction\"])\n",
    "\n",
    "for filename in all_outputs:\n",
    "    row = df[df[\"filename\"] == filename]\n",
    "    if row.empty:\n",
    "        continue\n",
    "\n",
    "    ground_truth = row.iloc[0][\"caption\"]\n",
    "    image_pil = row.iloc[0][\"image\"]\n",
    "\n",
    "    for prompt_index in range(6):\n",
    "        for run in range(2):\n",
    "            row_idx = prompt_index * 2 + run\n",
    "            prediction = all_outputs[filename][row_idx] if row_idx < len(all_outputs[filename]) else \"N/A\"\n",
    "\n",
    "            table.add_data(\n",
    "                filename,\n",
    "                f\"Prompt {prompt_index + 1}\",\n",
    "                f\"Run {run + 1}\",\n",
    "                wandb.Image(image_pil),\n",
    "                ground_truth,\n",
    "                prediction\n",
    "            )\n",
    "\n",
    "wandb.log({\"Prompting Comparison Results\": table})\n",
    "\n",
    "# Log metrics for each prompt run\n",
    "for filename, scores in all_metrics_scores.items():\n",
    "    for i, score in enumerate(scores):\n",
    "        wandb.log({\n",
    "            f\"{filename}/Prompt {i//2 + 1}/Run {i%2 + 1}/CIDEr\": score[\"CIDEr\"],\n",
    "            f\"{filename}/Prompt {i//2 + 1}/Run {i%2 + 1}/SPICE\": score[\"SPICE\"],\n",
    "            f\"{filename}/Prompt {i//2 + 1}/Run {i%2 + 1}/Cosine\": score[\"cosine_similarity\"]\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c88d3c1d-92d1-41d0-9b3d-f1e9c36cea7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openpyxl import Workbook, load_workbook\n",
    "from openpyxl.drawing.image import Image as ExcelImage\n",
    "from openpyxl.styles import Alignment\n",
    "from PIL import Image as PILImage\n",
    "import os\n",
    "\n",
    "def log_prompt_metrics_to_excel(\n",
    "    filename: str,\n",
    "    model_name: str,\n",
    "    inference_outputs: list,\n",
    "    metrics: list,\n",
    "    inference_times: list,\n",
    "    vram_usages: list,\n",
    "    df: pd.DataFrame,\n",
    "    output_excel_path: str = \"prompt_tuning_results_cardd_pixtral.xlsx\"\n",
    "):\n",
    "    row = df[df[\"filename\"] == filename].iloc[0]\n",
    "    original_caption = row[\"caption\"]\n",
    "    image_path = os.path.join(\"/workspace/data/test_dataset\", filename)\n",
    "\n",
    "    # Load or create workbook\n",
    "    if os.path.exists(output_excel_path):\n",
    "        wb = load_workbook(output_excel_path)\n",
    "        ws = wb.active\n",
    "    else:\n",
    "        wb = Workbook()\n",
    "        ws = wb.active\n",
    "        ws.title = \"Prompt Evaluation\"\n",
    "        headers = [\n",
    "            \"Model\", \"Image Number\", \"Image\", \"Original Caption\",\n",
    "            \"Prompt\", \"Output\", \"Inference Time (s)\", \"VRAM Used (GB)\",\n",
    "            \"CIDEr\", \"SPICE\", \"Cosine Similarity\"\n",
    "        ]\n",
    "        ws.append(headers)\n",
    "\n",
    "    # Loop over the 2 runs (Run 1, Run 2) — 6 prompts per run\n",
    "    for run_index in range(2):  # 0 for Run 1, 1 for Run 2\n",
    "        start_row = ws.max_row + 1\n",
    "\n",
    "        for prompt_index in range(6):  # Prompt 1 to 6\n",
    "            idx = prompt_index * 2 + run_index\n",
    "            ws.append([\n",
    "                model_name,\n",
    "                filename,\n",
    "                \"\",  # Placeholder for image\n",
    "                original_caption,\n",
    "                f\"Prompt {prompt_index + 1} (Run {run_index + 1})\",\n",
    "                inference_outputs[idx],\n",
    "                inference_times[idx],\n",
    "                vram_usages[idx],\n",
    "                metrics[idx][\"CIDEr\"],\n",
    "                metrics[idx][\"SPICE\"],\n",
    "                metrics[idx][\"cosine_similarity\"]\n",
    "            ])\n",
    "\n",
    "        # Merge A–D columns across 6 rows\n",
    "        for col in [\"A\", \"B\", \"C\", \"D\"]:\n",
    "            ws.merge_cells(f\"{col}{start_row}:{col}{start_row + 5}\")\n",
    "\n",
    "        # Apply alignment and formatting\n",
    "        align_top_wrap = Alignment(wrap_text=True, vertical=\"top\")\n",
    "        align_top = Alignment(vertical=\"top\")\n",
    "\n",
    "        for row_idx in range(start_row, start_row + 6):\n",
    "            for col_letter in [\"A\", \"B\", \"C\", \"E\"]:\n",
    "                ws[f\"{col_letter}{row_idx}\"].alignment = align_top\n",
    "            for col_letter in [\"D\", \"F\"]:\n",
    "                ws[f\"{col_letter}{row_idx}\"].alignment = align_top_wrap\n",
    "            ws.row_dimensions[row_idx].height = 120\n",
    "\n",
    "        # Set column widths\n",
    "        ws.column_dimensions[\"D\"].width = 40  # Original Caption\n",
    "        ws.column_dimensions[\"F\"].width = 40  # Output\n",
    "\n",
    "        # Embed image in this run block\n",
    "        if os.path.exists(image_path):\n",
    "            print(f\"[INFO] Inserting image for {filename} | Run {run_index + 1}\")\n",
    "            try:\n",
    "                img = ExcelImage(image_path)\n",
    "                img.width = 150\n",
    "                img.height = 150\n",
    "                img.anchor = f\"C{start_row}\"\n",
    "                ws.add_image(img)\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR] Could not insert image: {e}\")\n",
    "\n",
    "    # Save workbook\n",
    "    wb.save(output_excel_path)\n",
    "    print(f\"✅ Logged both runs for {filename} to {output_excel_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dd7d5bfd-a9fc-4e36-89d6-238542869d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Inserting image for 000404.jpg | Run 1\n",
      "[INFO] Inserting image for 000404.jpg | Run 2\n",
      "✅ Logged both runs for 000404.jpg to prompt_tuning_results_cardd_pixtral.xlsx\n",
      "[INFO] Inserting image for 000422.jpg | Run 1\n",
      "[INFO] Inserting image for 000422.jpg | Run 2\n",
      "✅ Logged both runs for 000422.jpg to prompt_tuning_results_cardd_pixtral.xlsx\n",
      "[INFO] Inserting image for 000433.jpg | Run 1\n",
      "[INFO] Inserting image for 000433.jpg | Run 2\n",
      "✅ Logged both runs for 000433.jpg to prompt_tuning_results_cardd_pixtral.xlsx\n",
      "[INFO] Inserting image for 000481.jpg | Run 1\n",
      "[INFO] Inserting image for 000481.jpg | Run 2\n",
      "✅ Logged both runs for 000481.jpg to prompt_tuning_results_cardd_pixtral.xlsx\n",
      "[INFO] Inserting image for 000520.jpg | Run 1\n",
      "[INFO] Inserting image for 000520.jpg | Run 2\n",
      "✅ Logged both runs for 000520.jpg to prompt_tuning_results_cardd_pixtral.xlsx\n",
      "[INFO] Inserting image for 000541.jpg | Run 1\n",
      "[INFO] Inserting image for 000541.jpg | Run 2\n",
      "✅ Logged both runs for 000541.jpg to prompt_tuning_results_cardd_pixtral.xlsx\n",
      "[INFO] Inserting image for 000698.jpg | Run 1\n",
      "[INFO] Inserting image for 000698.jpg | Run 2\n",
      "✅ Logged both runs for 000698.jpg to prompt_tuning_results_cardd_pixtral.xlsx\n",
      "[INFO] Inserting image for 000740.jpg | Run 1\n",
      "[INFO] Inserting image for 000740.jpg | Run 2\n",
      "✅ Logged both runs for 000740.jpg to prompt_tuning_results_cardd_pixtral.xlsx\n",
      "[INFO] Inserting image for 000869.jpg | Run 1\n",
      "[INFO] Inserting image for 000869.jpg | Run 2\n",
      "✅ Logged both runs for 000869.jpg to prompt_tuning_results_cardd_pixtral.xlsx\n",
      "[INFO] Inserting image for 000889.jpg | Run 1\n",
      "[INFO] Inserting image for 000889.jpg | Run 2\n",
      "✅ Logged both runs for 000889.jpg to prompt_tuning_results_cardd_pixtral.xlsx\n"
     ]
    }
   ],
   "source": [
    "for filename in all_outputs.keys():\n",
    "    log_prompt_metrics_to_excel(\n",
    "        filename=filename,\n",
    "        model_name=model_id,\n",
    "        inference_outputs=all_outputs[filename],\n",
    "        metrics=all_metrics_scores[filename],\n",
    "        inference_times=all_times[filename],\n",
    "        vram_usages=all_vram[filename],\n",
    "        df=df\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bd783220-02a4-4fd8-a655-bb5ef7e7fb91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>000404.jpg/Prompt 1/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 1/Run 1/Cosine</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 1/Run 1/SPICE</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 1/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 1/Run 2/Cosine</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 1/Run 2/SPICE</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 2/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 2/Run 1/Cosine</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 2/Run 1/SPICE</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 2/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 2/Run 2/Cosine</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 2/Run 2/SPICE</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 3/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 3/Run 1/Cosine</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 3/Run 1/SPICE</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 3/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 3/Run 2/Cosine</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 3/Run 2/SPICE</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 4/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 4/Run 1/Cosine</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 4/Run 1/SPICE</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 4/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 4/Run 2/Cosine</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 4/Run 2/SPICE</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 5/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 5/Run 1/Cosine</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 5/Run 1/SPICE</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 5/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 5/Run 2/Cosine</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 5/Run 2/SPICE</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 6/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 6/Run 1/Cosine</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 6/Run 1/SPICE</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 6/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 6/Run 2/Cosine</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 6/Run 2/SPICE</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 1/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 1/Run 1/Cosine</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 1/Run 1/SPICE</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 1/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 1/Run 2/Cosine</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 1/Run 2/SPICE</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 2/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 2/Run 1/Cosine</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 2/Run 1/SPICE</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 2/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 2/Run 2/Cosine</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 2/Run 2/SPICE</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 3/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 3/Run 1/Cosine</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 3/Run 1/SPICE</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 3/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 3/Run 2/Cosine</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 3/Run 2/SPICE</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 4/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 4/Run 1/Cosine</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 4/Run 1/SPICE</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 4/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 4/Run 2/Cosine</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 4/Run 2/SPICE</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 5/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 5/Run 1/Cosine</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 5/Run 1/SPICE</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 5/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 5/Run 2/Cosine</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 5/Run 2/SPICE</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 6/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 6/Run 1/Cosine</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 6/Run 1/SPICE</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 6/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 6/Run 2/Cosine</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 6/Run 2/SPICE</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 1/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 1/Run 1/Cosine</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 1/Run 1/SPICE</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 1/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 1/Run 2/Cosine</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 1/Run 2/SPICE</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 2/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 2/Run 1/Cosine</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 2/Run 1/SPICE</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 2/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 2/Run 2/Cosine</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 2/Run 2/SPICE</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 3/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 3/Run 1/Cosine</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 3/Run 1/SPICE</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 3/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 3/Run 2/Cosine</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 3/Run 2/SPICE</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 4/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 4/Run 1/Cosine</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 4/Run 1/SPICE</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 4/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 4/Run 2/Cosine</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 4/Run 2/SPICE</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 5/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 5/Run 1/Cosine</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 5/Run 1/SPICE</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 5/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 5/Run 2/Cosine</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 5/Run 2/SPICE</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 6/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 6/Run 1/Cosine</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 6/Run 1/SPICE</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 6/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 6/Run 2/Cosine</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 6/Run 2/SPICE</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 1/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 1/Run 1/Cosine</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 1/Run 1/SPICE</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 1/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 1/Run 2/Cosine</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 1/Run 2/SPICE</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 2/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 2/Run 1/Cosine</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 2/Run 1/SPICE</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 2/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 2/Run 2/Cosine</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 2/Run 2/SPICE</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 3/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 3/Run 1/Cosine</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 3/Run 1/SPICE</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 3/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 3/Run 2/Cosine</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 3/Run 2/SPICE</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 4/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 4/Run 1/Cosine</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 4/Run 1/SPICE</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 4/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 4/Run 2/Cosine</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 4/Run 2/SPICE</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 5/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 5/Run 1/Cosine</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 5/Run 1/SPICE</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 5/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 5/Run 2/Cosine</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 5/Run 2/SPICE</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 6/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 6/Run 1/Cosine</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 6/Run 1/SPICE</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 6/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 6/Run 2/Cosine</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 6/Run 2/SPICE</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 1/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 1/Run 1/Cosine</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 1/Run 1/SPICE</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 1/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 1/Run 2/Cosine</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 1/Run 2/SPICE</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 2/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 2/Run 1/Cosine</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 2/Run 1/SPICE</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 2/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 2/Run 2/Cosine</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 2/Run 2/SPICE</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 3/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 3/Run 1/Cosine</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 3/Run 1/SPICE</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 3/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 3/Run 2/Cosine</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 3/Run 2/SPICE</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 4/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 4/Run 1/Cosine</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 4/Run 1/SPICE</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 4/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 4/Run 2/Cosine</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 4/Run 2/SPICE</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 5/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 5/Run 1/Cosine</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 5/Run 1/SPICE</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 5/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 5/Run 2/Cosine</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 5/Run 2/SPICE</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 6/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 6/Run 1/Cosine</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 6/Run 1/SPICE</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 6/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 6/Run 2/Cosine</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 6/Run 2/SPICE</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 1/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 1/Run 1/Cosine</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 1/Run 1/SPICE</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 1/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 1/Run 2/Cosine</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 1/Run 2/SPICE</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 2/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 2/Run 1/Cosine</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 2/Run 1/SPICE</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 2/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 2/Run 2/Cosine</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 2/Run 2/SPICE</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 3/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 3/Run 1/Cosine</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 3/Run 1/SPICE</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 3/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 3/Run 2/Cosine</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 3/Run 2/SPICE</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 4/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 4/Run 1/Cosine</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 4/Run 1/SPICE</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 4/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 4/Run 2/Cosine</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 4/Run 2/SPICE</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 5/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 5/Run 1/Cosine</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 5/Run 1/SPICE</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 5/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 5/Run 2/Cosine</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 5/Run 2/SPICE</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 6/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 6/Run 1/Cosine</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 6/Run 1/SPICE</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 6/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 6/Run 2/Cosine</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 6/Run 2/SPICE</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 1/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 1/Run 1/Cosine</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 1/Run 1/SPICE</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 1/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 1/Run 2/Cosine</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 1/Run 2/SPICE</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 2/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 2/Run 1/Cosine</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 2/Run 1/SPICE</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 2/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 2/Run 2/Cosine</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 2/Run 2/SPICE</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 3/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 3/Run 1/Cosine</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 3/Run 1/SPICE</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 3/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 3/Run 2/Cosine</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 3/Run 2/SPICE</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 4/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 4/Run 1/Cosine</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 4/Run 1/SPICE</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 4/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 4/Run 2/Cosine</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 4/Run 2/SPICE</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 5/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 5/Run 1/Cosine</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 5/Run 1/SPICE</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 5/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 5/Run 2/Cosine</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 5/Run 2/SPICE</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 6/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 6/Run 1/Cosine</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 6/Run 1/SPICE</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 6/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 6/Run 2/Cosine</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 6/Run 2/SPICE</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 1/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 1/Run 1/Cosine</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 1/Run 1/SPICE</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 1/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 1/Run 2/Cosine</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 1/Run 2/SPICE</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 2/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 2/Run 1/Cosine</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 2/Run 1/SPICE</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 2/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 2/Run 2/Cosine</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 2/Run 2/SPICE</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 3/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 3/Run 1/Cosine</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 3/Run 1/SPICE</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 3/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 3/Run 2/Cosine</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 3/Run 2/SPICE</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 4/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 4/Run 1/Cosine</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 4/Run 1/SPICE</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 4/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 4/Run 2/Cosine</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 4/Run 2/SPICE</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 5/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 5/Run 1/Cosine</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 5/Run 1/SPICE</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 5/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 5/Run 2/Cosine</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 5/Run 2/SPICE</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 6/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 6/Run 1/Cosine</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 6/Run 1/SPICE</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 6/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 6/Run 2/Cosine</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 6/Run 2/SPICE</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 1/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 1/Run 1/Cosine</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 1/Run 1/SPICE</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 1/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 1/Run 2/Cosine</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 1/Run 2/SPICE</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 2/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 2/Run 1/Cosine</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 2/Run 1/SPICE</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 2/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 2/Run 2/Cosine</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 2/Run 2/SPICE</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 3/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 3/Run 1/Cosine</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 3/Run 1/SPICE</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 3/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 3/Run 2/Cosine</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 3/Run 2/SPICE</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 4/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 4/Run 1/Cosine</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 4/Run 1/SPICE</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 4/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 4/Run 2/Cosine</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 4/Run 2/SPICE</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 5/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 5/Run 1/Cosine</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 5/Run 1/SPICE</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 5/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 5/Run 2/Cosine</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 5/Run 2/SPICE</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 6/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 6/Run 1/Cosine</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 6/Run 1/SPICE</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 6/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 6/Run 2/Cosine</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 6/Run 2/SPICE</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 1/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 1/Run 1/Cosine</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 1/Run 1/SPICE</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 1/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 1/Run 2/Cosine</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 1/Run 2/SPICE</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 2/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 2/Run 1/Cosine</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 2/Run 1/SPICE</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 2/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 2/Run 2/Cosine</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 2/Run 2/SPICE</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 3/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 3/Run 1/Cosine</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 3/Run 1/SPICE</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 3/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 3/Run 2/Cosine</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 3/Run 2/SPICE</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 4/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 4/Run 1/Cosine</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 4/Run 1/SPICE</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 4/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 4/Run 2/Cosine</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 4/Run 2/SPICE</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 5/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 5/Run 1/Cosine</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 5/Run 1/SPICE</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 5/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 5/Run 2/Cosine</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 5/Run 2/SPICE</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 6/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 6/Run 1/Cosine</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 6/Run 1/SPICE</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 6/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 6/Run 2/Cosine</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 6/Run 2/SPICE</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>000404.jpg/Prompt 1/Run 1/CIDEr</td><td>5.3422</td></tr><tr><td>000404.jpg/Prompt 1/Run 1/Cosine</td><td>0.185</td></tr><tr><td>000404.jpg/Prompt 1/Run 1/SPICE</td><td>0</td></tr><tr><td>000404.jpg/Prompt 1/Run 2/CIDEr</td><td>5.3422</td></tr><tr><td>000404.jpg/Prompt 1/Run 2/Cosine</td><td>0.185</td></tr><tr><td>000404.jpg/Prompt 1/Run 2/SPICE</td><td>0</td></tr><tr><td>000404.jpg/Prompt 2/Run 1/CIDEr</td><td>0.5702</td></tr><tr><td>000404.jpg/Prompt 2/Run 1/Cosine</td><td>0.4061</td></tr><tr><td>000404.jpg/Prompt 2/Run 1/SPICE</td><td>0.0317</td></tr><tr><td>000404.jpg/Prompt 2/Run 2/CIDEr</td><td>0.5702</td></tr><tr><td>000404.jpg/Prompt 2/Run 2/Cosine</td><td>0.4061</td></tr><tr><td>000404.jpg/Prompt 2/Run 2/SPICE</td><td>0.0317</td></tr><tr><td>000404.jpg/Prompt 3/Run 1/CIDEr</td><td>1.1607</td></tr><tr><td>000404.jpg/Prompt 3/Run 1/Cosine</td><td>0.3116</td></tr><tr><td>000404.jpg/Prompt 3/Run 1/SPICE</td><td>0.0455</td></tr><tr><td>000404.jpg/Prompt 3/Run 2/CIDEr</td><td>1.1607</td></tr><tr><td>000404.jpg/Prompt 3/Run 2/Cosine</td><td>0.3116</td></tr><tr><td>000404.jpg/Prompt 3/Run 2/SPICE</td><td>0.0455</td></tr><tr><td>000404.jpg/Prompt 4/Run 1/CIDEr</td><td>3.3462</td></tr><tr><td>000404.jpg/Prompt 4/Run 1/Cosine</td><td>0.2931</td></tr><tr><td>000404.jpg/Prompt 4/Run 1/SPICE</td><td>0.0274</td></tr><tr><td>000404.jpg/Prompt 4/Run 2/CIDEr</td><td>3.3462</td></tr><tr><td>000404.jpg/Prompt 4/Run 2/Cosine</td><td>0.2931</td></tr><tr><td>000404.jpg/Prompt 4/Run 2/SPICE</td><td>0.0274</td></tr><tr><td>000404.jpg/Prompt 5/Run 1/CIDEr</td><td>5.8958</td></tr><tr><td>000404.jpg/Prompt 5/Run 1/Cosine</td><td>0.5898</td></tr><tr><td>000404.jpg/Prompt 5/Run 1/SPICE</td><td>0.0286</td></tr><tr><td>000404.jpg/Prompt 5/Run 2/CIDEr</td><td>5.8958</td></tr><tr><td>000404.jpg/Prompt 5/Run 2/Cosine</td><td>0.5898</td></tr><tr><td>000404.jpg/Prompt 5/Run 2/SPICE</td><td>0.0286</td></tr><tr><td>000404.jpg/Prompt 6/Run 1/CIDEr</td><td>1.1225</td></tr><tr><td>000404.jpg/Prompt 6/Run 1/Cosine</td><td>0.5004</td></tr><tr><td>000404.jpg/Prompt 6/Run 1/SPICE</td><td>0</td></tr><tr><td>000404.jpg/Prompt 6/Run 2/CIDEr</td><td>1.1225</td></tr><tr><td>000404.jpg/Prompt 6/Run 2/Cosine</td><td>0.5004</td></tr><tr><td>000404.jpg/Prompt 6/Run 2/SPICE</td><td>0</td></tr><tr><td>000422.jpg/Prompt 1/Run 1/CIDEr</td><td>2.9109</td></tr><tr><td>000422.jpg/Prompt 1/Run 1/Cosine</td><td>0.1561</td></tr><tr><td>000422.jpg/Prompt 1/Run 1/SPICE</td><td>0</td></tr><tr><td>000422.jpg/Prompt 1/Run 2/CIDEr</td><td>2.9109</td></tr><tr><td>000422.jpg/Prompt 1/Run 2/Cosine</td><td>0.1561</td></tr><tr><td>000422.jpg/Prompt 1/Run 2/SPICE</td><td>0</td></tr><tr><td>000422.jpg/Prompt 2/Run 1/CIDEr</td><td>2.2678</td></tr><tr><td>000422.jpg/Prompt 2/Run 1/Cosine</td><td>0.471</td></tr><tr><td>000422.jpg/Prompt 2/Run 1/SPICE</td><td>0.0323</td></tr><tr><td>000422.jpg/Prompt 2/Run 2/CIDEr</td><td>2.2678</td></tr><tr><td>000422.jpg/Prompt 2/Run 2/Cosine</td><td>0.471</td></tr><tr><td>000422.jpg/Prompt 2/Run 2/SPICE</td><td>0.0323</td></tr><tr><td>000422.jpg/Prompt 3/Run 1/CIDEr</td><td>2.0353</td></tr><tr><td>000422.jpg/Prompt 3/Run 1/Cosine</td><td>0.2461</td></tr><tr><td>000422.jpg/Prompt 3/Run 1/SPICE</td><td>0.0294</td></tr><tr><td>000422.jpg/Prompt 3/Run 2/CIDEr</td><td>2.0353</td></tr><tr><td>000422.jpg/Prompt 3/Run 2/Cosine</td><td>0.2461</td></tr><tr><td>000422.jpg/Prompt 3/Run 2/SPICE</td><td>0.0294</td></tr><tr><td>000422.jpg/Prompt 4/Run 1/CIDEr</td><td>1.0282</td></tr><tr><td>000422.jpg/Prompt 4/Run 1/Cosine</td><td>0.3189</td></tr><tr><td>000422.jpg/Prompt 4/Run 1/SPICE</td><td>0.0702</td></tr><tr><td>000422.jpg/Prompt 4/Run 2/CIDEr</td><td>1.0282</td></tr><tr><td>000422.jpg/Prompt 4/Run 2/Cosine</td><td>0.3189</td></tr><tr><td>000422.jpg/Prompt 4/Run 2/SPICE</td><td>0.0702</td></tr><tr><td>000422.jpg/Prompt 5/Run 1/CIDEr</td><td>2.3648</td></tr><tr><td>000422.jpg/Prompt 5/Run 1/Cosine</td><td>0.4621</td></tr><tr><td>000422.jpg/Prompt 5/Run 1/SPICE</td><td>0.0328</td></tr><tr><td>000422.jpg/Prompt 5/Run 2/CIDEr</td><td>2.3648</td></tr><tr><td>000422.jpg/Prompt 5/Run 2/Cosine</td><td>0.4621</td></tr><tr><td>000422.jpg/Prompt 5/Run 2/SPICE</td><td>0.0328</td></tr><tr><td>000422.jpg/Prompt 6/Run 1/CIDEr</td><td>0.248</td></tr><tr><td>000422.jpg/Prompt 6/Run 1/Cosine</td><td>0.5205</td></tr><tr><td>000422.jpg/Prompt 6/Run 1/SPICE</td><td>0.0308</td></tr><tr><td>000422.jpg/Prompt 6/Run 2/CIDEr</td><td>0.248</td></tr><tr><td>000422.jpg/Prompt 6/Run 2/Cosine</td><td>0.5205</td></tr><tr><td>000422.jpg/Prompt 6/Run 2/SPICE</td><td>0.0308</td></tr><tr><td>000433.jpg/Prompt 1/Run 1/CIDEr</td><td>2.2237</td></tr><tr><td>000433.jpg/Prompt 1/Run 1/Cosine</td><td>0.1072</td></tr><tr><td>000433.jpg/Prompt 1/Run 1/SPICE</td><td>0</td></tr><tr><td>000433.jpg/Prompt 1/Run 2/CIDEr</td><td>2.2237</td></tr><tr><td>000433.jpg/Prompt 1/Run 2/Cosine</td><td>0.1072</td></tr><tr><td>000433.jpg/Prompt 1/Run 2/SPICE</td><td>0</td></tr><tr><td>000433.jpg/Prompt 2/Run 1/CIDEr</td><td>2.7416</td></tr><tr><td>000433.jpg/Prompt 2/Run 1/Cosine</td><td>0.4018</td></tr><tr><td>000433.jpg/Prompt 2/Run 1/SPICE</td><td>0</td></tr><tr><td>000433.jpg/Prompt 2/Run 2/CIDEr</td><td>2.7416</td></tr><tr><td>000433.jpg/Prompt 2/Run 2/Cosine</td><td>0.4018</td></tr><tr><td>000433.jpg/Prompt 2/Run 2/SPICE</td><td>0</td></tr><tr><td>000433.jpg/Prompt 3/Run 1/CIDEr</td><td>3.103</td></tr><tr><td>000433.jpg/Prompt 3/Run 1/Cosine</td><td>0.5085</td></tr><tr><td>000433.jpg/Prompt 3/Run 1/SPICE</td><td>0.0435</td></tr><tr><td>000433.jpg/Prompt 3/Run 2/CIDEr</td><td>3.103</td></tr><tr><td>000433.jpg/Prompt 3/Run 2/Cosine</td><td>0.5085</td></tr><tr><td>000433.jpg/Prompt 3/Run 2/SPICE</td><td>0.0435</td></tr><tr><td>000433.jpg/Prompt 4/Run 1/CIDEr</td><td>1.8511</td></tr><tr><td>000433.jpg/Prompt 4/Run 1/Cosine</td><td>0.3277</td></tr><tr><td>000433.jpg/Prompt 4/Run 1/SPICE</td><td>0.0417</td></tr><tr><td>000433.jpg/Prompt 4/Run 2/CIDEr</td><td>1.8511</td></tr><tr><td>000433.jpg/Prompt 4/Run 2/Cosine</td><td>0.3277</td></tr><tr><td>000433.jpg/Prompt 4/Run 2/SPICE</td><td>0.0417</td></tr><tr><td>000433.jpg/Prompt 5/Run 1/CIDEr</td><td>2.2158</td></tr><tr><td>000433.jpg/Prompt 5/Run 1/Cosine</td><td>0.5993</td></tr><tr><td>000433.jpg/Prompt 5/Run 1/SPICE</td><td>0.0328</td></tr><tr><td>000433.jpg/Prompt 5/Run 2/CIDEr</td><td>2.2158</td></tr><tr><td>000433.jpg/Prompt 5/Run 2/Cosine</td><td>0.5993</td></tr><tr><td>000433.jpg/Prompt 5/Run 2/SPICE</td><td>0.0328</td></tr><tr><td>000433.jpg/Prompt 6/Run 1/CIDEr</td><td>0.7191</td></tr><tr><td>000433.jpg/Prompt 6/Run 1/Cosine</td><td>0.5297</td></tr><tr><td>000433.jpg/Prompt 6/Run 1/SPICE</td><td>0.0417</td></tr><tr><td>000433.jpg/Prompt 6/Run 2/CIDEr</td><td>0.7191</td></tr><tr><td>000433.jpg/Prompt 6/Run 2/Cosine</td><td>0.5297</td></tr><tr><td>000433.jpg/Prompt 6/Run 2/SPICE</td><td>0.0417</td></tr><tr><td>000481.jpg/Prompt 1/Run 1/CIDEr</td><td>2.9354</td></tr><tr><td>000481.jpg/Prompt 1/Run 1/Cosine</td><td>0.0707</td></tr><tr><td>000481.jpg/Prompt 1/Run 1/SPICE</td><td>0</td></tr><tr><td>000481.jpg/Prompt 1/Run 2/CIDEr</td><td>2.9354</td></tr><tr><td>000481.jpg/Prompt 1/Run 2/Cosine</td><td>0.0707</td></tr><tr><td>000481.jpg/Prompt 1/Run 2/SPICE</td><td>0</td></tr><tr><td>000481.jpg/Prompt 2/Run 1/CIDEr</td><td>0.1348</td></tr><tr><td>000481.jpg/Prompt 2/Run 1/Cosine</td><td>0.3319</td></tr><tr><td>000481.jpg/Prompt 2/Run 1/SPICE</td><td>0.0377</td></tr><tr><td>000481.jpg/Prompt 2/Run 2/CIDEr</td><td>0.1348</td></tr><tr><td>000481.jpg/Prompt 2/Run 2/Cosine</td><td>0.3319</td></tr><tr><td>000481.jpg/Prompt 2/Run 2/SPICE</td><td>0.0377</td></tr><tr><td>000481.jpg/Prompt 3/Run 1/CIDEr</td><td>1.231</td></tr><tr><td>000481.jpg/Prompt 3/Run 1/Cosine</td><td>0.4369</td></tr><tr><td>000481.jpg/Prompt 3/Run 1/SPICE</td><td>0.0615</td></tr><tr><td>000481.jpg/Prompt 3/Run 2/CIDEr</td><td>1.231</td></tr><tr><td>000481.jpg/Prompt 3/Run 2/Cosine</td><td>0.4369</td></tr><tr><td>000481.jpg/Prompt 3/Run 2/SPICE</td><td>0.0615</td></tr><tr><td>000481.jpg/Prompt 4/Run 1/CIDEr</td><td>4.2462</td></tr><tr><td>000481.jpg/Prompt 4/Run 1/Cosine</td><td>0.2275</td></tr><tr><td>000481.jpg/Prompt 4/Run 1/SPICE</td><td>0.0377</td></tr><tr><td>000481.jpg/Prompt 4/Run 2/CIDEr</td><td>4.2462</td></tr><tr><td>000481.jpg/Prompt 4/Run 2/Cosine</td><td>0.2275</td></tr><tr><td>000481.jpg/Prompt 4/Run 2/SPICE</td><td>0.0377</td></tr><tr><td>000481.jpg/Prompt 5/Run 1/CIDEr</td><td>1.917</td></tr><tr><td>000481.jpg/Prompt 5/Run 1/Cosine</td><td>0.5621</td></tr><tr><td>000481.jpg/Prompt 5/Run 1/SPICE</td><td>0.0645</td></tr><tr><td>000481.jpg/Prompt 5/Run 2/CIDEr</td><td>1.917</td></tr><tr><td>000481.jpg/Prompt 5/Run 2/Cosine</td><td>0.5621</td></tr><tr><td>000481.jpg/Prompt 5/Run 2/SPICE</td><td>0.0645</td></tr><tr><td>000481.jpg/Prompt 6/Run 1/CIDEr</td><td>0.4076</td></tr><tr><td>000481.jpg/Prompt 6/Run 1/Cosine</td><td>0.3424</td></tr><tr><td>000481.jpg/Prompt 6/Run 1/SPICE</td><td>0.0286</td></tr><tr><td>000481.jpg/Prompt 6/Run 2/CIDEr</td><td>0.4076</td></tr><tr><td>000481.jpg/Prompt 6/Run 2/Cosine</td><td>0.3424</td></tr><tr><td>000481.jpg/Prompt 6/Run 2/SPICE</td><td>0.0286</td></tr><tr><td>000520.jpg/Prompt 1/Run 1/CIDEr</td><td>1.0301</td></tr><tr><td>000520.jpg/Prompt 1/Run 1/Cosine</td><td>0.0567</td></tr><tr><td>000520.jpg/Prompt 1/Run 1/SPICE</td><td>0</td></tr><tr><td>000520.jpg/Prompt 1/Run 2/CIDEr</td><td>1.0301</td></tr><tr><td>000520.jpg/Prompt 1/Run 2/Cosine</td><td>0.0567</td></tr><tr><td>000520.jpg/Prompt 1/Run 2/SPICE</td><td>0</td></tr><tr><td>000520.jpg/Prompt 2/Run 1/CIDEr</td><td>3.7905</td></tr><tr><td>000520.jpg/Prompt 2/Run 1/Cosine</td><td>0.4014</td></tr><tr><td>000520.jpg/Prompt 2/Run 1/SPICE</td><td>0.0833</td></tr><tr><td>000520.jpg/Prompt 2/Run 2/CIDEr</td><td>3.7905</td></tr><tr><td>000520.jpg/Prompt 2/Run 2/Cosine</td><td>0.4014</td></tr><tr><td>000520.jpg/Prompt 2/Run 2/SPICE</td><td>0.0833</td></tr><tr><td>000520.jpg/Prompt 3/Run 1/CIDEr</td><td>2.8149</td></tr><tr><td>000520.jpg/Prompt 3/Run 1/Cosine</td><td>0.3681</td></tr><tr><td>000520.jpg/Prompt 3/Run 1/SPICE</td><td>0.0645</td></tr><tr><td>000520.jpg/Prompt 3/Run 2/CIDEr</td><td>2.8149</td></tr><tr><td>000520.jpg/Prompt 3/Run 2/Cosine</td><td>0.3681</td></tr><tr><td>000520.jpg/Prompt 3/Run 2/SPICE</td><td>0.0645</td></tr><tr><td>000520.jpg/Prompt 4/Run 1/CIDEr</td><td>1.5304</td></tr><tr><td>000520.jpg/Prompt 4/Run 1/Cosine</td><td>0.2219</td></tr><tr><td>000520.jpg/Prompt 4/Run 1/SPICE</td><td>0.0308</td></tr><tr><td>000520.jpg/Prompt 4/Run 2/CIDEr</td><td>1.5304</td></tr><tr><td>000520.jpg/Prompt 4/Run 2/Cosine</td><td>0.2219</td></tr><tr><td>000520.jpg/Prompt 4/Run 2/SPICE</td><td>0.0308</td></tr><tr><td>000520.jpg/Prompt 5/Run 1/CIDEr</td><td>3.7073</td></tr><tr><td>000520.jpg/Prompt 5/Run 1/Cosine</td><td>0.3431</td></tr><tr><td>000520.jpg/Prompt 5/Run 1/SPICE</td><td>0.0303</td></tr><tr><td>000520.jpg/Prompt 5/Run 2/CIDEr</td><td>3.7073</td></tr><tr><td>000520.jpg/Prompt 5/Run 2/Cosine</td><td>0.3431</td></tr><tr><td>000520.jpg/Prompt 5/Run 2/SPICE</td><td>0.0303</td></tr><tr><td>000520.jpg/Prompt 6/Run 1/CIDEr</td><td>0.3826</td></tr><tr><td>000520.jpg/Prompt 6/Run 1/Cosine</td><td>0.3467</td></tr><tr><td>000520.jpg/Prompt 6/Run 1/SPICE</td><td>0</td></tr><tr><td>000520.jpg/Prompt 6/Run 2/CIDEr</td><td>0.3826</td></tr><tr><td>000520.jpg/Prompt 6/Run 2/Cosine</td><td>0.3467</td></tr><tr><td>000520.jpg/Prompt 6/Run 2/SPICE</td><td>0</td></tr><tr><td>000541.jpg/Prompt 1/Run 1/CIDEr</td><td>1.6398</td></tr><tr><td>000541.jpg/Prompt 1/Run 1/Cosine</td><td>0.129</td></tr><tr><td>000541.jpg/Prompt 1/Run 1/SPICE</td><td>0</td></tr><tr><td>000541.jpg/Prompt 1/Run 2/CIDEr</td><td>1.6398</td></tr><tr><td>000541.jpg/Prompt 1/Run 2/Cosine</td><td>0.129</td></tr><tr><td>000541.jpg/Prompt 1/Run 2/SPICE</td><td>0</td></tr><tr><td>000541.jpg/Prompt 2/Run 1/CIDEr</td><td>0.5302</td></tr><tr><td>000541.jpg/Prompt 2/Run 1/Cosine</td><td>0.3268</td></tr><tr><td>000541.jpg/Prompt 2/Run 1/SPICE</td><td>0.0377</td></tr><tr><td>000541.jpg/Prompt 2/Run 2/CIDEr</td><td>0.5302</td></tr><tr><td>000541.jpg/Prompt 2/Run 2/Cosine</td><td>0.3268</td></tr><tr><td>000541.jpg/Prompt 2/Run 2/SPICE</td><td>0.0377</td></tr><tr><td>000541.jpg/Prompt 3/Run 1/CIDEr</td><td>2.8484</td></tr><tr><td>000541.jpg/Prompt 3/Run 1/Cosine</td><td>0.3393</td></tr><tr><td>000541.jpg/Prompt 3/Run 1/SPICE</td><td>0.0364</td></tr><tr><td>000541.jpg/Prompt 3/Run 2/CIDEr</td><td>2.8484</td></tr><tr><td>000541.jpg/Prompt 3/Run 2/Cosine</td><td>0.3393</td></tr><tr><td>000541.jpg/Prompt 3/Run 2/SPICE</td><td>0.0364</td></tr><tr><td>000541.jpg/Prompt 4/Run 1/CIDEr</td><td>2.1828</td></tr><tr><td>000541.jpg/Prompt 4/Run 1/Cosine</td><td>0.2624</td></tr><tr><td>000541.jpg/Prompt 4/Run 1/SPICE</td><td>0.0465</td></tr><tr><td>000541.jpg/Prompt 4/Run 2/CIDEr</td><td>2.1828</td></tr><tr><td>000541.jpg/Prompt 4/Run 2/Cosine</td><td>0.2624</td></tr><tr><td>000541.jpg/Prompt 4/Run 2/SPICE</td><td>0.0465</td></tr><tr><td>000541.jpg/Prompt 5/Run 1/CIDEr</td><td>3.7626</td></tr><tr><td>000541.jpg/Prompt 5/Run 1/Cosine</td><td>0.6124</td></tr><tr><td>000541.jpg/Prompt 5/Run 1/SPICE</td><td>0.0377</td></tr><tr><td>000541.jpg/Prompt 5/Run 2/CIDEr</td><td>3.7626</td></tr><tr><td>000541.jpg/Prompt 5/Run 2/Cosine</td><td>0.6124</td></tr><tr><td>000541.jpg/Prompt 5/Run 2/SPICE</td><td>0.0377</td></tr><tr><td>000541.jpg/Prompt 6/Run 1/CIDEr</td><td>3.3542</td></tr><tr><td>000541.jpg/Prompt 6/Run 1/Cosine</td><td>0.5492</td></tr><tr><td>000541.jpg/Prompt 6/Run 1/SPICE</td><td>0.0377</td></tr><tr><td>000541.jpg/Prompt 6/Run 2/CIDEr</td><td>3.3542</td></tr><tr><td>000541.jpg/Prompt 6/Run 2/Cosine</td><td>0.5492</td></tr><tr><td>000541.jpg/Prompt 6/Run 2/SPICE</td><td>0.0377</td></tr><tr><td>000698.jpg/Prompt 1/Run 1/CIDEr</td><td>1.063</td></tr><tr><td>000698.jpg/Prompt 1/Run 1/Cosine</td><td>0.0644</td></tr><tr><td>000698.jpg/Prompt 1/Run 1/SPICE</td><td>0</td></tr><tr><td>000698.jpg/Prompt 1/Run 2/CIDEr</td><td>1.063</td></tr><tr><td>000698.jpg/Prompt 1/Run 2/Cosine</td><td>0.0644</td></tr><tr><td>000698.jpg/Prompt 1/Run 2/SPICE</td><td>0</td></tr><tr><td>000698.jpg/Prompt 2/Run 1/CIDEr</td><td>0.4224</td></tr><tr><td>000698.jpg/Prompt 2/Run 1/Cosine</td><td>0.3501</td></tr><tr><td>000698.jpg/Prompt 2/Run 1/SPICE</td><td>0</td></tr><tr><td>000698.jpg/Prompt 2/Run 2/CIDEr</td><td>0.4224</td></tr><tr><td>000698.jpg/Prompt 2/Run 2/Cosine</td><td>0.3501</td></tr><tr><td>000698.jpg/Prompt 2/Run 2/SPICE</td><td>0</td></tr><tr><td>000698.jpg/Prompt 3/Run 1/CIDEr</td><td>2.9708</td></tr><tr><td>000698.jpg/Prompt 3/Run 1/Cosine</td><td>0.2731</td></tr><tr><td>000698.jpg/Prompt 3/Run 1/SPICE</td><td>0.0286</td></tr><tr><td>000698.jpg/Prompt 3/Run 2/CIDEr</td><td>2.9708</td></tr><tr><td>000698.jpg/Prompt 3/Run 2/Cosine</td><td>0.2731</td></tr><tr><td>000698.jpg/Prompt 3/Run 2/SPICE</td><td>0.0286</td></tr><tr><td>000698.jpg/Prompt 4/Run 1/CIDEr</td><td>1.0423</td></tr><tr><td>000698.jpg/Prompt 4/Run 1/Cosine</td><td>0.2116</td></tr><tr><td>000698.jpg/Prompt 4/Run 1/SPICE</td><td>0.0303</td></tr><tr><td>000698.jpg/Prompt 4/Run 2/CIDEr</td><td>1.0423</td></tr><tr><td>000698.jpg/Prompt 4/Run 2/Cosine</td><td>0.2116</td></tr><tr><td>000698.jpg/Prompt 4/Run 2/SPICE</td><td>0.0303</td></tr><tr><td>000698.jpg/Prompt 5/Run 1/CIDEr</td><td>3.6598</td></tr><tr><td>000698.jpg/Prompt 5/Run 1/Cosine</td><td>0.3526</td></tr><tr><td>000698.jpg/Prompt 5/Run 1/SPICE</td><td>0.0299</td></tr><tr><td>000698.jpg/Prompt 5/Run 2/CIDEr</td><td>3.6598</td></tr><tr><td>000698.jpg/Prompt 5/Run 2/Cosine</td><td>0.3526</td></tr><tr><td>000698.jpg/Prompt 5/Run 2/SPICE</td><td>0.0299</td></tr><tr><td>000698.jpg/Prompt 6/Run 1/CIDEr</td><td>0.6315</td></tr><tr><td>000698.jpg/Prompt 6/Run 1/Cosine</td><td>0.4422</td></tr><tr><td>000698.jpg/Prompt 6/Run 1/SPICE</td><td>0.0323</td></tr><tr><td>000698.jpg/Prompt 6/Run 2/CIDEr</td><td>0.6315</td></tr><tr><td>000698.jpg/Prompt 6/Run 2/Cosine</td><td>0.4422</td></tr><tr><td>000698.jpg/Prompt 6/Run 2/SPICE</td><td>0.0323</td></tr><tr><td>000740.jpg/Prompt 1/Run 1/CIDEr</td><td>2.583</td></tr><tr><td>000740.jpg/Prompt 1/Run 1/Cosine</td><td>0.2378</td></tr><tr><td>000740.jpg/Prompt 1/Run 1/SPICE</td><td>0</td></tr><tr><td>000740.jpg/Prompt 1/Run 2/CIDEr</td><td>2.583</td></tr><tr><td>000740.jpg/Prompt 1/Run 2/Cosine</td><td>0.2378</td></tr><tr><td>000740.jpg/Prompt 1/Run 2/SPICE</td><td>0</td></tr><tr><td>000740.jpg/Prompt 2/Run 1/CIDEr</td><td>0.5277</td></tr><tr><td>000740.jpg/Prompt 2/Run 1/Cosine</td><td>0.2976</td></tr><tr><td>000740.jpg/Prompt 2/Run 1/SPICE</td><td>0</td></tr><tr><td>000740.jpg/Prompt 2/Run 2/CIDEr</td><td>0.5277</td></tr><tr><td>000740.jpg/Prompt 2/Run 2/Cosine</td><td>0.2976</td></tr><tr><td>000740.jpg/Prompt 2/Run 2/SPICE</td><td>0</td></tr><tr><td>000740.jpg/Prompt 3/Run 1/CIDEr</td><td>1.7606</td></tr><tr><td>000740.jpg/Prompt 3/Run 1/Cosine</td><td>0.3304</td></tr><tr><td>000740.jpg/Prompt 3/Run 1/SPICE</td><td>0.0357</td></tr><tr><td>000740.jpg/Prompt 3/Run 2/CIDEr</td><td>1.7606</td></tr><tr><td>000740.jpg/Prompt 3/Run 2/Cosine</td><td>0.3304</td></tr><tr><td>000740.jpg/Prompt 3/Run 2/SPICE</td><td>0.0357</td></tr><tr><td>000740.jpg/Prompt 4/Run 1/CIDEr</td><td>0.8814</td></tr><tr><td>000740.jpg/Prompt 4/Run 1/Cosine</td><td>0.2488</td></tr><tr><td>000740.jpg/Prompt 4/Run 1/SPICE</td><td>0.1754</td></tr><tr><td>000740.jpg/Prompt 4/Run 2/CIDEr</td><td>0.8814</td></tr><tr><td>000740.jpg/Prompt 4/Run 2/Cosine</td><td>0.2488</td></tr><tr><td>000740.jpg/Prompt 4/Run 2/SPICE</td><td>0.1754</td></tr><tr><td>000740.jpg/Prompt 5/Run 1/CIDEr</td><td>4.0754</td></tr><tr><td>000740.jpg/Prompt 5/Run 1/Cosine</td><td>0.2695</td></tr><tr><td>000740.jpg/Prompt 5/Run 1/SPICE</td><td>0.0299</td></tr><tr><td>000740.jpg/Prompt 5/Run 2/CIDEr</td><td>4.0754</td></tr><tr><td>000740.jpg/Prompt 5/Run 2/Cosine</td><td>0.2695</td></tr><tr><td>000740.jpg/Prompt 5/Run 2/SPICE</td><td>0.0299</td></tr><tr><td>000740.jpg/Prompt 6/Run 1/CIDEr</td><td>2.6275</td></tr><tr><td>000740.jpg/Prompt 6/Run 1/Cosine</td><td>0.4512</td></tr><tr><td>000740.jpg/Prompt 6/Run 1/SPICE</td><td>0.0606</td></tr><tr><td>000740.jpg/Prompt 6/Run 2/CIDEr</td><td>2.6275</td></tr><tr><td>000740.jpg/Prompt 6/Run 2/Cosine</td><td>0.4512</td></tr><tr><td>000740.jpg/Prompt 6/Run 2/SPICE</td><td>0.0606</td></tr><tr><td>000869.jpg/Prompt 1/Run 1/CIDEr</td><td>0.9431</td></tr><tr><td>000869.jpg/Prompt 1/Run 1/Cosine</td><td>0.2412</td></tr><tr><td>000869.jpg/Prompt 1/Run 1/SPICE</td><td>0</td></tr><tr><td>000869.jpg/Prompt 1/Run 2/CIDEr</td><td>0.9431</td></tr><tr><td>000869.jpg/Prompt 1/Run 2/Cosine</td><td>0.2412</td></tr><tr><td>000869.jpg/Prompt 1/Run 2/SPICE</td><td>0</td></tr><tr><td>000869.jpg/Prompt 2/Run 1/CIDEr</td><td>1.5505</td></tr><tr><td>000869.jpg/Prompt 2/Run 1/Cosine</td><td>0.3566</td></tr><tr><td>000869.jpg/Prompt 2/Run 1/SPICE</td><td>0.0308</td></tr><tr><td>000869.jpg/Prompt 2/Run 2/CIDEr</td><td>1.5505</td></tr><tr><td>000869.jpg/Prompt 2/Run 2/Cosine</td><td>0.3566</td></tr><tr><td>000869.jpg/Prompt 2/Run 2/SPICE</td><td>0.0308</td></tr><tr><td>000869.jpg/Prompt 3/Run 1/CIDEr</td><td>2.4877</td></tr><tr><td>000869.jpg/Prompt 3/Run 1/Cosine</td><td>0.3856</td></tr><tr><td>000869.jpg/Prompt 3/Run 1/SPICE</td><td>0.0278</td></tr><tr><td>000869.jpg/Prompt 3/Run 2/CIDEr</td><td>2.4877</td></tr><tr><td>000869.jpg/Prompt 3/Run 2/Cosine</td><td>0.3856</td></tr><tr><td>000869.jpg/Prompt 3/Run 2/SPICE</td><td>0.0278</td></tr><tr><td>000869.jpg/Prompt 4/Run 1/CIDEr</td><td>1.4809</td></tr><tr><td>000869.jpg/Prompt 4/Run 1/Cosine</td><td>0.3107</td></tr><tr><td>000869.jpg/Prompt 4/Run 1/SPICE</td><td>0.0377</td></tr><tr><td>000869.jpg/Prompt 4/Run 2/CIDEr</td><td>1.4809</td></tr><tr><td>000869.jpg/Prompt 4/Run 2/Cosine</td><td>0.3107</td></tr><tr><td>000869.jpg/Prompt 4/Run 2/SPICE</td><td>0.0377</td></tr><tr><td>000869.jpg/Prompt 5/Run 1/CIDEr</td><td>2.5397</td></tr><tr><td>000869.jpg/Prompt 5/Run 1/Cosine</td><td>0.4458</td></tr><tr><td>000869.jpg/Prompt 5/Run 1/SPICE</td><td>0.0303</td></tr><tr><td>000869.jpg/Prompt 5/Run 2/CIDEr</td><td>2.5397</td></tr><tr><td>000869.jpg/Prompt 5/Run 2/Cosine</td><td>0.4458</td></tr><tr><td>000869.jpg/Prompt 5/Run 2/SPICE</td><td>0.0303</td></tr><tr><td>000869.jpg/Prompt 6/Run 1/CIDEr</td><td>1.1609</td></tr><tr><td>000869.jpg/Prompt 6/Run 1/Cosine</td><td>0.3323</td></tr><tr><td>000869.jpg/Prompt 6/Run 1/SPICE</td><td>0</td></tr><tr><td>000869.jpg/Prompt 6/Run 2/CIDEr</td><td>1.1609</td></tr><tr><td>000869.jpg/Prompt 6/Run 2/Cosine</td><td>0.3323</td></tr><tr><td>000869.jpg/Prompt 6/Run 2/SPICE</td><td>0</td></tr><tr><td>000889.jpg/Prompt 1/Run 1/CIDEr</td><td>3.1375</td></tr><tr><td>000889.jpg/Prompt 1/Run 1/Cosine</td><td>0.1464</td></tr><tr><td>000889.jpg/Prompt 1/Run 1/SPICE</td><td>0</td></tr><tr><td>000889.jpg/Prompt 1/Run 2/CIDEr</td><td>3.1375</td></tr><tr><td>000889.jpg/Prompt 1/Run 2/Cosine</td><td>0.1464</td></tr><tr><td>000889.jpg/Prompt 1/Run 2/SPICE</td><td>0</td></tr><tr><td>000889.jpg/Prompt 2/Run 1/CIDEr</td><td>2.2063</td></tr><tr><td>000889.jpg/Prompt 2/Run 1/Cosine</td><td>0.3584</td></tr><tr><td>000889.jpg/Prompt 2/Run 1/SPICE</td><td>0.0606</td></tr><tr><td>000889.jpg/Prompt 2/Run 2/CIDEr</td><td>2.2063</td></tr><tr><td>000889.jpg/Prompt 2/Run 2/Cosine</td><td>0.3584</td></tr><tr><td>000889.jpg/Prompt 2/Run 2/SPICE</td><td>0.0606</td></tr><tr><td>000889.jpg/Prompt 3/Run 1/CIDEr</td><td>2.0147</td></tr><tr><td>000889.jpg/Prompt 3/Run 1/Cosine</td><td>0.2865</td></tr><tr><td>000889.jpg/Prompt 3/Run 1/SPICE</td><td>0.0769</td></tr><tr><td>000889.jpg/Prompt 3/Run 2/CIDEr</td><td>2.0147</td></tr><tr><td>000889.jpg/Prompt 3/Run 2/Cosine</td><td>0.2865</td></tr><tr><td>000889.jpg/Prompt 3/Run 2/SPICE</td><td>0.0769</td></tr><tr><td>000889.jpg/Prompt 4/Run 1/CIDEr</td><td>1.4011</td></tr><tr><td>000889.jpg/Prompt 4/Run 1/Cosine</td><td>0.2248</td></tr><tr><td>000889.jpg/Prompt 4/Run 1/SPICE</td><td>0.0435</td></tr><tr><td>000889.jpg/Prompt 4/Run 2/CIDEr</td><td>1.4011</td></tr><tr><td>000889.jpg/Prompt 4/Run 2/Cosine</td><td>0.2248</td></tr><tr><td>000889.jpg/Prompt 4/Run 2/SPICE</td><td>0.0435</td></tr><tr><td>000889.jpg/Prompt 5/Run 1/CIDEr</td><td>2.8918</td></tr><tr><td>000889.jpg/Prompt 5/Run 1/Cosine</td><td>0.3675</td></tr><tr><td>000889.jpg/Prompt 5/Run 1/SPICE</td><td>0.0308</td></tr><tr><td>000889.jpg/Prompt 5/Run 2/CIDEr</td><td>2.8918</td></tr><tr><td>000889.jpg/Prompt 5/Run 2/Cosine</td><td>0.3675</td></tr><tr><td>000889.jpg/Prompt 5/Run 2/SPICE</td><td>0.0308</td></tr><tr><td>000889.jpg/Prompt 6/Run 1/CIDEr</td><td>0.132</td></tr><tr><td>000889.jpg/Prompt 6/Run 1/Cosine</td><td>0.4119</td></tr><tr><td>000889.jpg/Prompt 6/Run 1/SPICE</td><td>0</td></tr><tr><td>000889.jpg/Prompt 6/Run 2/CIDEr</td><td>0.132</td></tr><tr><td>000889.jpg/Prompt 6/Run 2/Cosine</td><td>0.4119</td></tr><tr><td>000889.jpg/Prompt 6/Run 2/SPICE</td><td>0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Prompt-Eval-Pixtral12B-CarDD</strong> at: <a href='https://wandb.ai/vlm-research/Prompting-Experiments/runs/6533z672' target=\"_blank\">https://wandb.ai/vlm-research/Prompting-Experiments/runs/6533z672</a><br> View project at: <a href='https://wandb.ai/vlm-research/Prompting-Experiments' target=\"_blank\">https://wandb.ai/vlm-research/Prompting-Experiments</a><br>Synced 5 W&B file(s), 1 media file(s), 12 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250515_174446-6533z672/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d421306c-8eb6-4008-98ea-22e4eb3a640c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
