{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "e5405616",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from unsloth import FastLanguageModel\n",
    "from transformers import AutoProcessor, TextStreamer\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "9080f8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image_caption_dataset(\n",
    "    image_folder: str,\n",
    "    captions_json: str,\n",
    "    caption_strategy: str = 'first'\n",
    ") -> pd.DataFrame:\n",
    "    with open(captions_json, 'r') as f:\n",
    "        captions_data = json.load(f)\n",
    "\n",
    "    data = []\n",
    "    for filename, caption_list in captions_data.items():\n",
    "        image_path = os.path.join(image_folder, filename)\n",
    "        if not os.path.exists(image_path):\n",
    "            continue\n",
    "        try:\n",
    "            image = Image.open(image_path).convert(\"RGB\")\n",
    "            caption = caption_list if caption_strategy == 'first' else random.choice(caption_list)\n",
    "            data.append({\"image\": image, \"caption\": caption, \"filename\": filename})\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Could not load {filename}: {e}\")\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bab70e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.4.7: Fast Qwen2_5_Vl patching. Transformers: 4.51.3.\n",
      "   \\\\   /|    NVIDIA A40. Num GPUs = 1. Max memory: 44.448 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 8.6. CUDA Toolkit: 12.6. Triton: 3.3.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e81261e8f6ed4b0294da026ec31357df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/5.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd32ea5619654b8a8013fcc1c998a76f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/267 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4c8677cf2814f51845d90db1d6c1bec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/575 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb8391a38174465f8a3cee58bae389cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/7.33k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80adfaed2972465d98ba3adae9d3009a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "020afaa859864667845719a021e21858",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5c4862ee0a945f6893faa10ce77e80f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0408f8670e104eac9bf58d9157b99878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/605 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3924c6a8ad748e3acfcfa97aff2e0e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8088248a3a8249b09e83752b5daf2d27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.json:   0%|          | 0.00/1.05k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6f35b98f631448bbeba0f9720d902d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/575 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ff461b8dacc42b49036cd62b87a3c79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/7.33k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c9f1c27e1e94453bb92fdd978ee3b32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c20dd3a3a64a41a58c5634445b839136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e324571752b34de29e5ded81a4271d86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48e24519e75349aa9c0329f7725b2c2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/605 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11aa15ba0dc7402abcaa5710b043a2e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a8c2c21f87b4aa1bdc7113600dee489",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.json:   0%|          | 0.00/1.05k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"unsloth/Qwen2.5-VL-7B-Instruct-bnb-4bit\"  # change if needed\n",
    "#unsloth/Pixtral-12B-2409-bnb-4bit\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = model_id,\n",
    "    dtype = torch.float16,\n",
    "    load_in_4bit = True,\n",
    "    device_map = \"auto\"\n",
    ")\n",
    "\n",
    "model = FastLanguageModel.for_inference(model)\n",
    "processor = AutoProcessor.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "71501eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 50 image-caption pairs\n"
     ]
    }
   ],
   "source": [
    "image_folder = \"/workspace/data/test_dataset\"\n",
    "captions_json = \"/workspace/data/test_set.json\"\n",
    "\n",
    "df = create_image_caption_dataset(image_folder, captions_json)\n",
    "print(f\"Loaded {len(df)} image-caption pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "99d52628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìå First 5 entries:\n",
      "                                               image  \\\n",
      "0  <PIL.Image.Image image mode=RGB size=1000x667 ...   \n",
      "1  <PIL.Image.Image image mode=RGB size=1000x667 ...   \n",
      "2  <PIL.Image.Image image mode=RGB size=1000x667 ...   \n",
      "3  <PIL.Image.Image image mode=RGB size=1000x750 ...   \n",
      "4  <PIL.Image.Image image mode=RGB size=1000x667 ...   \n",
      "\n",
      "                                             caption    filename  \n",
      "0  The car exhibits visible damage including a sc...  000481.jpg  \n",
      "1  The car exhibits significant damage to the win...  000433.jpg  \n",
      "2  The car exhibits a flat tire on the rear wheel...  000749.jpg  \n",
      "3  The car exhibits significant damage. The rear ...  000541.jpg  \n",
      "4  The car shows scratches along the side panel a...  000424.jpg   \n",
      "\n",
      "üìã Column types:\n",
      "image       object\n",
      "caption     object\n",
      "filename    object\n",
      "dtype: object\n",
      "\n",
      "üîé Size\n",
      "(50, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"üìå First 5 entries:\")\n",
    "print(df.head(), \"\\n\")\n",
    "\n",
    "print(\"üìã Column types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\nüîé Size\")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "6fabf79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "from transformers import TextStreamer\n",
    "import pandas as pd\n",
    "\n",
    "streamer = TextStreamer(tokenizer, skip_prompt=True)\n",
    "\n",
    "def run_vlm_inference(prompt: str, filename: str, df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Perform inference on a given image (by filename) from the dataframe using a custom prompt.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The prompt text (can include mask tokens)\n",
    "        filename (str): Filename of the image in the DataFrame\n",
    "        df (pd.DataFrame): DataFrame with 'filename' and 'image' columns\n",
    "\n",
    "    Returns:\n",
    "        Tuple[str, float, float]: (Generated output, inference time in seconds, VRAM used in GB)\n",
    "    \"\"\"\n",
    "    row = df[df[\"filename\"] == filename]\n",
    "    if row.empty:\n",
    "        print(f\"[ERROR] No image found with filename: {filename}\")\n",
    "        return None, 0.0, 0.0\n",
    "\n",
    "    row = row.iloc[0]\n",
    "    image = row[\"image\"]\n",
    "    caption = row[\"caption\"]\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompt},\n",
    "                {\"type\": \"image\", \"image\": image}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    input_text = tokenizer.apply_chat_template(messages, add_generation_prompt=True)\n",
    "    inputs = processor(images=image, text=input_text, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    start_mem = torch.cuda.memory_allocated() / 1024 / 1024 / 1024  # in GB\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(f\"üîπ Image: {filename}\")\n",
    "    print(f\"üßæ Prompt: {prompt}\")\n",
    "    print(\"üì§ Output:\")\n",
    "    \n",
    "    # Perform inference\n",
    "    output_ids = model.generate(\n",
    "        **inputs,\n",
    "        streamer=streamer,\n",
    "        max_new_tokens=128,\n",
    "        use_cache=True,\n",
    "        temperature=1.0,\n",
    "        top_p=0.95\n",
    "    )\n",
    "\n",
    "    end_time = time.time()\n",
    "    end_mem = torch.cuda.max_memory_allocated() / 1024**3\n",
    "\n",
    "    time_taken = round(end_time - start_time, 3)\n",
    "    vram_used = round(end_mem - start_mem, 3)\n",
    "    decoded_output = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    print(f\"‚è±Ô∏è Time taken: {time_taken} sec | üß† VRAM used: {vram_used} GB\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    return decoded_output, time_taken, vram_used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b21278-7d01-4918-be1a-2c1951787df2",
   "metadata": {},
   "source": [
    "### Test Images\r\n",
    "\r\n",
    "000404.jpg\r\n",
    "000422.jpg\r\n",
    "000433.jpg\r\n",
    "000481.jpg\r\n",
    "000520.jpg\r\n",
    "000541.jpg\r\n",
    "000698.jpg\r\n",
    "000740.jpg\r\n",
    "000869.jpg\r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "21a6f630-0b10-49de-9b34-e2da40a4bff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Image: 000889.jpg\n",
      "üßæ Prompt: \n",
      "üì§ Output:\n",
      "The image shows the side window of a car that has been shattered, likely due to an impact or explosion. The glass is broken into small pieces, and some of it appears to be still adhering to the window frame. The interior of the car is partially visible through the broken window, showing the steering wheel and dashboard. The background outside the car includes trees and a cloudy sky, suggesting the photo was taken outdoors on a day with overcast weather.<|im_end|>\n",
      "‚è±Ô∏è Time taken: 5.082 sec | üß† VRAM used: 0.343 GB\n",
      "--------------------------------------------------------------------------------\n",
      "üîπ Image: 000889.jpg\n",
      "üßæ Prompt: Describe &&damage 12 sedan drive‚Äô this !!image.\n",
      "üì§ Output:\n",
      "The image shows the side window of a sedan that has been severely damaged. The glass is shattered into numerous pieces, with large chunks missing and the remaining glass broken into smaller fragments. The damage appears to be extensive, likely caused by an impact or explosion. The interior of the car is partially visible through the broken window, showing the steering wheel and dashboard. The overall condition of the vehicle suggests significant structural damage beyond just the window.<|im_end|>\n",
      "‚è±Ô∏è Time taken: 4.788 sec | üß† VRAM used: 0.346 GB\n",
      "--------------------------------------------------------------------------------\n",
      "üîπ Image: 000889.jpg\n",
      "üßæ Prompt: An image of a damaged car parked on the side of the road.\n",
      "üì§ Output:\n",
      "The image shows a car with significant damage to its side window, which appears to be shattered into pieces. The broken glass is scattered across the window and the surrounding area. This type of damage could be caused by various factors such as vandalism, an accident, or an impact from an object. If this were your vehicle, it would be advisable to contact insurance to report the damage and arrange for repairs. Additionally, ensure that the vehicle is safe to drive before attempting to move it.<|im_end|>\n",
      "‚è±Ô∏è Time taken: 5.208 sec | üß† VRAM used: 0.346 GB\n",
      "--------------------------------------------------------------------------------\n",
      "üîπ Image: 000889.jpg\n",
      "üßæ Prompt: You are an insurance claims assessor. Provide a detailed description of the car‚Äôs condition.\n",
      "üì§ Output:\n",
      "The image shows a vehicle with significant damage to its rear passenger-side window. The glass is shattered, with large pieces of broken glass scattered across the interior and exterior surfaces of the window frame. The damage appears to be extensive, likely caused by an impact or explosion. The surrounding area of the window frame looks intact, suggesting that the breakage did not extend into the structural components of the car.\n",
      "\n",
      "The steering wheel and dashboard are visible through the broken window, indicating that the driver's side window is also affected but not as severely as the rear passenger-side window. There are no visible signs of damage to the car's bodywork outside the window\n",
      "‚è±Ô∏è Time taken: 6.812 sec | üß† VRAM used: 0.348 GB\n",
      "--------------------------------------------------------------------------------\n",
      "üîπ Image: 000889.jpg\n",
      "üßæ Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "üì§ Output:\n",
      "The part of the car shown in the image is the side window, which has been shattered. The severity of the damage appears to be significant, as the glass is completely broken and scattered across the interior of the car. Additional notes include that the damage seems to have occurred recently, possibly due to an impact or explosion, given the sharp edges of the broken glass.<|im_end|>\n",
      "‚è±Ô∏è Time taken: 4.05 sec | üß† VRAM used: 0.351 GB\n",
      "--------------------------------------------------------------------------------\n",
      "üîπ Image: 000889.jpg\n",
      "üßæ Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "üì§ Output:\n",
      "Damage Type: Shattering; Affected Part: Rear Window; Severity: Moderate; Notes: The rear window has a significant crack and shattered glass, indicating a moderate level of damage likely caused by an impact or explosion.<|im_end|>\n",
      "‚è±Ô∏è Time taken: 2.599 sec | üß† VRAM used: 0.348 GB\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "filename=\"000889.jpg\"\n",
    "\n",
    "row = df[df[\"filename\"] == filename]\n",
    "ground_truth = row.iloc[0][\"caption\"]\n",
    "\n",
    "inference_outputs = []\n",
    "vram_usages = []\n",
    "inference_times = []\n",
    "\n",
    "prompts = [\n",
    "    \"\",  # Prompt 1: No Prompt\n",
    "    \"Describe &&damage 12 sedan drive‚Äô this !!image.\",  # Noisy\n",
    "    \"An image of a damaged car parked on the side of the road.\",  # Hand-crafted\n",
    "    \"You are an insurance claims assessor. Provide a detailed description of the car‚Äôs condition.\",  # Roleplay\n",
    "    \"This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\",  # Masked\n",
    "    \"Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\"  # Format-Guided\n",
    "]\n",
    "\n",
    "for prompt in prompts:\n",
    "    output, time_taken, vram = run_vlm_inference(prompt, filename, df=df)\n",
    "    inference_outputs.append(output)\n",
    "    vram_usages.append(vram)\n",
    "    inference_times.append(time_taken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "3d38bf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "from pycocoevalcap.cider.cider import Cider\n",
    "from pycocoevalcap.spice.spice import Spice\n",
    "from pycocoevalcap.tokenizer.ptbtokenizer import PTBTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "1974cc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cosine_similarity(reference_captions, generated_caption):\n",
    "    try:\n",
    "        total_score = 0.0\n",
    "        for caption in reference_captions:\n",
    "            ref_embed = sbert_model.encode(caption, convert_to_tensor=True)\n",
    "            gen_embed = sbert_model.encode(generated_caption, convert_to_tensor=True)\n",
    "            score = util.cos_sim(gen_embed, ref_embed).item()\n",
    "            total_score += score\n",
    "        avg_score = total_score / len(reference_captions) if reference_captions else 0.0\n",
    "        return avg_score\n",
    "    except Exception as e:\n",
    "        print(f\"Error computing cosine similarity: {e}\")\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "3f9b8529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cider_spice_scores(reference_caption, generated_caption):\n",
    "    refs = {0: [reference_caption if reference_caption else \"\"]}\n",
    "    hypos = {0: [generated_caption if generated_caption else \"\"]}\n",
    "\n",
    "    # print(f\"Generated caption: {generated_caption}\")\n",
    "    # print(f\"Generated hypos: {hypos}\")\n",
    "\n",
    "    ptb = PTBTokenizer()\n",
    "    refs_tok = ptb.tokenize({i: [{\"caption\": c} for c in caps] for i, caps in refs.items()})\n",
    "    hypos_tok = ptb.tokenize({i: [{\"caption\": hypos[i][0]}] for i in hypos})\n",
    "\n",
    "    all_scores = {}\n",
    "\n",
    "    for scorer, name in [(Cider(), \"CIDEr\"), (Spice(), \"SPICE\")]:\n",
    "        try:\n",
    "            avg_score, _ = scorer.compute_score(refs_tok, hypos_tok)\n",
    "            if name == \"SPICE\":\n",
    "                # SPICE returns dicts per image\n",
    "                all_scores[name] = avg_score.get(\"All\", {}).get(\"f\", 0.0) if isinstance(avg_score, dict) else avg_score\n",
    "            else:\n",
    "                all_scores[name] = avg_score\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] {name} scoring failed: {e}\")\n",
    "            all_scores[name] = 0.0\n",
    "\n",
    "    return all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "57f4d517-34af-4a79-bb29-25613a22c9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cider import Cider\n",
    "\n",
    "PICKLE_PATH = \"/workspace/data/cardd-df.p\"\n",
    "\n",
    "def compute_cider2_score(reference_caption, generated_caption):\n",
    "    \"\"\"\n",
    "    Computes CIDEr score using new evaluate_cider logic with precomputed DF pickle.\n",
    "\n",
    "    Args:\n",
    "        reference_caption (str or list): Ground truth caption(s)\n",
    "        generated_caption (str): Model output\n",
    "\n",
    "    Returns:\n",
    "        float: CIDEr score (averaged if multiple refs)\n",
    "    \"\"\"\n",
    "    refs = {\"0\": reference_caption if isinstance(reference_caption, list) else [reference_caption]}\n",
    "    hypos = [{\"image_id\": \"0\", \"caption\": [generated_caption]}]  # Fix: caption should be a list\n",
    "\n",
    "    cider = Cider()\n",
    "    score, _ = cider.compute_score(refs, hypos, PICKLE_PATH)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "035e2bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_all_metrics(reference_caption, generated_caption):\n",
    "    cider_spice_scores = compute_cider_spice_scores(reference_caption, generated_caption)\n",
    "    cosine_sim = compute_cosine_similarity([reference_caption], generated_caption)\n",
    "    cider2 = compute_cider2_score(reference_caption, generated_caption)\n",
    "\n",
    "    return {\n",
    "        \"cosine_similarity\": round(cosine_sim, 4),\n",
    "        #\"CIDEr\": round(cider_spice_scores.get(\"CIDEr\", 0.0), 4),\n",
    "        \"SPICE\": round(cider_spice_scores.get(\"SPICE\", 0.0), 4),\n",
    "        \"CIDEr\": round(cider2, 4)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "36332c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The car exhibits significant damage to the driver's side window, which is shattered extensively. The glass is fragmented and broken, with large pieces missing, indicating a severe impact. \n",
      "['system\\nYou are a helpful assistant.\\nuser\\n\\nassistant\\nThe image shows the side window of a car that has been shattered, likely due to an impact or explosion. The glass is broken into small pieces, and some of it appears to be still adhering to the window frame. The interior of the car is partially visible through the broken window, showing the steering wheel and dashboard. The background outside the car includes trees and a cloudy sky, suggesting the photo was taken outdoors on a day with overcast weather.', 'system\\nYou are a helpful assistant.\\nuser\\nDescribe &&damage 12 sedan drive‚Äô this !!image.\\nassistant\\nThe image shows the side window of a sedan that has been severely damaged. The glass is shattered into numerous pieces, with large chunks missing and the remaining glass broken into smaller fragments. The damage appears to be extensive, likely caused by an impact or explosion. The interior of the car is partially visible through the broken window, showing the steering wheel and dashboard. The overall condition of the vehicle suggests significant structural damage beyond just the window.', 'system\\nYou are a helpful assistant.\\nuser\\nAn image of a damaged car parked on the side of the road.\\nassistant\\nThe image shows a car with significant damage to its side window, which appears to be shattered into pieces. The broken glass is scattered across the window and the surrounding area. This type of damage could be caused by various factors such as vandalism, an accident, or an impact from an object. If this were your vehicle, it would be advisable to contact insurance to report the damage and arrange for repairs. Additionally, ensure that the vehicle is safe to drive before attempting to move it.', \"system\\nYou are a helpful assistant.\\nuser\\nYou are an insurance claims assessor. Provide a detailed description of the car‚Äôs condition.\\nassistant\\nThe image shows a vehicle with significant damage to its rear passenger-side window. The glass is shattered, with large pieces of broken glass scattered across the interior and exterior surfaces of the window frame. The damage appears to be extensive, likely caused by an impact or explosion. The surrounding area of the window frame looks intact, suggesting that the breakage did not extend into the structural components of the car.\\n\\nThe steering wheel and dashboard are visible through the broken window, indicating that the driver's side window is also affected but not as severely as the rear passenger-side window. There are no visible signs of damage to the car's bodywork outside the window\", 'system\\nYou are a helpful assistant.\\nuser\\nThis <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\\nassistant\\nThe part of the car shown in the image is the side window, which has been shattered. The severity of the damage appears to be significant, as the glass is completely broken and scattered across the interior of the car. Additional notes include that the damage seems to have occurred recently, possibly due to an impact or explosion, given the sharp edges of the broken glass.', 'system\\nYou are a helpful assistant.\\nuser\\nDescribe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\\nassistant\\nDamage Type: Shattering; Affected Part: Rear Window; Severity: Moderate; Notes: The rear window has a significant crack and shattered glass, indicating a moderate level of damage likely caused by an impact or explosion.']\n",
      "[0.343, 0.346, 0.346, 0.348, 0.351, 0.348]\n",
      "[5.082, 4.788, 5.208, 6.812, 4.05, 2.599]\n"
     ]
    }
   ],
   "source": [
    "print(ground_truth)\n",
    "print(inference_outputs)\n",
    "print(vram_usages)\n",
    "print(inference_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "e8b2100b-1268-4fe2-816a-c46a3ed0cbb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 1 Output:\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "\n",
      "assistant\n",
      "The image shows the side window of a car that has been shattered, likely due to an impact or explosion. The glass is broken into small pieces, and some of it appears to be still adhering to the window frame. The interior of the car is partially visible through the broken window, showing the steering wheel and dashboard. The background outside the car includes trees and a cloudy sky, suggesting the photo was taken outdoors on a day with overcast weather.\n",
      "Reference:\n",
      "The car exhibits significant damage to the driver's side window, which is shattered extensively. The glass is fragmented and broken, with large pieces missing, indicating a severe impact. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 34 tokens at 553.38 tokens per second.\n",
      "PTBTokenizer tokenized 98 tokens at 2178.72 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 750.4 ms\n",
      "\n",
      "Prompt 2 Output:\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "Describe &&damage 12 sedan drive‚Äô this !!image.\n",
      "assistant\n",
      "The image shows the side window of a sedan that has been severely damaged. The glass is shattered into numerous pieces, with large chunks missing and the remaining glass broken into smaller fragments. The damage appears to be extensive, likely caused by an impact or explosion. The interior of the car is partially visible through the broken window, showing the steering wheel and dashboard. The overall condition of the vehicle suggests significant structural damage beyond just the window.\n",
      "Reference:\n",
      "The car exhibits significant damage to the driver's side window, which is shattered extensively. The glass is fragmented and broken, with large pieces missing, indicating a severe impact. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 34 tokens at 733.48 tokens per second.\n",
      "PTBTokenizer tokenized 107 tokens at 2108.39 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.6 sec].\n",
      "Threads( StanfordCoreNLP ) [3.749 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"system you are a helpful assistant user describe & & damage 12 sedan drive this !! image assistant the image shows the side window of a sedan that has been severely damaged the glass is shattered into numerous pieces with large chunks missing and the remaining glass broken into smaller fragments the damage appears to be extensive likely caused by an impact or explosion the interior of the car is partially visible through the broken window showing the steering wheel and dashboard the overall condition of the vehicle suggests significant structural damage beyond just the window\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 9.464 s\n",
      "\n",
      "Prompt 3 Output:\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "An image of a damaged car parked on the side of the road.\n",
      "assistant\n",
      "The image shows a car with significant damage to its side window, which appears to be shattered into pieces. The broken glass is scattered across the window and the surrounding area. This type of damage could be caused by various factors such as vandalism, an accident, or an impact from an object. If this were your vehicle, it would be advisable to contact insurance to report the damage and arrange for repairs. Additionally, ensure that the vehicle is safe to drive before attempting to move it.\n",
      "Reference:\n",
      "The car exhibits significant damage to the driver's side window, which is shattered extensively. The glass is fragmented and broken, with large pieces missing, indicating a severe impact. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 34 tokens at 848.23 tokens per second.\n",
      "PTBTokenizer tokenized 119 tokens at 2897.14 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.6 sec].\n",
      "Threads( StanfordCoreNLP ) [7.751 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"system you are a helpful assistant user an image of a damaged car parked on the side of the road assistant the image shows a car with significant damage to its side window which appears to be shattered into pieces the broken glass is scattered across the window and the surrounding area this type of damage could be caused by various factors such as vandalism an accident or an impact from an object if this were your vehicle it would be advisable to contact insurance to report the damage and arrange for repairs additionally ensure that the vehicle is safe to drive before attempting to move it\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.52 s\n",
      "\n",
      "Prompt 4 Output:\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "You are an insurance claims assessor. Provide a detailed description of the car‚Äôs condition.\n",
      "assistant\n",
      "The image shows a vehicle with significant damage to its rear passenger-side window. The glass is shattered, with large pieces of broken glass scattered across the interior and exterior surfaces of the window frame. The damage appears to be extensive, likely caused by an impact or explosion. The surrounding area of the window frame looks intact, suggesting that the breakage did not extend into the structural components of the car.\n",
      "\n",
      "The steering wheel and dashboard are visible through the broken window, indicating that the driver's side window is also affected but not as severely as the rear passenger-side window. There are no visible signs of damage to the car's bodywork outside the window\n",
      "Reference:\n",
      "The car exhibits significant damage to the driver's side window, which is shattered extensively. The glass is fragmented and broken, with large pieces missing, indicating a severe impact. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 34 tokens at 784.22 tokens per second.\n",
      "PTBTokenizer tokenized 150 tokens at 2743.64 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [10.665 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"system you are a helpful assistant user you are an insurance claims assessor provide a detailed description of the car 's condition assistant the image shows a vehicle with significant damage to its rear passenger-side window the glass is shattered with large pieces of broken glass scattered across the interior and exterior surfaces of the window frame the damage appears to be extensive likely caused by an impact or explosion the surrounding area of the window frame looks intact suggesting that the breakage did not extend into the structural components of the car the steering wheel and dashboard are visible through the broken window indicating that the driver 's side window is also affected but not as severely as the rear passenger-side window there are no visible signs of damage to the car 's bodywork outside the window\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.26 s\n",
      "\n",
      "Prompt 5 Output:\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "assistant\n",
      "The part of the car shown in the image is the side window, which has been shattered. The severity of the damage appears to be significant, as the glass is completely broken and scattered across the interior of the car. Additional notes include that the damage seems to have occurred recently, possibly due to an impact or explosion, given the sharp edges of the broken glass.\n",
      "Reference:\n",
      "The car exhibits significant damage to the driver's side window, which is shattered extensively. The glass is fragmented and broken, with large pieces missing, indicating a severe impact. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 34 tokens at 726.60 tokens per second.\n",
      "PTBTokenizer tokenized 102 tokens at 1818.95 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [4.517 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"system you are a helpful assistant user this <part_1> of the car has <damage_type_1> the severity appears to be <severity_1> additional notes <text_1> assistant the part of the car shown in the image is the side window which has been shattered the severity of the damage appears to be significant as the glass is completely broken and scattered across the interior of the car additional notes include that the damage seems to have occurred recently possibly due to an impact or explosion given the sharp edges of the broken glass\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 10.30 s\n",
      "\n",
      "Prompt 6 Output:\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "assistant\n",
      "Damage Type: Shattering; Affected Part: Rear Window; Severity: Moderate; Notes: The rear window has a significant crack and shattered glass, indicating a moderate level of damage likely caused by an impact or explosion.\n",
      "Reference:\n",
      "The car exhibits significant damage to the driver's side window, which is shattered extensively. The glass is fragmented and broken, with large pieces missing, indicating a severe impact. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 34 tokens at 733.14 tokens per second.\n",
      "PTBTokenizer tokenized 72 tokens at 1777.53 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 756.5 ms\n"
     ]
    }
   ],
   "source": [
    "all_scores = []\n",
    "\n",
    "for i, gen in enumerate(inference_outputs):\n",
    "    print(f\"\\nPrompt {i+1} Output:\\n{gen}\\nReference:\\n{ground_truth}\")\n",
    "    scores = evaluate_all_metrics(ground_truth, gen)\n",
    "    all_scores.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "093e00a7-2a5b-4ee1-ba53-4f463205070f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cosine_similarity</th>\n",
       "      <th>SPICE</th>\n",
       "      <th>CIDEr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Prompt 1</th>\n",
       "      <td>0.7445</td>\n",
       "      <td>0.2143</td>\n",
       "      <td>1.3744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prompt 2</th>\n",
       "      <td>0.8491</td>\n",
       "      <td>0.2769</td>\n",
       "      <td>1.4790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prompt 3</th>\n",
       "      <td>0.7759</td>\n",
       "      <td>0.2581</td>\n",
       "      <td>1.4910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prompt 4</th>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.2558</td>\n",
       "      <td>1.6658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prompt 5</th>\n",
       "      <td>0.8208</td>\n",
       "      <td>0.2642</td>\n",
       "      <td>1.1502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prompt 6</th>\n",
       "      <td>0.6326</td>\n",
       "      <td>0.1356</td>\n",
       "      <td>0.5604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          cosine_similarity   SPICE   CIDEr\n",
       "Prompt 1             0.7445  0.2143  1.3744\n",
       "Prompt 2             0.8491  0.2769  1.4790\n",
       "Prompt 3             0.7759  0.2581  1.4910\n",
       "Prompt 4             0.8000  0.2558  1.6658\n",
       "Prompt 5             0.8208  0.2642  1.1502\n",
       "Prompt 6             0.6326  0.1356  0.5604"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df = pd.DataFrame(all_scores, index=[f\"Prompt {i+1}\" for i in range(len(inference_outputs))])\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "c88d3c1d-92d1-41d0-9b3d-f1e9c36cea7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openpyxl import Workbook, load_workbook\n",
    "from openpyxl.drawing.image import Image as ExcelImage\n",
    "from openpyxl.styles import Alignment\n",
    "from PIL import Image as PILImage\n",
    "import os\n",
    "\n",
    "def log_prompt_metrics_to_excel(\n",
    "    filename: str,\n",
    "    model_name: str,\n",
    "    inference_outputs: list,\n",
    "    metrics: list,\n",
    "    inference_times: list,\n",
    "    vram_usages: list,\n",
    "    df: pd.DataFrame,\n",
    "    output_excel_path: str = \"prompt_tuning_results_cardd_qwen.xlsx\"\n",
    "):\n",
    "    row = df[df[\"filename\"] == filename].iloc[0]\n",
    "    original_caption = row[\"caption\"]\n",
    "    image_path = os.path.join(\"/workspace/data/test_dataset\", filename)\n",
    "\n",
    "    # Load or create workbook\n",
    "    if os.path.exists(output_excel_path):\n",
    "        wb = load_workbook(output_excel_path)\n",
    "        ws = wb.active\n",
    "    else:\n",
    "        wb = Workbook()\n",
    "        ws = wb.active\n",
    "        ws.title = \"Prompt Evaluation\"\n",
    "        headers = [\n",
    "            \"Model\", \"Image Number\", \"Image\", \"Original Caption\",\n",
    "            \"Prompt\", \"Output\", \"Inference Time (s)\", \"VRAM Used (GB)\",\n",
    "            \"CIDEr\", \"SPICE\", \"Cosine Similarity\"\n",
    "        ]\n",
    "        ws.append(headers)\n",
    "\n",
    "    # Find the next empty row\n",
    "    start_row = ws.max_row + 1\n",
    "\n",
    "    # Append data\n",
    "    for i in range(6):\n",
    "        ws.append([\n",
    "            model_name,\n",
    "            filename,\n",
    "            \"\",  # placeholder for image\n",
    "            original_caption,\n",
    "            f\"Prompt {i+1}\",\n",
    "            inference_outputs[i],\n",
    "            inference_times[i],\n",
    "            vram_usages[i],\n",
    "            metrics[i][\"CIDEr\"],\n",
    "            metrics[i][\"SPICE\"],\n",
    "            metrics[i][\"cosine_similarity\"]\n",
    "        ])\n",
    "\n",
    "    # Merge A‚ÄìD columns across the 6 rows\n",
    "    for col in [\"A\", \"B\", \"C\", \"D\"]:\n",
    "        ws.merge_cells(f\"{col}{start_row}:{col}{start_row + 5}\")\n",
    "\n",
    "    # Apply alignment\n",
    "    align_top_wrap = Alignment(wrap_text=True, vertical=\"top\")\n",
    "    align_top = Alignment(vertical=\"top\")\n",
    "\n",
    "    for row in range(start_row, start_row + 6):\n",
    "        for col_letter in [\"A\", \"B\", \"C\", \"E\"]:\n",
    "            ws[f\"{col_letter}{row}\"].alignment = align_top\n",
    "        for col_letter in [\"D\", \"F\"]:\n",
    "            ws[f\"{col_letter}{row}\"].alignment = align_top_wrap\n",
    "        ws.row_dimensions[row].height = 120\n",
    "\n",
    "    # Set column widths\n",
    "    ws.column_dimensions[\"D\"].width = 40  # Original Caption\n",
    "    ws.column_dimensions[\"F\"].width = 40  # Output\n",
    "\n",
    "    # Embed image\n",
    "    if os.path.exists(image_path):\n",
    "        print(f\"[INFO] Inserting image: {image_path}\")\n",
    "        try:\n",
    "            img = ExcelImage(image_path)\n",
    "            img.width = 150\n",
    "            img.height = 150\n",
    "            img.anchor = f\"C{start_row}\"\n",
    "            ws.add_image(img)\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Could not insert image: {e}\")\n",
    "\n",
    "    wb.save(output_excel_path)\n",
    "    print(f\"‚úÖ Logged metrics for {filename} to {output_excel_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "dd7d5bfd-a9fc-4e36-89d6-238542869d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Inserting image: /workspace/data/test_dataset/000889.jpg\n",
      "‚úÖ Logged metrics for 000889.jpg to prompt_tuning_results_cardd_qwen.xlsx\n"
     ]
    }
   ],
   "source": [
    "log_prompt_metrics_to_excel(\n",
    "    filename=filename,\n",
    "    model_name=model_id,\n",
    "    inference_outputs=inference_outputs,\n",
    "    metrics=all_scores,\n",
    "    inference_times=inference_times,\n",
    "    vram_usages=vram_usages,\n",
    "    df=df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd783220-02a4-4fd8-a655-bb5ef7e7fb91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
