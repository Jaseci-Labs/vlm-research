{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93361d37-7eac-4abb-97f9-faacc6d701b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
      "Standard import failed for UnslothDPOTrainer: No module named 'UnslothDPOTrainer'. Using tempfile instead!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from unsloth import FastVisionModel, FastLanguageModel\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from transformers import AutoProcessor, TextStreamer\n",
    "import nltk\n",
    "from datasets import load_from_disk\n",
    "\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97e52241-aec0-4f63-aaf8-bd76e51e5cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgayanukaa\u001b[0m (\u001b[33mvlm-research\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250515_083251-tg5zjjbg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vlm-research/Prompting-Experiments/runs/tg5zjjbg' target=\"_blank\">Prompt-Eval-Pixtral12B-Flickr30k</a></strong> to <a href='https://wandb.ai/vlm-research/Prompting-Experiments' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vlm-research/Prompting-Experiments' target=\"_blank\">https://wandb.ai/vlm-research/Prompting-Experiments</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vlm-research/Prompting-Experiments/runs/tg5zjjbg' target=\"_blank\">https://wandb.ai/vlm-research/Prompting-Experiments/runs/tg5zjjbg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/vlm-research/Prompting-Experiments/runs/tg5zjjbg?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x78fe9a9698a0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init(\n",
    "    project=\"Prompting-Experiments\",\n",
    "    name=\"Prompt-Eval-Pixtral12B-Flickr30k\",\n",
    "    group=\"prompting-experiments\",\n",
    "    tags=[\"pixtral\", \"image-captioning\", \"prompting\", \"flickr30k\"],\n",
    "    notes=\"Comparing handcrafted prompting strategies across multiple images and prompt types.\",\n",
    "    config={\n",
    "        \"model\": \"Pixtral-12B\",\n",
    "        \"prompting\": \"handcrafted\",\n",
    "        \"num_prompts\": 6,\n",
    "        \"num_runs_per_prompt\": 2,\n",
    "        \"dataset\": \"flickr30k\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c59bc64-858c-48d1-bc34-f29f04f3edf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.5.3: Fast Mistral patching. Transformers: 4.51.3.\n",
      "   \\\\   /|    NVIDIA A40. Num GPUs = 1. Max memory: 44.448 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 8.6. CUDA Toolkit: 12.6. Triton: 3.3.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "Unsloth: Mistral does not support SDPA - switching to eager!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d746cf2d86c849a380eac6194a273a21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/214k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7fe43fe517e4cf5851d911fe7d308ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b466f56edc604f2688b190de60731029",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/4.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc051da1782645f08c266cd1bc3f52ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "104aae7451864911a817c6b1609ad4c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/133 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "694319aeee594df487d88422563d97db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "processor_config.json:   0%|          | 0.00/162 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6983be87b93046f78e8ee8f4bf2276d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.json:   0%|          | 0.00/1.59k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcb3286e14314a1790f255a8a80f9354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa77af58fd1647a2ac737fd245f3cb67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/177k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69fe0ad300574923929060cee7d8268b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbac5fb90ac6474ebdf78ac2e1d65639",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/552 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, tokenizer = FastVisionModel.from_pretrained(\n",
    "    \"unsloth/Pixtral-12B-2409\",\n",
    "    load_in_4bit = True,\n",
    "    use_gradient_checkpointing = \"unsloth\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "decc91c6-c815-4ec1-8939-2f7fb22ffa9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7ac66e8e3054df3ae338d0fa2a414be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "processor_config.json:   0%|          | 0.00/162 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cee03ca3372443b589723708bbfcb11e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.json:   0%|          | 0.00/1.59k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e07b24a11f04f88b033ddea38444c56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e87b0ceecefc4f8191c7a8af7428fd15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/177k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c75bc8b88bd4ce6bd80386a5cd90fb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "182848ae92a54d728f7711a9a62e0f1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/552 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"unsloth/Pixtral-12B-2409\"\n",
    "\n",
    "model = FastVisionModel.for_inference(model)\n",
    "processor = AutoProcessor.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac930dd8-f59b-4361-bae0-c39f77143b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = load_from_disk(\"/workspace/data/filtered_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ddd2b1d-955f-4085-827e-1e0a20c7f2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered test Dataset:\n",
      "Dataset({\n",
      "    features: ['image', 'caption', 'sentids', 'split', 'img_id', 'filename'],\n",
      "    num_rows: 10\n",
      "})\n",
      "Loaded 10 image-caption entries\n",
      "\n",
      "📌 First 5 entries:\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x375 at 0x78FE979092D0>, 'caption': ['Three Caucasian hikers in summer clothes walk a dirt path through a wooded meadow during the day.', 'Three people walking down a muddy dirt road on a cloudy day.', 'Three people are walking down a dirt road in the country.', 'Three people walking on a trail in the middle of the day.', 'Three people are walking down a dirt path.'], 'sentids': ['12500', '12501', '12502', '12503', '12504'], 'split': 'train', 'img_id': '2500', 'filename': '182169366.jpg'} \n",
      "\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=356x500 at 0x78FE9790A320>, 'caption': ['A waitress in a black T-shirt and black shorts at Cafe Mambo serves a tray of beverages to a seated customer in a red tank top and black bandanna.', 'A waitress wearing black is talking to a man who is wearing a red shirt and bandanna.', 'A waitress talking with a man at an outside cafe.', 'A blond woman in a skirt serving food to a man.', 'Man ordering drinks from a waitress.'], 'sentids': ['12505', '12506', '12507', '12508', '12509'], 'split': 'train', 'img_id': '2501', 'filename': '182184279.jpg'} \n",
      "\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x375 at 0x78FE979083D0>, 'caption': ['Two young boys are walking over a wet section of pavement, one is holding a hat over his head, the other is holding an umbrella.', 'A child, carrying a closed blue umbrella, is walking with another child who is under a yellow umbrella, on a muddy path.', 'School children walking home after a rainstorm.', 'Two little boys walking home in the rain.', 'Young boys are walking in galoshes.'], 'sentids': ['12510', '12511', '12512', '12513', '12514'], 'split': 'train', 'img_id': '2502', 'filename': '182246705.jpg'} \n",
      "\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x333 at 0x78FE9790B220>, 'caption': ['Some sort of outdoor event with a clown wearing a name tag that says \"Toodles\".', 'Clown standing across the street from a large group of people.', 'A clown standing in front of a crowd along a street.', 'This clown is proud to be entertaining the crowd.', 'A clown is smiling for a picture during a parade.'], 'sentids': ['12515', '12516', '12517', '12518', '12519'], 'split': 'train', 'img_id': '2503', 'filename': '182396080.jpg'} \n",
      "\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x375 at 0x78FE9790A740>, 'caption': ['Two people kneel on the snow and raise their arms with mountains behind them.', 'Two people jumping up with snow covered mountains in the background.', 'Two people raise their arms on a snowy hill in the mountains.', 'Two men raise their arms atop a snowy mountain.', 'Two snowboarders throw up their hands.'], 'sentids': ['12520', '12521', '12522', '12523', '12524'], 'split': 'train', 'img_id': '2504', 'filename': '182493240.jpg'} \n",
      "\n",
      "📋 Column types:\n",
      "{'image': Image(mode=None, decode=True, id=None), 'caption': [Value(dtype='string', id=None)], 'sentids': [Value(dtype='string', id=None)], 'split': Value(dtype='string', id=None), 'img_id': Value(dtype='string', id=None), 'filename': Value(dtype='string', id=None)}\n",
      "\n",
      "🔎 Size\n",
      "(10, 6)\n"
     ]
    }
   ],
   "source": [
    "print(\"Filtered test Dataset:\")\n",
    "print(test_dataset)\n",
    "\n",
    "print(f\"Loaded {len(test_dataset)} image-caption entries\\n\")\n",
    "\n",
    "print(\"📌 First 5 entries:\")\n",
    "first_5 = test_dataset.select(range(5))\n",
    "for row in first_5:\n",
    "    print(row, \"\\n\")\n",
    "\n",
    "print(\"📋 Column types:\")\n",
    "print(test_dataset.features)\n",
    "\n",
    "print(\"\\n🔎 Size\")\n",
    "print((len(test_dataset), len(test_dataset.features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "784e0a55-55b5-4388-a1df-333e034d2b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total filenames with duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "filename_counts = Counter(test_dataset[\"filename\"])\n",
    "\n",
    "# Print filenames with more than 1 occurrence\n",
    "for filename, count in filename_counts.items():\n",
    "    if count > 1:\n",
    "        print(f\"{filename}: {count} occurrences\")\n",
    "\n",
    "num_duplicates = sum(1 for count in filename_counts.values() if count > 1)\n",
    "print(f\"\\nTotal filenames with duplicates: {num_duplicates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c963d366-f218-4c2a-9718-3498070a1c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "from transformers import TextStreamer\n",
    "import pandas as pd\n",
    "\n",
    "streamer = TextStreamer(tokenizer, skip_prompt=True)\n",
    "\n",
    "def run_vlm_inference(prompt: str, filename: str, df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Perform inference on a given image (by filename) from the dataframe using a custom prompt.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The prompt text (can include mask tokens)\n",
    "        filename (str): Filename of the image in the DataFrame\n",
    "        df (pd.DataFrame): DataFrame with 'filename' and 'image' columns\n",
    "\n",
    "    Returns:\n",
    "        Tuple[str, float, float]: (Generated output, inference time in seconds, VRAM used in GB)\n",
    "    \"\"\"\n",
    "    row = df[df[\"filename\"] == filename]\n",
    "    if row.empty:\n",
    "        print(f\"[ERROR] No image found with filename: {filename}\")\n",
    "        return None, 0.0, 0.0\n",
    "\n",
    "    row = row.iloc[0]\n",
    "    image = row[\"image\"]\n",
    "    if isinstance(image, dict) and \"bytes\" in image:\n",
    "        from PIL import Image\n",
    "        from io import BytesIO\n",
    "        image = Image.open(BytesIO(image[\"bytes\"])).convert(\"RGB\")\n",
    "    caption = row[\"caption\"]\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompt},\n",
    "                {\"type\": \"image\", \"image\": image}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    input_text = tokenizer.apply_chat_template(messages, add_generation_prompt=True)\n",
    "    inputs = processor(images=image, text=input_text, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    start_mem = torch.cuda.memory_allocated() / 1024 / 1024 / 1024  # in GB\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(f\"🔹 Image: {filename}\")\n",
    "    print(f\"🧾 Prompt: {prompt}\")\n",
    "    print(\"📤 Output:\")\n",
    "\n",
    "    inputs.pop(\"token_type_ids\", None)\n",
    "\n",
    "    # Perform inference\n",
    "    output_ids = model.generate(\n",
    "        **inputs,\n",
    "        streamer=streamer,\n",
    "        max_new_tokens=128,\n",
    "        use_cache=True,\n",
    "        temperature=1.5,\n",
    "        min_p=0.1,\n",
    "    )\n",
    "\n",
    "    end_time = time.time()\n",
    "    end_mem = torch.cuda.max_memory_allocated() / 1024**3\n",
    "\n",
    "    time_taken = round(end_time - start_time, 3)\n",
    "    vram_used = round(end_mem - start_mem, 3)\n",
    "    decoded_output = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    print(f\"⏱️ Time taken: {time_taken} sec | 🧠 VRAM used: {vram_used} GB\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    return decoded_output, time_taken, vram_used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbdbeb36-49d2-4931-95d9-6a8c14f39085",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_set_0 = [\"\",\n",
    "              \"How many people are playing soccer in this scene?\",\n",
    "               \"An image of...\",\n",
    "               \"You are a nature trail guide. Describe what’s happening in this scene to someone preparing for their first family hike.\",\n",
    "               \"There is a <text_1> walking on a <text_2> in this image.\",\n",
    "               \"Describe using format - Subject:  \\_\\_\\_; Activity:  \\_\\_\\_; Environment:  \\_\\_\\_; Additional Notes: \\_\\_\\_;\"\n",
    "               ]\n",
    "prompt_set_1= [\"\",\n",
    "              \"How many people are playing soccer in this scene?\",\n",
    "               \"An image of...\",\n",
    "               \"You are a food critic observing customer service at cafes. Describe the interaction happening in this scene.\",\n",
    "               \"A <text_1> is standing beside a <text_2> who is sitting down at a table.\",\n",
    "               \"Describe using format - Subject:  \\_\\_\\_; Activity:  \\_\\_\\_; Environment:  \\_\\_\\_; Additional Notes: \\_\\_\\_;\"\n",
    "               ]\n",
    "prompt_set_2= [\"\",\n",
    "              \"How many people are playing soccer in this scene?\",\n",
    "               \"An image of...\",\n",
    "               \"You are a weather reporter documenting children’s routines during rainy mornings. Describe what’s going on in this image.\",\n",
    "               \"<text_1> are walking with <text_2> in the rain.\",\n",
    "               \"Describe using format - Subject:  \\_\\_\\_; Activity:  \\_\\_\\_; Environment:  \\_\\_\\_; Additional Notes: \\_\\_\\_;\"\n",
    "               ]\n",
    "prompt_set_3= [\"\",\n",
    "              \"How many people are playing soccer in this scene?\",\n",
    "               \"An image of...\",\n",
    "               \"You are a journalist covering a small-town parade. Describe the role and setting of the clown in this festive scene.\",\n",
    "               \"A <text_1> with bright makeup and colorful clothes stands near a <text_2> during an event.\",\n",
    "               \"Describe using format - Subject:  \\_\\_\\_; Activity:  \\_\\_\\_; Environment:  \\_\\_\\_; Additional Notes: \\_\\_\\_;\"\n",
    "               ]\n",
    "prompt_set_4= [\"\",\n",
    "              \"How many people are playing soccer in this scene?\",\n",
    "               \"An image of...\",\n",
    "               \"You are a winter sports photographer recounting a joyful moment you captured. Describe the scene with vivid detail.\",\n",
    "               \"Two <text_1> are sitting on a snowy slope with their arms <text_2>.\",\n",
    "               \"Describe using format - Subject:  \\_\\_\\_; Activity:  \\_\\_\\_; Environment:  \\_\\_\\_; Additional Notes: \\_\\_\\_;\"\n",
    "               ]\n",
    "prompt_set_5= [\"\",\n",
    "              \"How many people are playing soccer in this scene?\",\n",
    "               \"An image of...\",\n",
    "               \"You are a market researcher documenting traditional grocery stores. Describe what the boy is doing and what the store looks like.\",\n",
    "               \"A <text_1> is behind a counter filled with <text_2> in a small shop.\",\n",
    "               \"Describe using format - Subject:  \\_\\_\\_; Activity:  \\_\\_\\_; Environment:  \\_\\_\\_; Additional Notes: \\_\\_\\_;\"\n",
    "               ]\n",
    "prompt_set_6= [\"\",\n",
    "              \"How many people are playing soccer in this scene?\",\n",
    "               \"An image of...\",\n",
    "               \"You are an IT workplace culture analyst. Describe the work environment and team dynamic shown in this image.\",\n",
    "               \"A <text_1> is using a laptop at a desk while two <text_2> are in the background.\",\n",
    "               \"Describe using format - Subject:  \\_\\_\\_; Activity:  \\_\\_\\_; Environment:  \\_\\_\\_; Additional Notes: \\_\\_\\_;\"\n",
    "               ]\n",
    "prompt_set_7= [\"\",\n",
    "              \"How many people are playing soccer in this scene?\",\n",
    "               \"An image of...\",\n",
    "               \"You are a canine trainer assessing a working dog’s field behavior. Describe the dog’s posture and role based on the scene..\",\n",
    "               \"A <text_1> is wearing a vest and holding a <text_2> in its mouth.\",\n",
    "               \"Describe using format - Subject:  \\_\\_\\_; Activity:  \\_\\_\\_; Environment:  \\_\\_\\_; Additional Notes: \\_\\_\\_;\"\n",
    "               ]\n",
    "prompt_set_8= [\"\",\n",
    "              \"How many people are playing soccer in this scene?\",\n",
    "               \"An image of...\",\n",
    "               \"You are a cultural anthropologist documenting traditional street labor. Describe what the person is doing and how they are carrying the items.\",\n",
    "               \"A <text_1> is walking while carrying <text_2> suspended from a pole.\",\n",
    "               \"Describe using format - Subject:  \\_\\_\\_; Activity:  \\_\\_\\_; Environment:  \\_\\_\\_; Additional Notes: \\_\\_\\_;\"\n",
    "               ]\n",
    "prompt_set_9= [\"\",\n",
    "              \"How many people are playing soccer in this scene?\",\n",
    "               \"An image of...\",\n",
    "               \"You are a museum docent giving a tour. Describe the activity of the woman in the context of the art gallery.\",\n",
    "               \"A <text_1> is painting a replica of an artwork in front of <text_2>.\",\n",
    "               \"Describe using format - Subject:  \\_\\_\\_; Activity:  \\_\\_\\_; Environment:  \\_\\_\\_; Additional Notes: \\_\\_\\_;\"\n",
    "               ]\n",
    "PROMPT_LIST = [prompt_set_0, prompt_set_1, prompt_set_2, prompt_set_3, prompt_set_4, prompt_set_5, prompt_set_6, prompt_set_7, prompt_set_8, prompt_set_9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88ca1509-6e9e-4adc-a197-1127f29066d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Running prompts for image: 182169366.jpg (img_id: 2500)\n",
      "------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: \n",
      "🔹 Image: 182169366.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The group in the image features a group of hikers taking a hike. skulpture.|A group.</s>\n",
      "⏱️ Time taken: 1.792 sec | 🧠 VRAM used: 0.27 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: \n",
      "🔹 Image: 182169366.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The group in the image features a group of hikers taking a hike. skulpture.|A group.</s>\n",
      "⏱️ Time taken: 1.774 sec | 🧠 VRAM used: 0.27 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: How many people are playing soccer in this scene?\n",
      "🔹 Image: 182169366.jpg\n",
      "🧾 Prompt: How many people are playing soccer in this scene?\n",
      "📤 Output:\n",
      "The scene depicts a group of people playing frisbee, which two dogs, suggesting that they are a bunch of, or near the field. hétérogènes. Or, field that a group of people of them are to . A group two of people of them is a  a of the some are to the a of they is a some.</s>\n",
      "⏱️ Time taken: 4.21 sec | 🧠 VRAM used: 0.272 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: How many people are playing soccer in this scene?\n",
      "🔹 Image: 182169366.jpg\n",
      "🧾 Prompt: How many people are playing soccer in this scene?\n",
      "📤 Output:\n",
      "The scene depicts a group of people playing frisbee, which two dogs, suggesting that they are a bunch of, or near the field. hétérogènes. Or, field that a group of people of them are to . A group two of people of them is a  a of the some are to the a of they is a some.</s>\n",
      "⏱️ Time taken: 4.033 sec | 🧠 VRAM used: 0.272 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: An image of...\n",
      "🔹 Image: 182169366.jpg\n",
      "🧾 Prompt: An image of...\n",
      "📤 Output:\n",
      "The term \"all the way\" is typically used in the context of a specific route or journey along a chosen path or course. konflik to avoid misunderstandings.</s>\n",
      "⏱️ Time taken: 2.196 sec | 🧠 VRAM used: 0.271 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: An image of...\n",
      "🔹 Image: 182169366.jpg\n",
      "🧾 Prompt: An image of...\n",
      "📤 Output:\n",
      "The term \"all the way\" is typically used in the context of a specific route or journey along a chosen path or course. konflik to avoid misunderstandings.</s>\n",
      "⏱️ Time taken: 2.312 sec | 🧠 VRAM used: 0.271 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: You are a nature trail guide. Describe what’s happ...\n",
      "🔹 Image: 182169366.jpg\n",
      "🧾 Prompt: You are a nature trail guide. Describe what’s happening in this scene to someone preparing for their first family hike.\n",
      "📤 Output:\n",
      "As you embark on your family hike, you'll be greeted by a serene woodland trail winding through a canopy of mature oaks and verdant undergrowth. The path's wide and well-trod, with only gentle slopes and informative markers to guide you. As you tread, you'll notice how the dappled light filters through the leaves, dotting the woodland floor with gold. The air'll be redolent with loam and chlorophyll, a earthy and green. You'll hear the rustle of leaves, the trill of birds, and mayhap the faintest whisper of a brook.\n",
      "\n",
      "Ahead\n",
      "⏱️ Time taken: 8.201 sec | 🧠 VRAM used: 0.274 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: You are a nature trail guide. Describe what’s happ...\n",
      "🔹 Image: 182169366.jpg\n",
      "🧾 Prompt: You are a nature trail guide. Describe what’s happening in this scene to someone preparing for their first family hike.\n",
      "📤 Output:\n",
      "As you embark on your family hike, you'll be greeted by a serene woodland trail winding through a canopy of mature oaks and verdant undergrowth. The path's wide and well-trod, with only gentle slopes and informative markers to guide you. As you tread, you'll notice how the dappled light filters through the leaves, dotting the woodland floor with gold. The air'll be redolent with loam and chlorophyll, a earthy and green. You'll hear the rustle of leaves, the trill of birds, and mayhap the faintest whisper of a brook.\n",
      "\n",
      "Ahead\n",
      "⏱️ Time taken: 7.91 sec | 🧠 VRAM used: 0.274 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: There is a <text_1> walking on a <text_2> in this ...\n",
      "🔹 Image: 182169366.jpg\n",
      "🧾 Prompt: There is a <text_1> walking on a <text_2> in this image.\n",
      "📤 Output:\n",
      "The text-while walking on a- text- thei- the a and picking up- the a the in -a gathers- the inof -n the y at h- the a- the of- or- ant- the a igh- the a- our- m the e- the a- to- ar- the en- the if- the os- the h- to- a n- the i- to a- m- the i- a- m- the i- a- to- i- a- to- i- a- to- i- a- to- i-\n",
      "⏱️ Time taken: 7.575 sec | 🧠 VRAM used: 0.273 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: There is a <text_1> walking on a <text_2> in this ...\n",
      "🔹 Image: 182169366.jpg\n",
      "🧾 Prompt: There is a <text_1> walking on a <text_2> in this image.\n",
      "📤 Output:\n",
      "The text-while walking on a- text- thei- the a and picking up- the a the in -a gathers- the inof -n the y at h- the a- the of- or- ant- the a igh- the a- our- m the e- the a- to- ar- the en- the if- the os- the h- to- a n- the i- to a- m- the i- a- m- the i- a- to- i- a- to- i- a- to- i- a- to- i-\n",
      "⏱️ Time taken: 7.51 sec | 🧠 VRAM used: 0.273 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe using format - Subject:  \\_\\_\\_; Activity...\n",
      "🔹 Image: 182169366.jpg\n",
      "🧾 Prompt: Describe using format - Subject:  \\_\\_\\_; Activity:  \\_\\_\\_; Environment:  \\_\\_\\_; Additional Notes: \\_\\_\\_;\n",
      "📤 Output:\n",
      "**Subject:** People Hiking\n",
      " terc\n",
      "**Activity:** Hiking\n",
      "**Environment:** Forest\n",
      "**Additional Notes:** A group of hikers, including children, are seen hiking on a dirt path in a forested area. The hikers are equipped with backpacks and are walking along a designated trail.\n",
      "\n",
      "**Subject:** Mountain Bikers\n",
      "**Activity:** Mountain Biking\n",
      "**Environment:** Mountain Trail\n",
      "**Additional Notes:** Mountain bikers are seen riding on a trail in a forested area. The bikers are equipped with helmets and are riding along a designated trail.\n",
      "\n",
      "**Subject:** Runners\n",
      "**Activity:** Running\n",
      "⏱️ Time taken: 7.576 sec | 🧠 VRAM used: 0.276 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe using format - Subject:  \\_\\_\\_; Activity...\n",
      "🔹 Image: 182169366.jpg\n",
      "🧾 Prompt: Describe using format - Subject:  \\_\\_\\_; Activity:  \\_\\_\\_; Environment:  \\_\\_\\_; Additional Notes: \\_\\_\\_;\n",
      "📤 Output:\n",
      "**Subject:** People Hiking\n",
      " terc\n",
      "**Activity:** Hiking\n",
      "**Environment:** Forest\n",
      "**Additional Notes:** A group of hikers, including children, are seen hiking on a dirt path in a forested area. The hikers are equipped with backpacks and are walking along a designated trail.\n",
      "\n",
      "**Subject:** Mountain Bikers\n",
      "**Activity:** Mountain Biking\n",
      "**Environment:** Mountain Trail\n",
      "**Additional Notes:** Mountain bikers are seen riding on a trail in a forested area. The bikers are equipped with helmets and are riding along a designated trail.\n",
      "\n",
      "**Subject:** Runners\n",
      "**Activity:** Running\n",
      "⏱️ Time taken: 7.957 sec | 🧠 VRAM used: 0.276 GB\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "🔍 Running prompts for image: 182184279.jpg (img_id: 2501)\n",
      "------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: \n",
      "🔹 Image: 182184279.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "Audiences, the crowd, and the crowd,an captions, the, the the the a the a theE 1923, the the 'veggs., 'the 232 , a 'thee 'this: a 'thee 'this3., ofthes, that 23000ve 200 a 'the 'the 13, a 'the 'that 3\n",
      "\n",
      "## Answer the a 'that 300 the 1, a 'this 23</s>\n",
      "⏱️ Time taken: 6.775 sec | 🧠 VRAM used: 0.266 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: \n",
      "🔹 Image: 182184279.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "Audiences, the crowd, and the crowd,an captions, the, the the the a the a theE 1923, the the 'veggs., 'the 232 , a 'thee 'this: a 'thee 'this3., ofthes, that 23000ve 200 a 'the 'the 13, a 'the 'that 3\n",
      "\n",
      "## Answer the a 'that 300 the 1, a 'this 23</s>\n",
      "⏱️ Time taken: 6.978 sec | 🧠 VRAM used: 0.266 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: How many people are playing soccer in this scene?\n",
      "🔹 Image: 182184279.jpg\n",
      "🧾 Prompt: How many people are playing soccer in this scene?\n",
      "📤 Output:\n",
      "The image depicts a woman in black and a man blowing blowing blowing bubbles with a lighter. etapod.</s>\n",
      "⏱️ Time taken: 1.465 sec | 🧠 VRAM used: 0.267 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: How many people are playing soccer in this scene?\n",
      "🔹 Image: 182184279.jpg\n",
      "🧾 Prompt: How many people are playing soccer in this scene?\n",
      "📤 Output:\n",
      "The image depicts a woman in black and a man blowing blowing blowing bubbles with a lighter. etapod.</s>\n",
      "⏱️ Time taken: 1.46 sec | 🧠 VRAM used: 0.267 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: An image of...\n",
      "🔹 Image: 182184279.jpg\n",
      "🧾 Prompt: An image of...\n",
      "📤 Output:\n",
      "The woman is kissing a fake mustache mouth to a man who is eating a hot dog. hétérogènes.</s>\n",
      "⏱️ Time taken: 1.58 sec | 🧠 VRAM used: 0.267 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: An image of...\n",
      "🔹 Image: 182184279.jpg\n",
      "🧾 Prompt: An image of...\n",
      "📤 Output:\n",
      "The woman is kissing a fake mustache mouth to a man who is eating a hot dog. hétérogènes.</s>\n",
      "⏱️ Time taken: 1.606 sec | 🧠 VRAM used: 0.267 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: You are a food critic observing customer service a...\n",
      "🔹 Image: 182184279.jpg\n",
      "🧾 Prompt: You are a food critic observing customer service at cafes. Describe the interaction happening in this scene.\n",
      "📤 Output:\n",
      "In the 1\n",
      "\n",
      "The image depicts a playful and humorous scene where a young woman in a novelty t-shirt that reads \"Cafe' and a man wearing a bandana and a rubber duck impression of a mustache. They are playfully ham it a game, with a rubber in his a bib, which is emblazoned \"In a rubber of a bib, which is emblazoned \"In a bib, which is emblazoned \"In a bib, which is emblazoned \"In a bib, which is emblazoned \"In a bib, which is emblazoned \"In a bib, which is embl\n",
      "⏱️ Time taken: 7.55 sec | 🧠 VRAM used: 0.269 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: You are a food critic observing customer service a...\n",
      "🔹 Image: 182184279.jpg\n",
      "🧾 Prompt: You are a food critic observing customer service at cafes. Describe the interaction happening in this scene.\n",
      "📤 Output:\n",
      "In the 1\n",
      "\n",
      "The image depicts a playful and humorous scene where a young woman in a novelty t-shirt that reads \"Cafe' and a man wearing a bandana and a rubber duck impression of a mustache. They are playfully ham it a game, with a rubber in his a bib, which is emblazoned \"In a rubber of a bib, which is emblazoned \"In a bib, which is emblazoned \"In a bib, which is emblazoned \"In a bib, which is emblazoned \"In a bib, which is emblazoned \"In a bib, which is embl\n",
      "⏱️ Time taken: 7.605 sec | 🧠 VRAM used: 0.269 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: A <text_1> is standing beside a <text_2> who is si...\n",
      "🔹 Image: 182184279.jpg\n",
      "🧾 Prompt: A <text_1> is standing beside a <text_2> who is sitting down at a table.\n",
      "📤 Output:\n",
      "The structure of the sentence: A is the action, conforming a the in possessive a this the into in the to a our your a this soon of and with to the 2 2020s. The their 23 our this the the 10 and for a the our into 1 1 a the the 3 and for 2 a 100 this is the 1 a the 0 this has 3 a the 0 our 3 this 0 a 3 the 0 our 3 this 0 a 3 the 0 our 3 this 0\n",
      "⏱️ Time taken: 7.431 sec | 🧠 VRAM used: 0.269 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: A <text_1> is standing beside a <text_2> who is si...\n",
      "🔹 Image: 182184279.jpg\n",
      "🧾 Prompt: A <text_1> is standing beside a <text_2> who is sitting down at a table.\n",
      "📤 Output:\n",
      "The structure of the sentence: A is the action, conforming a the in possessive a this the into in the to a our your a this soon of and with to the 2 2020s. The their 23 our this the the 10 and for a the our into 1 1 a the the 3 and for 2 a 100 this is the 1 a the 0 this has 3 a the 0 our 3 this 0 a 3 the 0 our 3 this 0 a 3 the 0 our 3 this 0\n",
      "⏱️ Time taken: 7.457 sec | 🧠 VRAM used: 0.269 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe using format - Subject:  \\_\\_\\_; Activity...\n",
      "🔹 Image: 182184279.jpg\n",
      "🧾 Prompt: Describe using format - Subject:  \\_\\_\\_; Activity:  \\_\\_\\_; Environment:  \\_\\_\\_; Additional Notes: \\_\\_\\_;\n",
      "📤 Output:\n",
      "**Subject:** Two people, a boy and a girl\n",
      " tercena\n",
      "**Activity:** The boy is kissing the girl on the cheek\n",
      "**Environment:** A crowded public place, maybe a mall\n",
      "**Additional Notes: Unterschied between their ages, casual clothing, public display of affection\n",
      "\n",
      "---\n",
      "\n",
      "It seems there is a significant difference in the ages of the two, as indicated by the difference in their physical appearances. Additionally, their casual clothing styles also reflect this age difference. The bold display of affection, kissing on the cheek in a public place, may also suggest a difference in their comfort levels with public displays of affection.</s>\n",
      "⏱️ Time taken: 7.722 sec | 🧠 VRAM used: 0.272 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe using format - Subject:  \\_\\_\\_; Activity...\n",
      "🔹 Image: 182184279.jpg\n",
      "🧾 Prompt: Describe using format - Subject:  \\_\\_\\_; Activity:  \\_\\_\\_; Environment:  \\_\\_\\_; Additional Notes: \\_\\_\\_;\n",
      "📤 Output:\n",
      "**Subject:** Two people, a boy and a girl\n",
      " tercena\n",
      "**Activity:** The boy is kissing the girl on the cheek\n",
      "**Environment:** A crowded public place, maybe a mall\n",
      "**Additional Notes: Unterschied between their ages, casual clothing, public display of affection\n",
      "\n",
      "---\n",
      "\n",
      "It seems there is a significant difference in the ages of the two, as indicated by the difference in their physical appearances. Additionally, their casual clothing styles also reflect this age difference. The bold display of affection, kissing on the cheek in a public place, may also suggest a difference in their comfort levels with public displays of affection.</s>\n",
      "⏱️ Time taken: 8.258 sec | 🧠 VRAM used: 0.272 GB\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "🔍 Running prompts for image: 182246705.jpg (img_id: 2502)\n",
      "------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: \n",
      "🔹 Image: 182246705.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The children are often seen walking down a dirt road with raincoat, Raining, each holding an umbrella. hétérogènes, one with a backpack. The childreaching up to touch a bird sitting on a fence. Additional information provided: The children are wearing raincoats and rain boots. The ground is wet from the recent rain. The children seem to be enjoying themselves despite the wet conditions.</s>\n",
      "⏱️ Time taken: 4.847 sec | 🧠 VRAM used: 0.27 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: \n",
      "🔹 Image: 182246705.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The children are often seen walking down a dirt road with raincoat, Raining, each holding an umbrella. hétérogènes, one with a backpack. The childreaching up to touch a bird sitting on a fence. Additional information provided: The children are wearing raincoats and rain boots. The ground is wet from the recent rain. The children seem to be enjoying themselves despite the wet conditions.</s>\n",
      "⏱️ Time taken: 4.748 sec | 🧠 VRAM used: 0.27 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: How many people are playing soccer in this scene?\n",
      "🔹 Image: 182246705.jpg\n",
      "🧾 Prompt: How many people are playing soccer in this scene?\n",
      "📤 Output:\n",
      "The image depicts two young boys walking on a dirt road with umbrella. edukit.</s>\n",
      "⏱️ Time taken: 1.231 sec | 🧠 VRAM used: 0.272 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: How many people are playing soccer in this scene?\n",
      "🔹 Image: 182246705.jpg\n",
      "🧾 Prompt: How many people are playing soccer in this scene?\n",
      "📤 Output:\n",
      "The image depicts two young boys walking on a dirt road with umbrella. edukit.</s>\n",
      "⏱️ Time taken: 1.23 sec | 🧠 VRAM used: 0.272 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: An image of...\n",
      "🔹 Image: 182246705.jpg\n",
      "🧾 Prompt: An image of...\n",
      "📤 Output:\n",
      "The two children are playing with a colorful outdoor play area rug with a luge. edukasyon\n",
      "A:Q: What is the largest organellepsst their favorite game to play?</s>\n",
      "⏱️ Time taken: 2.438 sec | 🧠 VRAM used: 0.271 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: An image of...\n",
      "🔹 Image: 182246705.jpg\n",
      "🧾 Prompt: An image of...\n",
      "📤 Output:\n",
      "The two children are playing with a colorful outdoor play area rug with a luge. edukasyon\n",
      "A:Q: What is the largest organellepsst their favorite game to play?</s>\n",
      "⏱️ Time taken: 2.401 sec | 🧠 VRAM used: 0.271 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: You are a weather reporter documenting children’s ...\n",
      "🔹 Image: 182246705.jpg\n",
      "🧾 Prompt: You are a weather reporter documenting children’s routines during rainy mornings. Describe what’s going on in this image.\n",
      "📤 Output:\n",
      "In the midst of a lush, verdant garden, two young adventurers, each equipped with vibrant backpacks and umbreitas they embark on an expedition. The first adventurer, garbed in a blue raincoat and matching hat, toting a brilliant yellow parasol, strides forward, a blue backpack strapped securely to their back. Parallel to them, the second adventurer, cloaked in a red raincoat and matching hat, bears aloft a matching red parasol, a green backpack riding high on their shoulders. Their path, a winding trail of pebbles, meanders through the garden,\n",
      "⏱️ Time taken: 7.593 sec | 🧠 VRAM used: 0.273 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: You are a weather reporter documenting children’s ...\n",
      "🔹 Image: 182246705.jpg\n",
      "🧾 Prompt: You are a weather reporter documenting children’s routines during rainy mornings. Describe what’s going on in this image.\n",
      "📤 Output:\n",
      "In the midst of a lush, verdant garden, two young adventurers, each equipped with vibrant backpacks and umbreitas they embark on an expedition. The first adventurer, garbed in a blue raincoat and matching hat, toting a brilliant yellow parasol, strides forward, a blue backpack strapped securely to their back. Parallel to them, the second adventurer, cloaked in a red raincoat and matching hat, bears aloft a matching red parasol, a green backpack riding high on their shoulders. Their path, a winding trail of pebbles, meanders through the garden,\n",
      "⏱️ Time taken: 7.366 sec | 🧠 VRAM used: 0.273 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: <text_1> are walking with <text_2> in the rain.\n",
      "🔹 Image: 182246705.jpg\n",
      "🧾 Prompt: <text_1> are walking with <text_2> in the rain.\n",
      "📤 Output:\n",
      "The image depicts two small children, a young boy and a young girl, walking down a gravel path in a garden. The children are carrying a umbrella and a fishing net, and are wearing rain boots. They are passing a pond and flowers on the side of the path. The children seem to be on an adventure, exploring the outdoors.</s>\n",
      "⏱️ Time taken: 4.186 sec | 🧠 VRAM used: 0.273 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: <text_1> are walking with <text_2> in the rain.\n",
      "🔹 Image: 182246705.jpg\n",
      "🧾 Prompt: <text_1> are walking with <text_2> in the rain.\n",
      "📤 Output:\n",
      "The image depicts two small children, a young boy and a young girl, walking down a gravel path in a garden. The children are carrying a umbrella and a fishing net, and are wearing rain boots. They are passing a pond and flowers on the side of the path. The children seem to be on an adventure, exploring the outdoors.</s>\n",
      "⏱️ Time taken: 4.092 sec | 🧠 VRAM used: 0.273 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe using format - Subject:  \\_\\_\\_; Activity...\n",
      "🔹 Image: 182246705.jpg\n",
      "🧾 Prompt: Describe using format - Subject:  \\_\\_\\_; Activity:  \\_\\_\\_; Environment:  \\_\\_\\_; Additional Notes: \\_\\_\\_;\n",
      "📤 Output:\n",
      "***\n",
      "Subject: Children playing with umbrea and backpacks\n",
      "**Activity: Children playing with toy umbrellas and toy cameras\n",
      "**Environment: Garden path with flowers and puddles\n",
      "**Additional Notes: The children are enjoying themselves, jumping in puddles with their toy umbrellas and cameras. They are having a great time outdoors in the garden, exploring and playing with their toys. The garden is beautiful with flowers and a path for the children to jump in the puddles.</s>\n",
      "⏱️ Time taken: 6.04 sec | 🧠 VRAM used: 0.276 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe using format - Subject:  \\_\\_\\_; Activity...\n",
      "🔹 Image: 182246705.jpg\n",
      "🧾 Prompt: Describe using format - Subject:  \\_\\_\\_; Activity:  \\_\\_\\_; Environment:  \\_\\_\\_; Additional Notes: \\_\\_\\_;\n",
      "📤 Output:\n",
      "***\n",
      "Subject: Children playing with umbrea and backpacks\n",
      "**Activity: Children playing with toy umbrellas and toy cameras\n",
      "**Environment: Garden path with flowers and puddles\n",
      "**Additional Notes: The children are enjoying themselves, jumping in puddles with their toy umbrellas and cameras. They are having a great time outdoors in the garden, exploring and playing with their toys. The garden is beautiful with flowers and a path for the children to jump in the puddles.</s>\n",
      "⏱️ Time taken: 6.04 sec | 🧠 VRAM used: 0.276 GB\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "🔍 Running prompts for image: 182396080.jpg (img_id: 2503)\n",
      "------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: \n",
      "🔹 Image: 182396080.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The person is wearing a colorful and playful clown costume, 39;s[^ clown,Clown costume, Smurf (�omb in the ground, the in the person's the 2019a complete the 13, a the 15, a the 10, .16-7, .9a clown1, .</s>\n",
      "⏱️ Time taken: 4.382 sec | 🧠 VRAM used: 0.253 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: \n",
      "🔹 Image: 182396080.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The person is wearing a colorful and playful clown costume, 39;s[^ clown,Clown costume, Smurf (�omb in the ground, the in the person's the 2019a complete the 13, a the 15, a the 10, .16-7, .9a clown1, .</s>\n",
      "⏱️ Time taken: 4.467 sec | 🧠 VRAM used: 0.253 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: How many people are playing soccer in this scene?\n",
      "🔹 Image: 182396080.jpg\n",
      "🧾 Prompt: How many people are playing soccer in this scene?\n",
      "📤 Output:\n",
      "The person is wearing a colorful and playful clown costume attire resembling Ronald McDonald's outfit, with a 16, withiba16 socrates with many people. edukie-better than3.</s>\n",
      "⏱️ Time taken: 2.534 sec | 🧠 VRAM used: 0.255 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: How many people are playing soccer in this scene?\n",
      "🔹 Image: 182396080.jpg\n",
      "🧾 Prompt: How many people are playing soccer in this scene?\n",
      "📤 Output:\n",
      "The person is wearing a colorful and playful clown costume attire resembling Ronald McDonald's outfit, with a 16, withiba16 socrates with many people. edukie-better than3.</s>\n",
      "⏱️ Time taken: 2.539 sec | 🧠 VRAM used: 0.255 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: An image of...\n",
      "🔹 Image: 182396080.jpg\n",
      "🧾 Prompt: An image of...\n",
      "📤 Output:\n",
      "The person is wearing a colorful and juggling outfit, consisting of aown, with a little girl Cray of funhouseplantation or location, with funnymousei­ theroni- in the crowd of and children n'tI- \" and the fun, a the a the - CLOWELLIS A WHOSE the the the a the -a  job the a the a the a the - in a the a the a the a the a the - show the a the 's the a the -e that 13006 the a the a 'a to the a ' to ' to a ' to\n",
      "⏱️ Time taken: 7.45 sec | 🧠 VRAM used: 0.254 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: An image of...\n",
      "🔹 Image: 182396080.jpg\n",
      "🧾 Prompt: An image of...\n",
      "📤 Output:\n",
      "The person is wearing a colorful and juggling outfit, consisting of aown, with a little girl Cray of funhouseplantation or location, with funnymousei­ theroni- in the crowd of and children n'tI- \" and the fun, a the a the - CLOWELLIS A WHOSE the the the a the -a  job the a the a the a the - in a the a the a the a the a the - show the a the 's the a the -e that 13006 the a the a 'a to the a ' to ' to a ' to\n",
      "⏱️ Time taken: 7.393 sec | 🧠 VRAM used: 0.254 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: You are a journalist covering a small-town parade....\n",
      "🔹 Image: 182396080.jpg\n",
      "🧾 Prompt: You are a journalist covering a small-town parade. Describe the role and setting of the clown in this festive scene.\n",
      "📤 Output:\n",
      "In the scene, aicularly clown costume, a colorful, the festive atmosphere of the festivities, a part of a clown's a colorful costume the merrifai??[^mischar with a festive the is a clown's a festive atmosphere the mwith a festive the merringly with a festive the merringly\n",
      "___\n",
      "a the migh with a the merringly\n",
      "a festive the charm of a festive the charmingly\n",
      "a festive the charmingly\n",
      "a festive the charmingly\n",
      "a the charmingly\n",
      "a festive the charmingly\n",
      "a the charm\n",
      "⏱️ Time taken: 7.678 sec | 🧠 VRAM used: 0.257 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: You are a journalist covering a small-town parade....\n",
      "🔹 Image: 182396080.jpg\n",
      "🧾 Prompt: You are a journalist covering a small-town parade. Describe the role and setting of the clown in this festive scene.\n",
      "📤 Output:\n",
      "In the scene, aicularly clown costume, a colorful, the festive atmosphere of the festivities, a part of a clown's a colorful costume the merrifai??[^mischar with a festive the is a clown's a festive atmosphere the mwith a festive the merringly with a festive the merringly\n",
      "___\n",
      "a the migh with a the merringly\n",
      "a festive the charm of a festive the charmingly\n",
      "a festive the charmingly\n",
      "a festive the charmingly\n",
      "a the charmingly\n",
      "a festive the charmingly\n",
      "a the charm\n",
      "⏱️ Time taken: 7.296 sec | 🧠 VRAM used: 0.257 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: A <text_1> with bright makeup and colorful clothes...\n",
      "🔹 Image: 182396080.jpg\n",
      "🧾 Prompt: A <text_1> with bright makeup and colorful clothes stands near a <text_2> during an event.\n",
      "📤 Output:\n",
      "The image depicts a person in the middle, for a is wearing colorful outfit and large shoes, with a costume.</s>\n",
      "⏱️ Time taken: 1.527 sec | 🧠 VRAM used: 0.257 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: A <text_1> with bright makeup and colorful clothes...\n",
      "🔹 Image: 182396080.jpg\n",
      "🧾 Prompt: A <text_1> with bright makeup and colorful clothes stands near a <text_2> during an event.\n",
      "📤 Output:\n",
      "The image depicts a person in the middle, for a is wearing colorful outfit and large shoes, with a costume.</s>\n",
      "⏱️ Time taken: 1.526 sec | 🧠 VRAM used: 0.257 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe using format - Subject:  \\_\\_\\_; Activity...\n",
      "🔹 Image: 182396080.jpg\n",
      "🧾 Prompt: Describe using format - Subject:  \\_\\_\\_; Activity:  \\_\\_\\_; Environment:  \\_\\_\\_; Additional Notes: \\_\\_\\_;\n",
      "📤 Output:\n",
      "***\n",
      " terc: Performing as a clown at a. Performing as a. Brightly lit. festive and colorful costume with exaggerated makeup and a festive. Small town, festive with a festive. Carnival worker in a festive. Carnival worker in a festive. Carnival worker in a festive. Carnival worker in a festive. Carnival worker in a festive. Carnival worker in a festive. Carnival worker in a festive. Carnival worker in a festive. Carnival worker in a festive. Carnival worker in a festive. Carnival worker in a fest\n",
      "⏱️ Time taken: 7.281 sec | 🧠 VRAM used: 0.259 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe using format - Subject:  \\_\\_\\_; Activity...\n",
      "🔹 Image: 182396080.jpg\n",
      "🧾 Prompt: Describe using format - Subject:  \\_\\_\\_; Activity:  \\_\\_\\_; Environment:  \\_\\_\\_; Additional Notes: \\_\\_\\_;\n",
      "📤 Output:\n",
      "***\n",
      " terc: Performing as a clown at a. Performing as a. Brightly lit. festive and colorful costume with exaggerated makeup and a festive. Small town, festive with a festive. Carnival worker in a festive. Carnival worker in a festive. Carnival worker in a festive. Carnival worker in a festive. Carnival worker in a festive. Carnival worker in a festive. Carnival worker in a festive. Carnival worker in a festive. Carnival worker in a festive. Carnival worker in a festive. Carnival worker in a fest\n",
      "⏱️ Time taken: 7.42 sec | 🧠 VRAM used: 0.259 GB\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "🔍 Running prompts for image: 182493240.jpg (img_id: 2504)\n",
      "------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: \n",
      "🔹 Image: 182493240.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The sky with fluffy white snow\n",
      " kampanterrhea maintanhiu I've, the ize S the the aAnd this in the a the, 141, the a the, the the the the the a the e who13ssan dI'st the a 'in g o.</s>\n",
      "⏱️ Time taken: 3.95 sec | 🧠 VRAM used: 0.27 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: \n",
      "🔹 Image: 182493240.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The sky with fluffy white snow\n",
      " kampanterrhea maintanhiu I've, the ize S the the aAnd this in the a the, 141, the a the, the the the the the a the e who13ssan dI'st the a 'in g o.</s>\n",
      "⏱️ Time taken: 3.968 sec | 🧠 VRAM used: 0.27 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: How many people are playing soccer in this scene?\n",
      "🔹 Image: 182493240.jpg\n",
      "🧾 Prompt: How many people are playing soccer in this scene?\n",
      "📤 Output:\n",
      "The group of people in the image seems to be playing soccer?</s>\n",
      "⏱️ Time taken: 1.007 sec | 🧠 VRAM used: 0.272 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: How many people are playing soccer in this scene?\n",
      "🔹 Image: 182493240.jpg\n",
      "🧾 Prompt: How many people are playing soccer in this scene?\n",
      "📤 Output:\n",
      "The group of people in the image seems to be playing soccer?</s>\n",
      "⏱️ Time taken: 1.005 sec | 🧠 VRAM used: 0.272 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: An image of...\n",
      "🔹 Image: 182493240.jpg\n",
      "🧾 Prompt: An image of...\n",
      "📤 Output:\n",
      "The sky is clear and blue. hétérogènes.</s>\n",
      "⏱️ Time taken: 0.786 sec | 🧠 VRAM used: 0.271 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: An image of...\n",
      "🔹 Image: 182493240.jpg\n",
      "🧾 Prompt: An image of...\n",
      "📤 Output:\n",
      "The sky is clear and blue. hétérogènes.</s>\n",
      "⏱️ Time taken: 0.781 sec | 🧠 VRAM used: 0.271 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: You are a winter sports photographer recounting a ...\n",
      "🔹 Image: 182493240.jpg\n",
      "🧾 Prompt: You are a winter sports photographer recounting a joyful moment you captured. Describe the scene with vivid detail.\n",
      "📤 Output:\n",
      "In the heart of the majestic, snow-capped peaks stretched out before us, their triumphant poses, their jubilant, their jubilant, anted in jubilant, ant the sky, their joyous, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant\n",
      "⏱️ Time taken: 7.527 sec | 🧠 VRAM used: 0.273 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: You are a winter sports photographer recounting a ...\n",
      "🔹 Image: 182493240.jpg\n",
      "🧾 Prompt: You are a winter sports photographer recounting a joyful moment you captured. Describe the scene with vivid detail.\n",
      "📤 Output:\n",
      "In the heart of the majestic, snow-capped peaks stretched out before us, their triumphant poses, their jubilant, their jubilant, anted in jubilant, ant the sky, their joyous, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant\n",
      "⏱️ Time taken: 7.507 sec | 🧠 VRAM used: 0.273 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Two <text_1> are sitting on a snowy slope with the...\n",
      "🔹 Image: 182493240.jpg\n",
      "🧾 Prompt: Two <text_1> are sitting on a snowy slope with their arms <text_2>.\n",
      "📤 Output:\n",
      "The sentence above the snow with their hands in the sky with their a on the ground, the a the a the a the in the a the a the in the a the a the in the  the  a the 2. baita the 2013.</s>\n",
      "⏱️ Time taken: 3.376 sec | 🧠 VRAM used: 0.273 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Two <text_1> are sitting on a snowy slope with the...\n",
      "🔹 Image: 182493240.jpg\n",
      "🧾 Prompt: Two <text_1> are sitting on a snowy slope with their arms <text_2>.\n",
      "📤 Output:\n",
      "The sentence above the snow with their hands in the sky with their a on the ground, the a the a the a the in the a the a the in the a the a the in the  the  a the 2. baita the 2013.</s>\n",
      "⏱️ Time taken: 3.544 sec | 🧠 VRAM used: 0.273 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe using format - Subject:  \\_\\_\\_; Activity...\n",
      "🔹 Image: 182493240.jpg\n",
      "🧾 Prompt: Describe using format - Subject:  \\_\\_\\_; Activity:  \\_\\_\\_; Environment:  \\_\\_\\_; Additional Notes: \\_\\_\\_;\n",
      "📤 Output:\n",
      "**Subject:** Snowboarding\n",
      " tercane/em of aq: Snowboarding\n",
      "**e: Mountains\n",
      "**dditional Notes: he couple celebrating in the snow with the mountains in the background</s>\n",
      "⏱️ Time taken: 2.462 sec | 🧠 VRAM used: 0.276 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe using format - Subject:  \\_\\_\\_; Activity...\n",
      "🔹 Image: 182493240.jpg\n",
      "🧾 Prompt: Describe using format - Subject:  \\_\\_\\_; Activity:  \\_\\_\\_; Environment:  \\_\\_\\_; Additional Notes: \\_\\_\\_;\n",
      "📤 Output:\n",
      "**Subject:** Snowboarding\n",
      " tercane/em of aq: Snowboarding\n",
      "**e: Mountains\n",
      "**dditional Notes: he couple celebrating in the snow with the mountains in the background</s>\n",
      "⏱️ Time taken: 2.461 sec | 🧠 VRAM used: 0.276 GB\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "🔍 Running prompts for image: 182503906.jpg (img_id: 2505)\n",
      "------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: \n",
      "🔹 Image: 182503906.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The expansive grocery store with a wide variety of goods on shelves, ranging from candies to dried goods, with bulk, and other</s>\n",
      "⏱️ Time taken: 1.794 sec | 🧠 VRAM used: 0.27 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: \n",
      "🔹 Image: 182503906.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The expansive grocery store with a wide variety of goods on shelves, ranging from candies to dried goods, with bulk, and other</s>\n",
      "⏱️ Time taken: 1.804 sec | 🧠 VRAM used: 0.27 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: How many people are playing soccer in this scene?\n",
      "🔹 Image: 182503906.jpg\n",
      "🧾 Prompt: How many people are playing soccer in this scene?\n",
      "📤 Output:\n",
      "The store is well stocked with a variety of goods on shelves. hétérogènes.</s>\n",
      "⏱️ Time taken: 1.174 sec | 🧠 VRAM used: 0.272 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: How many people are playing soccer in this scene?\n",
      "🔹 Image: 182503906.jpg\n",
      "🧾 Prompt: How many people are playing soccer in this scene?\n",
      "📤 Output:\n",
      "The store is well stocked with a variety of goods on shelves. hétérogènes.</s>\n",
      "⏱️ Time taken: 1.184 sec | 🧠 VRAM used: 0.272 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: An image of...\n",
      "🔹 Image: 182503906.jpg\n",
      "🧾 Prompt: An image of...\n",
      "📤 Output:\n",
      "The interior of a grocery store is very colorful and seems to be very large and large?</s>\n",
      "⏱️ Time taken: 1.287 sec | 🧠 VRAM used: 0.271 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: An image of...\n",
      "🔹 Image: 182503906.jpg\n",
      "🧾 Prompt: An image of...\n",
      "📤 Output:\n",
      "The interior of a grocery store is very colorful and seems to be very large and large?</s>\n",
      "⏱️ Time taken: 1.29 sec | 🧠 VRAM used: 0.271 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: You are a market researcher documenting traditiona...\n",
      "🔹 Image: 182503906.jpg\n",
      "🧾 Prompt: You are a market researcher documenting traditional grocery stores. Describe what the boy is doing and what the store looks like.\n",
      "📤 Output:\n",
      "The scene depicts a bustling, well-stocked traditional grocery store bustling with a variety of products. The store is characterized by its rustic charm, with wooden shelves stacked high with an assortment of canned goods, jars, and other staples. The store's interior is warmly illuminated by flickering light bulbs, casting a cozy glow over the scene.\n",
      "\n",
      "In the midst of the store, a boy is engrossed in his task, meticulously scooping cereal from a large bin into a bag. His focus is unwavering, a testament to his dedication to his duty.\n",
      "\n",
      "The store's atmosphere is\n",
      "⏱️ Time taken: 7.391 sec | 🧠 VRAM used: 0.273 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: You are a market researcher documenting traditiona...\n",
      "🔹 Image: 182503906.jpg\n",
      "🧾 Prompt: You are a market researcher documenting traditional grocery stores. Describe what the boy is doing and what the store looks like.\n",
      "📤 Output:\n",
      "The scene depicts a bustling, well-stocked traditional grocery store bustling with a variety of products. The store is characterized by its rustic charm, with wooden shelves stacked high with an assortment of canned goods, jars, and other staples. The store's interior is warmly illuminated by flickering light bulbs, casting a cozy glow over the scene.\n",
      "\n",
      "In the midst of the store, a boy is engrossed in his task, meticulously scooping cereal from a large bin into a bag. His focus is unwavering, a testament to his dedication to his duty.\n",
      "\n",
      "The store's atmosphere is\n",
      "⏱️ Time taken: 7.395 sec | 🧠 VRAM used: 0.273 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: A <text_1> is behind a counter filled with <text_2...\n",
      "🔹 Image: 182503906.jpg\n",
      "🧾 Prompt: A <text_1> is behind a counter filled with <text_2> in a small shop.\n",
      "📤 Output:\n",
      "The contextually, a large store with a shelf of candy: every and where you're like of a lot and you've and only the is\n",
      "\n",
      "The store\n",
      "\n",
      "A story the a are the orbs.</s>\n",
      "⏱️ Time taken: 2.651 sec | 🧠 VRAM used: 0.273 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: A <text_1> is behind a counter filled with <text_2...\n",
      "🔹 Image: 182503906.jpg\n",
      "🧾 Prompt: A <text_1> is behind a counter filled with <text_2> in a small shop.\n",
      "📤 Output:\n",
      "The contextually, a large store with a shelf of candy: every and where you're like of a lot and you've and only the is\n",
      "\n",
      "The store\n",
      "\n",
      "A story the a are the orbs.</s>\n",
      "⏱️ Time taken: 2.63 sec | 🧠 VRAM used: 0.273 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe using format - Subject:  \\_\\_\\_; Activity...\n",
      "🔹 Image: 182503906.jpg\n",
      "🧾 Prompt: Describe using format - Subject:  \\_\\_\\_; Activity:  \\_\\_\\_; Environment:  \\_\\_\\_; Additional Notes: \\_\\_\\_;\n",
      "📤 Output:\n",
      "**Subject:** Image of a large store with vast assortment of goods\n",
      " tercet\n",
      "**Activity:** Shoppers browsing and selecting items\n",
      "**Environment:** Busy indoor store with wide aisles of products\n",
      "**Additional Notes:** The store specializes in a huge selection of candies and snacks, with numerous bins of bulk candy and shelves of packaged goods. The store appears well-stocked and well-lit, with a classic, retro feel. There are signs in multiple languages, indicating a diverse customer base.</s>\n",
      "⏱️ Time taken: 6.175 sec | 🧠 VRAM used: 0.276 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe using format - Subject:  \\_\\_\\_; Activity...\n",
      "🔹 Image: 182503906.jpg\n",
      "🧾 Prompt: Describe using format - Subject:  \\_\\_\\_; Activity:  \\_\\_\\_; Environment:  \\_\\_\\_; Additional Notes: \\_\\_\\_;\n",
      "📤 Output:\n",
      "**Subject:** Image of a large store with vast assortment of goods\n",
      " tercet\n",
      "**Activity:** Shoppers browsing and selecting items\n",
      "**Environment:** Busy indoor store with wide aisles of products\n",
      "**Additional Notes:** The store specializes in a huge selection of candies and snacks, with numerous bins of bulk candy and shelves of packaged goods. The store appears well-stocked and well-lit, with a classic, retro feel. There are signs in multiple languages, indicating a diverse customer base.</s>\n",
      "⏱️ Time taken: 6.25 sec | 🧠 VRAM used: 0.276 GB\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "🔍 Running prompts for image: 1827287777.jpg (img_id: 2506)\n",
      "------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: \n",
      "🔹 Image: 1827287777.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The central image depicts a person sitting at a wooden desk, working on a laptop. maksimum. 2. There is also standing up, with crossed hands on the desk, and there is also standing, with crossed hands on the hip, looking at the laptop screen. The room have posters on the wall. One of the posters is pacis a comic book posters.</s>\n",
      "⏱️ Time taken: 4.523 sec | 🧠 VRAM used: 0.27 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: \n",
      "🔹 Image: 1827287777.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The central image depicts a person sitting at a wooden desk, working on a laptop. maksimum. 2. There is also standing up, with crossed hands on the desk, and there is also standing, with crossed hands on the hip, looking at the laptop screen. The room have posters on the wall. One of the posters is pacis a comic book posters.</s>\n",
      "⏱️ Time taken: 4.528 sec | 🧠 VRAM used: 0.27 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: How many people are playing soccer in this scene?\n",
      "🔹 Image: 1827287777.jpg\n",
      "🧾 Prompt: How many people are playing soccer in this scene?\n",
      "📤 Output:\n",
      "The image depicts a group of people in a room, with a laptop on a desk. maksimum.</s>\n",
      "⏱️ Time taken: 1.461 sec | 🧠 VRAM used: 0.272 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: How many people are playing soccer in this scene?\n",
      "🔹 Image: 1827287777.jpg\n",
      "🧾 Prompt: How many people are playing soccer in this scene?\n",
      "📤 Output:\n",
      "The image depicts a group of people in a room, with a laptop on a desk. maksimum.</s>\n",
      "⏱️ Time taken: 1.459 sec | 🧠 VRAM used: 0.272 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: An image of...\n",
      "🔹 Image: 1827287777.jpg\n",
      "🧾 Prompt: An image of...\n",
      "📤 Output:\n",
      "The image depicts a man sitting at a wooden desk, typing on a laptop. prouctions on the desk, including a headphones. The man is wearing a black and a black shirt with a black wristwatch. On the wall behind him, there are three posters.</s>\n",
      "⏱️ Time taken: 3.318 sec | 🧠 VRAM used: 0.271 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: An image of...\n",
      "🔹 Image: 1827287777.jpg\n",
      "🧾 Prompt: An image of...\n",
      "📤 Output:\n",
      "The image depicts a man sitting at a wooden desk, typing on a laptop. prouctions on the desk, including a headphones. The man is wearing a black and a black shirt with a black wristwatch. On the wall behind him, there are three posters.</s>\n",
      "⏱️ Time taken: 3.321 sec | 🧠 VRAM used: 0.271 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: You are an IT workplace culture analyst. Describe ...\n",
      "🔹 Image: 1827287777.jpg\n",
      "🧾 Prompt: You are an IT workplace culture analyst. Describe the work environment and team dynamic shown in this image.\n",
      "📤 Output:\n",
      "The work environment depicted in the image appears to portray a casual and informal office culture. The central figure is seen working on a laptop while seated on an oversized, unconventional office chair, which resembles a giant hand, suggesting a playful and relaxed atmosphere. The walls are adorned with humorous and lighthearted posters, reinforcing the informal vibe. Another individual is casually leaning against a wall, dressed in casual attire, further emphasizing the informal dress code. The presence of various tech gadgets, such as headphones and a laptop, indicates a tech-savvy and modern workplace. The overall scene suggests a dynamic and friendly team dynamic,\n",
      "⏱️ Time taken: 7.528 sec | 🧠 VRAM used: 0.273 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: You are an IT workplace culture analyst. Describe ...\n",
      "🔹 Image: 1827287777.jpg\n",
      "🧾 Prompt: You are an IT workplace culture analyst. Describe the work environment and team dynamic shown in this image.\n",
      "📤 Output:\n",
      "The work environment depicted in the image appears to portray a casual and informal office culture. The central figure is seen working on a laptop while seated on an oversized, unconventional office chair, which resembles a giant hand, suggesting a playful and relaxed atmosphere. The walls are adorned with humorous and lighthearted posters, reinforcing the informal vibe. Another individual is casually leaning against a wall, dressed in casual attire, further emphasizing the informal dress code. The presence of various tech gadgets, such as headphones and a laptop, indicates a tech-savvy and modern workplace. The overall scene suggests a dynamic and friendly team dynamic,\n",
      "⏱️ Time taken: 7.482 sec | 🧠 VRAM used: 0.273 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: A <text_1> is using a laptop at a desk while two <...\n",
      "🔹 Image: 1827287777.jpg\n",
      "🧾 Prompt: A <text_1> is using a laptop at a desk while two <text_2> are in the background.\n",
      "📤 Output:\n",
      "Sure, here's a detailed summary of the passage, properly formatted and with the changes highlighted accordingly.\n",
      "\n",
      "---\n",
      "\n",
      "A <text_1> is using a laptop at a desk while two <text_2> are in the background.\n",
      "\n",
      "Please replace the following text with the highlighted text.\n",
      "\n",
      "Original text: `<text_1>` is using a laptop at a desk while two `<text_2>` are in the background.\n",
      "\n",
      "Formatted and highlighted text:\n",
      "\n",
      "A `<text_1>` is using a laptop at a desk while two `<text_2>` are in the background.\n",
      "\n",
      "This revision ensures the text is properly formatted and the highlighted changes are incorporated.\n",
      "⏱️ Time taken: 7.404 sec | 🧠 VRAM used: 0.274 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: A <text_1> is using a laptop at a desk while two <...\n",
      "🔹 Image: 1827287777.jpg\n",
      "🧾 Prompt: A <text_1> is using a laptop at a desk while two <text_2> are in the background.\n",
      "📤 Output:\n",
      "Sure, here's a detailed summary of the passage, properly formatted and with the changes highlighted accordingly.\n",
      "\n",
      "---\n",
      "\n",
      "A <text_1> is using a laptop at a desk while two <text_2> are in the background.\n",
      "\n",
      "Please replace the following text with the highlighted text.\n",
      "\n",
      "Original text: `<text_1>` is using a laptop at a desk while two `<text_2>` are in the background.\n",
      "\n",
      "Formatted and highlighted text:\n",
      "\n",
      "A `<text_1>` is using a laptop at a desk while two `<text_2>` are in the background.\n",
      "\n",
      "This revision ensures the text is properly formatted and the highlighted changes are incorporated.\n",
      "⏱️ Time taken: 7.68 sec | 🧠 VRAM used: 0.274 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe using format - Subject:  \\_\\_\\_; Activity...\n",
      "🔹 Image: 1827287777.jpg\n",
      "🧾 Prompt: Describe using format - Subject:  \\_\\_\\_; Activity:  \\_\\_\\_; Environment:  \\_\\_\\_; Additional Notes: \\_\\_\\_;\n",
      "📤 Output:\n",
      "***\n",
      "Subject: Man working on a laptop\n",
      "**Activity:** Sitting at a desk, using a laptop\n",
      "**Environment:** Office setting with a desk, chair, and posters on the wall\n",
      "**Additional Notes: **A man is intensely working on his laptop, seemingly in a casual office environment with humorous posters on the wall, including one depicting a character from a popular show. Another man is standing and observing the seated man, adding a casual and relaxed atmosphere to the workspace.</s>\n",
      "⏱️ Time taken: 5.645 sec | 🧠 VRAM used: 0.276 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe using format - Subject:  \\_\\_\\_; Activity...\n",
      "🔹 Image: 1827287777.jpg\n",
      "🧾 Prompt: Describe using format - Subject:  \\_\\_\\_; Activity:  \\_\\_\\_; Environment:  \\_\\_\\_; Additional Notes: \\_\\_\\_;\n",
      "📤 Output:\n",
      "***\n",
      "Subject: Man working on a laptop\n",
      "**Activity:** Sitting at a desk, using a laptop\n",
      "**Environment:** Office setting with a desk, chair, and posters on the wall\n",
      "**Additional Notes: **A man is intensely working on his laptop, seemingly in a casual office environment with humorous posters on the wall, including one depicting a character from a popular show. Another man is standing and observing the seated man, adding a casual and relaxed atmosphere to the workspace.</s>\n",
      "⏱️ Time taken: 5.683 sec | 🧠 VRAM used: 0.276 GB\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "🔍 Running prompts for image: 1827560917.jpg (img_id: 2507)\n",
      "------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: \n",
      "🔹 Image: 1827560917.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The dog is also laying on the grass. Του construct.</s>\n",
      "⏱️ Time taken: 0.949 sec | 🧠 VRAM used: 0.27 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: \n",
      "🔹 Image: 1827560917.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The dog is also laying on the grass. Του construct.</s>\n",
      "⏱️ Time taken: 0.947 sec | 🧠 VRAM used: 0.27 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: How many people are playing soccer in this scene?\n",
      "🔹 Image: 1827560917.jpg\n",
      "🧾 Prompt: How many people are playing soccer in this scene?\n",
      "📤 Output:\n",
      "The image depicts a playful pup with a soccer ball in its mouth. etaplaying with a \n",
      "\n",
      "From the nearby 13, 2 a the ground, a 2with a the 13 theF 2with a the 12with a 11 the 10with a 9 the 8with a 7 the 6with a 5 the 4with a 3 the 2with a 1with a 0the end.</s>\n",
      "⏱️ Time taken: 6.153 sec | 🧠 VRAM used: 0.272 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: How many people are playing soccer in this scene?\n",
      "🔹 Image: 1827560917.jpg\n",
      "🧾 Prompt: How many people are playing soccer in this scene?\n",
      "📤 Output:\n",
      "The image depicts a playful pup with a soccer ball in its mouth. etaplaying with a \n",
      "\n",
      "From the nearby 13, 2 a the ground, a 2with a the 13 theF 2with a the 12with a 11 the 10with a 9 the 8with a 7 the 6with a 5 the 4with a 3 the 2with a 1with a 0the end.</s>\n",
      "⏱️ Time taken: 5.931 sec | 🧠 VRAM used: 0.272 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: An image of...\n",
      "🔹 Image: 1827560917.jpg\n",
      "🧾 Prompt: An image of...\n",
      "📤 Output:\n",
      "The object returned 3 0.653.</s>\n",
      "⏱️ Time taken: 0.945 sec | 🧠 VRAM used: 0.271 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: An image of...\n",
      "🔹 Image: 1827560917.jpg\n",
      "🧾 Prompt: An image of...\n",
      "📤 Output:\n",
      "The object returned 3 0.653.</s>\n",
      "⏱️ Time taken: 0.942 sec | 🧠 VRAM used: 0.271 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: You are a canine trainer assessing a working dog’s...\n",
      "🔹 Image: 1827560917.jpg\n",
      "🧾 Prompt: You are a canine trainer assessing a working dog’s field behavior. Describe the dog’s posture and role based on the scene..\n",
      "📤 Output:\n",
      "The image depicts a small, fluffy black and white dog wearing a reflective harness with an orange and green design on its back. The harness has reflective strips and a handle on top for leading. The dog is standing on patch of grass, looking eagerly upward, with an object in its mouth. appears to be tug toy, which is gripping in its jaws. The dog's ears are perked up, and its eyes are wide open, indicating excitement and focus. The scene suggests playful, outdoor activity, such as a game of fetch or tug-of-war. The harness and reflective strips on it suggest that the dog is well-equipped for\n",
      "⏱️ Time taken: 7.486 sec | 🧠 VRAM used: 0.274 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: You are a canine trainer assessing a working dog’s...\n",
      "🔹 Image: 1827560917.jpg\n",
      "🧾 Prompt: You are a canine trainer assessing a working dog’s field behavior. Describe the dog’s posture and role based on the scene..\n",
      "📤 Output:\n",
      "The image depicts a small, fluffy black and white dog wearing a reflective harness with an orange and green design on its back. The harness has reflective strips and a handle on top for leading. The dog is standing on patch of grass, looking eagerly upward, with an object in its mouth. appears to be tug toy, which is gripping in its jaws. The dog's ears are perked up, and its eyes are wide open, indicating excitement and focus. The scene suggests playful, outdoor activity, such as a game of fetch or tug-of-war. The harness and reflective strips on it suggest that the dog is well-equipped for\n",
      "⏱️ Time taken: 7.462 sec | 🧠 VRAM used: 0.274 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: A <text_1> is wearing a vest and holding a <text_2...\n",
      "🔹 Image: 1827560917.jpg\n",
      "🧾 Prompt: A <text_1> is wearing a vest and holding a <text_2> in its mouth.\n",
      "📤 Output:\n",
      "The given image is of a cute small black, white, and brown, with a  with long, thick, black, and white, long, thick, glossy black, white, and brown, with, glossy black, and white, with, thick, gloss white, and black, with, thick, gloss white, and black, with, thick, gloss white, and black, with, thick, gloss white, and black, with, thick, gloss white, and black, with, thick, glossy black, and white, with, thick, gloss white, and black, with, thick, glossy black\n",
      "⏱️ Time taken: 7.682 sec | 🧠 VRAM used: 0.273 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: A <text_1> is wearing a vest and holding a <text_2...\n",
      "🔹 Image: 1827560917.jpg\n",
      "🧾 Prompt: A <text_1> is wearing a vest and holding a <text_2> in its mouth.\n",
      "📤 Output:\n",
      "The given image is of a cute small black, white, and brown, with a  with long, thick, black, and white, long, thick, glossy black, white, and brown, with, glossy black, and white, with, thick, gloss white, and black, with, thick, gloss white, and black, with, thick, gloss white, and black, with, thick, gloss white, and black, with, thick, gloss white, and black, with, thick, glossy black, and white, with, thick, gloss white, and black, with, thick, glossy black\n",
      "⏱️ Time taken: 7.397 sec | 🧠 VRAM used: 0.273 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe using format - Subject:  \\_\\_\\_; Activity...\n",
      "🔹 Image: 1827560917.jpg\n",
      "🧾 Prompt: Describe using format - Subject:  \\_\\_\\_; Activity:  \\_\\_\\_; Environment:  \\_\\_\\_; Additional Notes: \\_\\_\\_;\n",
      "📤 Output:\n",
      "**Subject:** Dog playing with a toy\n",
      " terc\n",
      "**Activity:** Tug of War\n",
      "**Environment:** Park\n",
      "**Additional Notes:**\n",
      "- The dog appears to be a Border Terrier, known for their tenacity and agility.\n",
      "- The toy is a large, stick, suitable for a strong play.\n",
      "- The harness the dog is wearing is brightly colored, ensuring high visibility during outdoor activities.\n",
      "- The environment seems to be a natural, open space, ideal for play.\n",
      "- The dog's focused and engaged in the play, indicating enjoyment and stimulation.</s>\n",
      "⏱️ Time taken: 6.665 sec | 🧠 VRAM used: 0.276 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe using format - Subject:  \\_\\_\\_; Activity...\n",
      "🔹 Image: 1827560917.jpg\n",
      "🧾 Prompt: Describe using format - Subject:  \\_\\_\\_; Activity:  \\_\\_\\_; Environment:  \\_\\_\\_; Additional Notes: \\_\\_\\_;\n",
      "📤 Output:\n",
      "**Subject:** Dog playing with a toy\n",
      " terc\n",
      "**Activity:** Tug of War\n",
      "**Environment:** Park\n",
      "**Additional Notes:**\n",
      "- The dog appears to be a Border Terrier, known for their tenacity and agility.\n",
      "- The toy is a large, stick, suitable for a strong play.\n",
      "- The harness the dog is wearing is brightly colored, ensuring high visibility during outdoor activities.\n",
      "- The environment seems to be a natural, open space, ideal for play.\n",
      "- The dog's focused and engaged in the play, indicating enjoyment and stimulation.</s>\n",
      "⏱️ Time taken: 6.539 sec | 🧠 VRAM used: 0.276 GB\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "🔍 Running prompts for image: 182825639.jpg (img_id: 2508)\n",
      "------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: \n",
      "🔹 Image: 182825639.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The depicted person, in the raincoat, and is outervuma that — the a on the, aoccupe ofief the a this, a ( s: a of red-in- a you`1. novemb hiss, 0.achs so f0]3, inand iful f, 's the, ol system.//</s>\n",
      "⏱️ Time taken: 4.552 sec | 🧠 VRAM used: 0.27 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: \n",
      "🔹 Image: 182825639.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The depicted person, in the raincoat, and is outervuma that — the a on the, aoccupe ofief the a this, a ( s: a of red-in- a you`1. novemb hiss, 0.achs so f0]3, inand iful f, 's the, ol system.//</s>\n",
      "⏱️ Time taken: 4.317 sec | 🧠 VRAM used: 0.27 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: How many people are playing soccer in this scene?\n",
      "🔹 Image: 182825639.jpg\n",
      "🧾 Prompt: How many people are playing soccer in this scene?\n",
      "📤 Output:\n",
      "The depicted scene features a child playing with a tricycle prop, specifically a type of small child’s plaything. edukation, Kem as a activity, with a playardua nstrength, a devely of a game, with toy as a playarduild, with a to of a play as a thing, with a toy, with a toyouth, with a to be a thing, with a toy, with a to be of a game, with a to be of a play as a to be of a to, with a to be of a to, with a to be of a to,\n",
      "⏱️ Time taken: 7.36 sec | 🧠 VRAM used: 0.272 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: How many people are playing soccer in this scene?\n",
      "🔹 Image: 182825639.jpg\n",
      "🧾 Prompt: How many people are playing soccer in this scene?\n",
      "📤 Output:\n",
      "The depicted scene features a child playing with a tricycle prop, specifically a type of small child’s plaything. edukation, Kem as a activity, with a playardua nstrength, a devely of a game, with toy as a playarduild, with a to of a play as a thing, with a toy, with a toyouth, with a to be a thing, with a toy, with a to be of a game, with a to be of a play as a to be of a to, with a to be of a to, with a to be of a to,\n",
      "⏱️ Time taken: 7.339 sec | 🧠 VRAM used: 0.272 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: An image of...\n",
      "🔹 Image: 182825639.jpg\n",
      "🧾 Prompt: An image of...\n",
      "📤 Output:\n",
      "The person is wearing a conical hat and is pulling a string attached to a very large suitcase. etapathere attached to a leg of a the a the a on the line of the, a the line sofa the in the the roof the top: a the : // the of the the Nagi : the the : the - crosshat: the t- a : a 've : a to e: a ', a 1, a[an- a 1 a 1: the 1.</s>\n",
      "⏱️ Time taken: 6.118 sec | 🧠 VRAM used: 0.271 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: An image of...\n",
      "🔹 Image: 182825639.jpg\n",
      "🧾 Prompt: An image of...\n",
      "📤 Output:\n",
      "The person is wearing a conical hat and is pulling a string attached to a very large suitcase. etapathere attached to a leg of a the a the a on the line of the, a the line sofa the in the the roof the top: a the : // the of the the Nagi : the the : the - crosshat: the t- a : a 've : a to e: a ', a 1, a[an- a 1 a 1: the 1.</s>\n",
      "⏱️ Time taken: 6.157 sec | 🧠 VRAM used: 0.271 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: You are a cultural anthropologist documenting trad...\n",
      "🔹 Image: 182825639.jpg\n",
      "🧾 Prompt: You are a cultural anthropologist documenting traditional street labor. Describe what the person is doing and how they are carrying the items.\n",
      "📤 Output:\n",
      "In the image, a person is depicted engaging in the traditional street labor, specifically, they are seen carrying a large bundle strapped to their back using a traditional shoulder pole, a form of headwear, known as a coolie hat, is popular in many parts of a Southeast Asia. The person is dressed in a light- colored, long-sleeved shirt, light-colored pants with a distinctive pattern, and flip-flops. They are walking on a even, paved surface, adjacent to a plain, light-colored wall.\n",
      "\n",
      "The individual is transporting two large, woven baskets, one in each hand, suspended from end of a long\n",
      "⏱️ Time taken: 7.38 sec | 🧠 VRAM used: 0.274 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: You are a cultural anthropologist documenting trad...\n",
      "🔹 Image: 182825639.jpg\n",
      "🧾 Prompt: You are a cultural anthropologist documenting traditional street labor. Describe what the person is doing and how they are carrying the items.\n",
      "📤 Output:\n",
      "In the image, a person is depicted engaging in the traditional street labor, specifically, they are seen carrying a large bundle strapped to their back using a traditional shoulder pole, a form of headwear, known as a coolie hat, is popular in many parts of a Southeast Asia. The person is dressed in a light- colored, long-sleeved shirt, light-colored pants with a distinctive pattern, and flip-flops. They are walking on a even, paved surface, adjacent to a plain, light-colored wall.\n",
      "\n",
      "The individual is transporting two large, woven baskets, one in each hand, suspended from end of a long\n",
      "⏱️ Time taken: 7.388 sec | 🧠 VRAM used: 0.274 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: A <text_1> is walking while carrying <text_2> susp...\n",
      "🔹 Image: 182825639.jpg\n",
      "🧾 Prompt: A <text_1> is walking while carrying <text_2> suspended from a pole.\n",
      "📤 Output:\n",
      "Certainly, the term we are looking for is: \"A person walking while carrying _B a basket on a shoulder, \"basket\" is the a on and _the ____ is walking ____ is a ____ is a ____ is ____ is a ____ is ____ is a _is a _\"is a _\"is a _\"is a _\"or _is a _\"or _\"or _or _\"or _\"or _\"or _\"or _\"or _\"or _\"or _\"or _\"or _\"or _\"or _\"or _\n",
      "⏱️ Time taken: 7.339 sec | 🧠 VRAM used: 0.273 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: A <text_1> is walking while carrying <text_2> susp...\n",
      "🔹 Image: 182825639.jpg\n",
      "🧾 Prompt: A <text_1> is walking while carrying <text_2> suspended from a pole.\n",
      "📤 Output:\n",
      "Certainly, the term we are looking for is: \"A person walking while carrying _B a basket on a shoulder, \"basket\" is the a on and _the ____ is walking ____ is a ____ is a ____ is ____ is a ____ is ____ is a _is a _\"is a _\"is a _\"is a _\"or _is a _\"or _\"or _or _\"or _\"or _\"or _\"or _\"or _\"or _\"or _\"or _\"or _\"or _\"or _\"or _\n",
      "⏱️ Time taken: 7.427 sec | 🧠 VRAM used: 0.273 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe using format - Subject:  \\_\\_\\_; Activity...\n",
      "🔹 Image: 182825639.jpg\n",
      "🧾 Prompt: Describe using format - Subject:  \\_\\_\\_; Activity:  \\_\\_\\_; Environment:  \\_\\_\\_; Additional Notes: \\_\\_\\_;\n",
      "📤 Output:\n",
      "***\n",
      "Subject: Playful and Whimsical Playtime Scene\n",
      "**Activity:** A child is playfully balancing a basket scale with a conical hat and bags\n",
      "**Environment:** A sunny and bright, with a plain white wall and ground backdrop\n",
      "**Additional Notes:** The child seems to be enjoying the play, wearing mismatched outfit with a conical hat, and the scale is creatively used as a toy\n",
      "\n",
      "Here are the details in the specified format:\n",
      "\n",
      "- **Subject:** Playful Playtime Scene\n",
      "- **Activity:** A child is playfully balancing a basket scale with a conical hat and bags\n",
      "- **Environment:** A sunny\n",
      "⏱️ Time taken: 7.358 sec | 🧠 VRAM used: 0.276 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe using format - Subject:  \\_\\_\\_; Activity...\n",
      "🔹 Image: 182825639.jpg\n",
      "🧾 Prompt: Describe using format - Subject:  \\_\\_\\_; Activity:  \\_\\_\\_; Environment:  \\_\\_\\_; Additional Notes: \\_\\_\\_;\n",
      "📤 Output:\n",
      "***\n",
      "Subject: Playful and Whimsical Playtime Scene\n",
      "**Activity:** A child is playfully balancing a basket scale with a conical hat and bags\n",
      "**Environment:** A sunny and bright, with a plain white wall and ground backdrop\n",
      "**Additional Notes:** The child seems to be enjoying the play, wearing mismatched outfit with a conical hat, and the scale is creatively used as a toy\n",
      "\n",
      "Here are the details in the specified format:\n",
      "\n",
      "- **Subject:** Playful Playtime Scene\n",
      "- **Activity:** A child is playfully balancing a basket scale with a conical hat and bags\n",
      "- **Environment:** A sunny\n",
      "⏱️ Time taken: 7.409 sec | 🧠 VRAM used: 0.276 GB\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "🔍 Running prompts for image: 18284727.jpg (img_id: 2509)\n",
      "------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: \n",
      "🔹 Image: 18284727.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The woman admiring, fascinated by a curator, [START\n",
      "\n",
      "## Image of a that you\"r by a description: aThis? with a let’s a to:strengrossd by you attention:as off6l  be g for to bethat seems to:</s>\n",
      "⏱️ Time taken: 3.581 sec | 🧠 VRAM used: 0.253 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: \n",
      "🔹 Image: 18284727.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The woman admiring, fascinated by a curator, [START\n",
      "\n",
      "## Image of a that you\"r by a description: aThis? with a let’s a to:strengrossd by you attention:as off6l  be g for to bethat seems to:</s>\n",
      "⏱️ Time taken: 3.553 sec | 🧠 VRAM used: 0.253 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: How many people are playing soccer in this scene?\n",
      "🔹 Image: 18284727.jpg\n",
      "🧾 Prompt: How many people are playing soccer in this scene?\n",
      "📤 Output:\n",
      "The woman is sitting in a chair, viewing 2pictures with ornate gilding. edukase available cognitive faily.</s>\n",
      "⏱️ Time taken: 1.764 sec | 🧠 VRAM used: 0.255 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: How many people are playing soccer in this scene?\n",
      "🔹 Image: 18284727.jpg\n",
      "🧾 Prompt: How many people are playing soccer in this scene?\n",
      "📤 Output:\n",
      "The woman is sitting in a chair, viewing 2pictures with ornate gilding. edukase available cognitive faily.</s>\n",
      "⏱️ Time taken: 1.75 sec | 🧠 VRAM used: 0.255 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: An image of...\n",
      "🔹 Image: 18284727.jpg\n",
      "🧾 Prompt: An image of...\n",
      "📤 Output:\n",
      "The artwork is being revered as a: a shrine. hétérogènes</s>\n",
      "⏱️ Time taken: 0.975 sec | 🧠 VRAM used: 0.254 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: An image of...\n",
      "🔹 Image: 18284727.jpg\n",
      "🧾 Prompt: An image of...\n",
      "📤 Output:\n",
      "The artwork is being revered as a: a shrine. hétérogènes</s>\n",
      "⏱️ Time taken: 0.975 sec | 🧠 VRAM used: 0.254 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: You are a museum docent giving a tour. Describe th...\n",
      "🔹 Image: 18284727.jpg\n",
      "🧾 Prompt: You are a museum docent giving a tour. Describe the activity of the woman in the context of the art gallery.\n",
      "📤 Output:\n",
      "As a woman in the art gallery, a young woman is standing in the GIF YOU aready to the latter, the latter and the a the better to the v: a the latter, only other. The '?seem to the more\n",
      "\n",
      "The woman is the in the and to the of a the large and the of the and is the in the of the and the of the and the and the and the and the and the and the and the and the and the of the my the and the of the and the of the and the of the more the of the more the and the and the and the and the of\n",
      "⏱️ Time taken: 7.393 sec | 🧠 VRAM used: 0.257 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: You are a museum docent giving a tour. Describe th...\n",
      "🔹 Image: 18284727.jpg\n",
      "🧾 Prompt: You are a museum docent giving a tour. Describe the activity of the woman in the context of the art gallery.\n",
      "📤 Output:\n",
      "As a woman in the art gallery, a young woman is standing in the GIF YOU aready to the latter, the latter and the a the better to the v: a the latter, only other. The '?seem to the more\n",
      "\n",
      "The woman is the in the and to the of a the large and the of the and is the in the of the and the of the and the and the and the and the and the and the and the and the and the of the my the and the of the and the of the and the of the more the of the more the and the and the and the and the of\n",
      "⏱️ Time taken: 7.383 sec | 🧠 VRAM used: 0.257 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: A <text_1> is painting a replica of an artwork in ...\n",
      "🔹 Image: 18284727.jpg\n",
      "🧾 Prompt: A <text_1> is painting a replica of an artwork in front of <text_2>.\n",
      "📤 Output:\n",
      "A framed art[text_1[an_text:for a specific part attt:b: ament_that: a: anthisis more: a: an: athat: a: a: a: nn: a: a: a: nthat_an: a: a: nthat: a: n: a: n: a: n: a: n: a: n: a: n: a: s: a: s: a: s: a: s: a: s: a: s: a: s: a: s: a: s: a: s\n",
      "⏱️ Time taken: 7.278 sec | 🧠 VRAM used: 0.257 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: A <text_1> is painting a replica of an artwork in ...\n",
      "🔹 Image: 18284727.jpg\n",
      "🧾 Prompt: A <text_1> is painting a replica of an artwork in front of <text_2>.\n",
      "📤 Output:\n",
      "A framed art[text_1[an_text:for a specific part attt:b: ament_that: a: anthisis more: a: an: athat: a: a: a: nn: a: a: a: nthat_an: a: a: nthat: a: n: a: n: a: n: a: n: a: n: a: n: a: s: a: s: a: s: a: s: a: s: a: s: a: s: a: s: a: s: a: s\n",
      "⏱️ Time taken: 7.337 sec | 🧠 VRAM used: 0.257 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe using format - Subject:  \\_\\_\\_; Activity...\n",
      "🔹 Image: 18284727.jpg\n",
      "🧾 Prompt: Describe using format - Subject:  \\_\\_\\_; Activity:  \\_\\_\\_; Environment:  \\_\\_\\_; Additional Notes: \\_\\_\\_;\n",
      "📤 Output:\n",
      "***\n",
      " terc?Subject: Museum Visit\n",
      "- Art Museum\n",
      "- Indoors\n",
      "- The person is indoors, inside a museum, admiring famous paintings\n",
      "\n",
      "Additional Notes: The person is holding a clipboard and examining the artwork closely, examining a painting in a museum, The person is in a museum, observing art, observing a painting in a gallery, the person is in an art museum, looking at a painting in a gallery, the person is in a museum, viewing art, the person is in an art gallery, gazing at a painting, the person is in a national museum, viewing art, the person is in an art\n",
      "⏱️ Time taken: 7.311 sec | 🧠 VRAM used: 0.259 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe using format - Subject:  \\_\\_\\_; Activity...\n",
      "🔹 Image: 18284727.jpg\n",
      "🧾 Prompt: Describe using format - Subject:  \\_\\_\\_; Activity:  \\_\\_\\_; Environment:  \\_\\_\\_; Additional Notes: \\_\\_\\_;\n",
      "📤 Output:\n",
      "***\n",
      " terc?Subject: Museum Visit\n",
      "- Art Museum\n",
      "- Indoors\n",
      "- The person is indoors, inside a museum, admiring famous paintings\n",
      "\n",
      "Additional Notes: The person is holding a clipboard and examining the artwork closely, examining a painting in a museum, The person is in a museum, observing art, observing a painting in a gallery, the person is in an art museum, looking at a painting in a gallery, the person is in a museum, viewing art, the person is in an art gallery, gazing at a painting, the person is in a national museum, viewing art, the person is in an art\n",
      "⏱️ Time taken: 7.385 sec | 🧠 VRAM used: 0.259 GB\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "test_img_ids = [2500, 2501, 2502, 2503, 2504, 2505, 2506, 2507, 2508, 2509]\n",
    "df = test_dataset.to_pandas()\n",
    "\n",
    "all_outputs = {}\n",
    "all_times = {}\n",
    "all_vram = {}\n",
    "\n",
    "# Loop through each image and its corresponding prompt set\n",
    "for i, img_id in enumerate(test_img_ids):\n",
    "    row = test_dataset.filter(lambda x: x[\"img_id\"] == str(img_id))\n",
    "    if len(row) == 0:\n",
    "        print(f\"[WARNING] No image found with img_id {img_id}\")\n",
    "        continue\n",
    "\n",
    "    filename = row[0][\"filename\"]\n",
    "    prompts = PROMPT_LIST[i]\n",
    "\n",
    "    print(f\"\\n🔍 Running prompts for image: {filename} (img_id: {img_id})\\n\" + \"-\"*60)\n",
    "\n",
    "    inference_outputs = []\n",
    "    inference_times = []\n",
    "    vram_usages = []\n",
    "\n",
    "    for prompt in prompts:\n",
    "        # Run the same prompt twice for the same image\n",
    "        for run in range(2):\n",
    "            print(f\"🔁 Run {run+1} for prompt: {prompt[:50]}{'...' if len(prompt) > 50 else ''}\")\n",
    "            output, time_taken, vram_used = run_vlm_inference(prompt, filename, df=df)\n",
    "            inference_outputs.append(output)\n",
    "            inference_times.append(time_taken)\n",
    "            vram_usages.append(vram_used)\n",
    "\n",
    "    # Save to overall dicts\n",
    "    all_outputs[img_id] = inference_outputs\n",
    "    all_times[img_id] = inference_times\n",
    "    all_vram[img_id] = vram_usages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70751f0-0a79-4b4a-88cd-9a9592bcc968",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_id in all_outputs:\n",
    "    print(f\"\\n🖼️ Image ID: {img_id}\")\n",
    "    print(\"-\" * 60)\n",
    "    for i, (output, time_taken, vram_used) in enumerate(zip(all_outputs[img_id], all_times[img_id], all_vram[img_id])):\n",
    "        print(f\"🔹 Prompt {i+1}\")\n",
    "        print(f\"📝 Output: {output}\")\n",
    "        print(f\"⏱️ Inference Time: {time_taken:.3f} sec\")\n",
    "        print(f\"💾 VRAM Used: {vram_used:.3f} GB\")\n",
    "        print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2e99ac1-5afc-474d-8471-8351b77b5df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "from pycocoevalcap.cider.cider import Cider\n",
    "from pycocoevalcap.spice.spice import Spice\n",
    "from pycocoevalcap.tokenizer.ptbtokenizer import PTBTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f101e498-ff73-4b37-8284-dd304e242d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cosine_similarity(reference_captions, generated_caption):\n",
    "    try:\n",
    "        total_score = 0.0\n",
    "        for caption in reference_captions:\n",
    "            ref_embed = sbert_model.encode(caption, convert_to_tensor=True)\n",
    "            gen_embed = sbert_model.encode(generated_caption, convert_to_tensor=True)\n",
    "            score = util.cos_sim(gen_embed, ref_embed).item()\n",
    "            total_score += score\n",
    "        avg_score = total_score / len(reference_captions) if reference_captions else 0.0\n",
    "        return avg_score\n",
    "    except Exception as e:\n",
    "        print(f\"Error computing cosine similarity: {e}\")\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba995d08-78cc-482d-9b09-55188cae7696",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cider_spice_scores(reference_caption, generated_caption):\n",
    "    refs = {0: [reference_caption if reference_caption else \"\"]}\n",
    "    hypos = {0: [generated_caption if generated_caption else \"\"]}\n",
    "\n",
    "    # print(f\"Generated caption: {generated_caption}\")\n",
    "    # print(f\"Generated hypos: {hypos}\")\n",
    "\n",
    "    ptb = PTBTokenizer()\n",
    "    refs_tok = ptb.tokenize({i: [{\"caption\": c} for c in caps] for i, caps in refs.items()})\n",
    "    hypos_tok = ptb.tokenize({i: [{\"caption\": hypos[i][0]}] for i in hypos})\n",
    "\n",
    "    all_scores = {}\n",
    "\n",
    "    for scorer, name in [(Cider(), \"CIDEr\"), (Spice(), \"SPICE\")]:\n",
    "        try:\n",
    "            avg_score, _ = scorer.compute_score(refs_tok, hypos_tok)\n",
    "            if name == \"SPICE\":\n",
    "                # SPICE returns dicts per image\n",
    "                all_scores[name] = avg_score.get(\"All\", {}).get(\"f\", 0.0) if isinstance(avg_score, dict) else avg_score\n",
    "            else:\n",
    "                all_scores[name] = avg_score\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] {name} scoring failed: {e}\")\n",
    "            all_scores[name] = 0.0\n",
    "\n",
    "    return all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e23226fc-b171-4e37-b25d-225f6b6c09f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cider import Cider\n",
    "\n",
    "PICKLE_PATH = \"/workspace/data/flickr-df.p\"\n",
    "\n",
    "def compute_cider2_score(reference_caption, generated_caption):\n",
    "    refs = {\"0\": reference_caption if isinstance(reference_caption, list) else [reference_caption]}\n",
    "    hypos = [{\"image_id\": \"0\", \"caption\": [generated_caption]}]  # Fix: caption should be a list\n",
    "\n",
    "    cider = Cider()\n",
    "    score, _ = cider.compute_score(refs, hypos, PICKLE_PATH)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7410ff99-e2d4-47e5-aede-1ffb4dc1778c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_all_metrics(reference_caption, generated_caption):\n",
    "    cider_spice_scores = compute_cider_spice_scores(reference_caption, generated_caption)\n",
    "    cosine_sim = compute_cosine_similarity([reference_caption], generated_caption)\n",
    "    cider2 = compute_cider2_score(reference_caption, generated_caption)\n",
    "\n",
    "    return {\n",
    "        \"cosine_similarity\": round(cosine_sim, 4),\n",
    "        #\"CIDEr\": round(cider_spice_scores.get(\"CIDEr\", 0.0), 4),\n",
    "        \"SPICE\": round(cider_spice_scores.get(\"SPICE\", 0.0), 4),\n",
    "        \"CIDEr\": round(cider2, 4)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39061635-41c6-4673-8a5e-d32018ba2ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Evaluating image ID: 2500 | Ground truths: 5 captions\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 215.42 tokens per second.\n",
      "PTBTokenizer tokenized 20 tokens at 421.23 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.6 sec].\n",
      "Threads( StanfordCoreNLP ) [0.576 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 7.899 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 337.76 tokens per second.\n",
      "PTBTokenizer tokenized 20 tokens at 422.39 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 760.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 245.46 tokens per second.\n",
      "PTBTokenizer tokenized 20 tokens at 532.71 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 697.0 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 327.94 tokens per second.\n",
      "PTBTokenizer tokenized 20 tokens at 543.83 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 697.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 236.51 tokens per second.\n",
      "PTBTokenizer tokenized 20 tokens at 419.01 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 677.7 ms\n",
      "📝 Prompt Run 1 | CIDEr: 2.8409 | SPICE: 0.0174 | CosSim: 0.3718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 455.59 tokens per second.\n",
      "PTBTokenizer tokenized 20 tokens at 532.48 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 686.0 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 346.83 tokens per second.\n",
      "PTBTokenizer tokenized 20 tokens at 332.70 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 667.3 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 324.01 tokens per second.\n",
      "PTBTokenizer tokenized 20 tokens at 516.90 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 670.3 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 357.38 tokens per second.\n",
      "PTBTokenizer tokenized 20 tokens at 518.67 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 669.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 244.13 tokens per second.\n",
      "PTBTokenizer tokenized 20 tokens at 521.64 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 716.2 ms\n",
      "📝 Prompt Run 2 | CIDEr: 2.8409 | SPICE: 0.0174 | CosSim: 0.3718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 480.78 tokens per second.\n",
      "PTBTokenizer tokenized 73 tokens at 1923.35 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [2.100 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 8.632 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 317.87 tokens per second.\n",
      "PTBTokenizer tokenized 73 tokens at 1888.54 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 704.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 255.56 tokens per second.\n",
      "PTBTokenizer tokenized 73 tokens at 1265.21 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 647.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 315.56 tokens per second.\n",
      "PTBTokenizer tokenized 73 tokens at 1972.97 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 726.4 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 223.80 tokens per second.\n",
      "PTBTokenizer tokenized 73 tokens at 1959.30 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 705.7 ms\n",
      "📝 Prompt Run 3 | CIDEr: 3.7694 | SPICE: 0.056 | CosSim: 0.0784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 477.33 tokens per second.\n",
      "PTBTokenizer tokenized 73 tokens at 1928.49 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 677.0 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 331.65 tokens per second.\n",
      "PTBTokenizer tokenized 73 tokens at 1851.54 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 705.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 294.01 tokens per second.\n",
      "PTBTokenizer tokenized 73 tokens at 1914.51 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 722.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 288.26 tokens per second.\n",
      "PTBTokenizer tokenized 73 tokens at 1914.21 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 723.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 240.15 tokens per second.\n",
      "PTBTokenizer tokenized 73 tokens at 1692.12 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 688.0 ms\n",
      "📝 Prompt Run 4 | CIDEr: 3.7694 | SPICE: 0.056 | CosSim: 0.0784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 484.50 tokens per second.\n",
      "PTBTokenizer tokenized 35 tokens at 788.92 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [0.939 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.586 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 346.86 tokens per second.\n",
      "PTBTokenizer tokenized 35 tokens at 804.59 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 696.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 299.29 tokens per second.\n",
      "PTBTokenizer tokenized 35 tokens at 690.07 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 704.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 301.11 tokens per second.\n",
      "PTBTokenizer tokenized 35 tokens at 888.11 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 702.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 201.61 tokens per second.\n",
      "PTBTokenizer tokenized 35 tokens at 864.35 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 699.8 ms\n",
      "📝 Prompt Run 5 | CIDEr: 2.4533 | SPICE: 0.0752 | CosSim: 0.1246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 372.53 tokens per second.\n",
      "PTBTokenizer tokenized 35 tokens at 919.99 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 736.3 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 344.11 tokens per second.\n",
      "PTBTokenizer tokenized 35 tokens at 752.57 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 672.4 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 231.60 tokens per second.\n",
      "PTBTokenizer tokenized 35 tokens at 951.01 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 716.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 342.43 tokens per second.\n",
      "PTBTokenizer tokenized 35 tokens at 829.57 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 729.3 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 224.19 tokens per second.\n",
      "PTBTokenizer tokenized 35 tokens at 655.76 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 753.3 ms\n",
      "📝 Prompt Run 6 | CIDEr: 2.4533 | SPICE: 0.0752 | CosSim: 0.1246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 457.65 tokens per second.\n",
      "PTBTokenizer tokenized 128 tokens at 2962.27 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [8.781 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a nature trail guide describe what 's happening in this scene to someone preparing for their first family hike.as you embark on your family hike you 'll be greeted by a serene woodland trail winding through a canopy of mature oaks and verdant undergrowth the path 's wide and well-trod with only gentle slopes and informative markers to guide you as you tread you 'll notice how the dappled light filters through the leaves dotting the woodland floor with gold the air 'll be redolent with loam and chlorophyll a earthy and green you 'll hear the rustle of leaves the trill of birds and mayhap the faintest whisper of a brook ahead\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 14.53 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 270.95 tokens per second.\n",
      "PTBTokenizer tokenized 128 tokens at 2976.14 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [8.215 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a nature trail guide describe what 's happening in this scene to someone preparing for their first family hike.as you embark on your family hike you 'll be greeted by a serene woodland trail winding through a canopy of mature oaks and verdant undergrowth the path 's wide and well-trod with only gentle slopes and informative markers to guide you as you tread you 'll notice how the dappled light filters through the leaves dotting the woodland floor with gold the air 'll be redolent with loam and chlorophyll a earthy and green you 'll hear the rustle of leaves the trill of birds and mayhap the faintest whisper of a brook ahead\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.92 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 311.73 tokens per second.\n",
      "PTBTokenizer tokenized 128 tokens at 3352.13 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [8.416 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a nature trail guide describe what 's happening in this scene to someone preparing for their first family hike.as you embark on your family hike you 'll be greeted by a serene woodland trail winding through a canopy of mature oaks and verdant undergrowth the path 's wide and well-trod with only gentle slopes and informative markers to guide you as you tread you 'll notice how the dappled light filters through the leaves dotting the woodland floor with gold the air 'll be redolent with loam and chlorophyll a earthy and green you 'll hear the rustle of leaves the trill of birds and mayhap the faintest whisper of a brook ahead\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.92 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 307.95 tokens per second.\n",
      "PTBTokenizer tokenized 128 tokens at 3228.20 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.4 sec].\n",
      "Threads( StanfordCoreNLP ) [8.279 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a nature trail guide describe what 's happening in this scene to someone preparing for their first family hike.as you embark on your family hike you 'll be greeted by a serene woodland trail winding through a canopy of mature oaks and verdant undergrowth the path 's wide and well-trod with only gentle slopes and informative markers to guide you as you tread you 'll notice how the dappled light filters through the leaves dotting the woodland floor with gold the air 'll be redolent with loam and chlorophyll a earthy and green you 'll hear the rustle of leaves the trill of birds and mayhap the faintest whisper of a brook ahead\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.48 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 237.67 tokens per second.\n",
      "PTBTokenizer tokenized 128 tokens at 3464.19 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [8.131 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a nature trail guide describe what 's happening in this scene to someone preparing for their first family hike.as you embark on your family hike you 'll be greeted by a serene woodland trail winding through a canopy of mature oaks and verdant undergrowth the path 's wide and well-trod with only gentle slopes and informative markers to guide you as you tread you 'll notice how the dappled light filters through the leaves dotting the woodland floor with gold the air 'll be redolent with loam and chlorophyll a earthy and green you 'll hear the rustle of leaves the trill of birds and mayhap the faintest whisper of a brook ahead\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.34 s\n",
      "📝 Prompt Run 7 | CIDEr: 2.6577 | SPICE: 0.0234 | CosSim: 0.2707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 440.04 tokens per second.\n",
      "PTBTokenizer tokenized 128 tokens at 3430.78 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.3 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [8.507 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a nature trail guide describe what 's happening in this scene to someone preparing for their first family hike.as you embark on your family hike you 'll be greeted by a serene woodland trail winding through a canopy of mature oaks and verdant undergrowth the path 's wide and well-trod with only gentle slopes and informative markers to guide you as you tread you 'll notice how the dappled light filters through the leaves dotting the woodland floor with gold the air 'll be redolent with loam and chlorophyll a earthy and green you 'll hear the rustle of leaves the trill of birds and mayhap the faintest whisper of a brook ahead\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.63 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 257.50 tokens per second.\n",
      "PTBTokenizer tokenized 128 tokens at 2811.94 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [8.108 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a nature trail guide describe what 's happening in this scene to someone preparing for their first family hike.as you embark on your family hike you 'll be greeted by a serene woodland trail winding through a canopy of mature oaks and verdant undergrowth the path 's wide and well-trod with only gentle slopes and informative markers to guide you as you tread you 'll notice how the dappled light filters through the leaves dotting the woodland floor with gold the air 'll be redolent with loam and chlorophyll a earthy and green you 'll hear the rustle of leaves the trill of birds and mayhap the faintest whisper of a brook ahead\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.78 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 316.58 tokens per second.\n",
      "PTBTokenizer tokenized 128 tokens at 3197.39 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [8.306 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a nature trail guide describe what 's happening in this scene to someone preparing for their first family hike.as you embark on your family hike you 'll be greeted by a serene woodland trail winding through a canopy of mature oaks and verdant undergrowth the path 's wide and well-trod with only gentle slopes and informative markers to guide you as you tread you 'll notice how the dappled light filters through the leaves dotting the woodland floor with gold the air 'll be redolent with loam and chlorophyll a earthy and green you 'll hear the rustle of leaves the trill of birds and mayhap the faintest whisper of a brook ahead\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.94 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 260.41 tokens per second.\n",
      "PTBTokenizer tokenized 128 tokens at 2798.55 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [8.248 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a nature trail guide describe what 's happening in this scene to someone preparing for their first family hike.as you embark on your family hike you 'll be greeted by a serene woodland trail winding through a canopy of mature oaks and verdant undergrowth the path 's wide and well-trod with only gentle slopes and informative markers to guide you as you tread you 'll notice how the dappled light filters through the leaves dotting the woodland floor with gold the air 'll be redolent with loam and chlorophyll a earthy and green you 'll hear the rustle of leaves the trill of birds and mayhap the faintest whisper of a brook ahead\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.60 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 241.75 tokens per second.\n",
      "PTBTokenizer tokenized 128 tokens at 3219.90 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [8.774 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a nature trail guide describe what 's happening in this scene to someone preparing for their first family hike.as you embark on your family hike you 'll be greeted by a serene woodland trail winding through a canopy of mature oaks and verdant undergrowth the path 's wide and well-trod with only gentle slopes and informative markers to guide you as you tread you 'll notice how the dappled light filters through the leaves dotting the woodland floor with gold the air 'll be redolent with loam and chlorophyll a earthy and green you 'll hear the rustle of leaves the trill of birds and mayhap the faintest whisper of a brook ahead\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 14.45 s\n",
      "📝 Prompt Run 8 | CIDEr: 2.6577 | SPICE: 0.0234 | CosSim: 0.2707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 466.52 tokens per second.\n",
      "PTBTokenizer tokenized 132 tokens at 3486.67 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [6.506 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 12.21 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 338.70 tokens per second.\n",
      "PTBTokenizer tokenized 132 tokens at 3371.37 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 614.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 256.16 tokens per second.\n",
      "PTBTokenizer tokenized 132 tokens at 3403.74 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 605.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 322.04 tokens per second.\n",
      "PTBTokenizer tokenized 132 tokens at 2848.02 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 677.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 240.17 tokens per second.\n",
      "PTBTokenizer tokenized 132 tokens at 3369.85 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 669.8 ms\n",
      "📝 Prompt Run 9 | CIDEr: 2.926 | SPICE: 0.0129 | CosSim: 0.2002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 394.00 tokens per second.\n",
      "PTBTokenizer tokenized 132 tokens at 3486.57 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 683.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 341.10 tokens per second.\n",
      "PTBTokenizer tokenized 132 tokens at 3349.52 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 692.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 314.82 tokens per second.\n",
      "PTBTokenizer tokenized 132 tokens at 3169.66 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 682.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 339.75 tokens per second.\n",
      "PTBTokenizer tokenized 132 tokens at 3134.13 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 666.0 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 227.65 tokens per second.\n",
      "PTBTokenizer tokenized 132 tokens at 3422.47 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 683.5 ms\n",
      "📝 Prompt Run 10 | CIDEr: 2.926 | SPICE: 0.0129 | CosSim: 0.2002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 474.06 tokens per second.\n",
      "PTBTokenizer tokenized 157 tokens at 3585.06 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [11.463 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** people hiking terc ** activity ** hiking ** environment ** forest ** additional notes ** a group of hikers including children are seen hiking on a dirt path in a forested area the hikers are equipped with backpacks and are walking along a designated trail ** subject ** mountain bikers ** activity ** mountain biking ** environment ** mountain trail ** additional notes ** mountain bikers are seen riding on a trail in a forested area the bikers are equipped with helmets and are riding along a designated trail ** subject ** runners ** activity ** running\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.10 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 280.52 tokens per second.\n",
      "PTBTokenizer tokenized 157 tokens at 4125.21 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [11.881 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** people hiking terc ** activity ** hiking ** environment ** forest ** additional notes ** a group of hikers including children are seen hiking on a dirt path in a forested area the hikers are equipped with backpacks and are walking along a designated trail ** subject ** mountain bikers ** activity ** mountain biking ** environment ** mountain trail ** additional notes ** mountain bikers are seen riding on a trail in a forested area the bikers are equipped with helmets and are riding along a designated trail ** subject ** runners ** activity ** running\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.64 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 284.91 tokens per second.\n",
      "PTBTokenizer tokenized 157 tokens at 4153.04 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [12.330 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** people hiking terc ** activity ** hiking ** environment ** forest ** additional notes ** a group of hikers including children are seen hiking on a dirt path in a forested area the hikers are equipped with backpacks and are walking along a designated trail ** subject ** mountain bikers ** activity ** mountain biking ** environment ** mountain trail ** additional notes ** mountain bikers are seen riding on a trail in a forested area the bikers are equipped with helmets and are riding along a designated trail ** subject ** runners ** activity ** running\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 18.19 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 272.59 tokens per second.\n",
      "PTBTokenizer tokenized 157 tokens at 3969.58 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [12.645 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** people hiking terc ** activity ** hiking ** environment ** forest ** additional notes ** a group of hikers including children are seen hiking on a dirt path in a forested area the hikers are equipped with backpacks and are walking along a designated trail ** subject ** mountain bikers ** activity ** mountain biking ** environment ** mountain trail ** additional notes ** mountain bikers are seen riding on a trail in a forested area the bikers are equipped with helmets and are riding along a designated trail ** subject ** runners ** activity ** running\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 18.56 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 226.29 tokens per second.\n",
      "PTBTokenizer tokenized 157 tokens at 3898.66 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [12.923 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** people hiking terc ** activity ** hiking ** environment ** forest ** additional notes ** a group of hikers including children are seen hiking on a dirt path in a forested area the hikers are equipped with backpacks and are walking along a designated trail ** subject ** mountain bikers ** activity ** mountain biking ** environment ** mountain trail ** additional notes ** mountain bikers are seen riding on a trail in a forested area the bikers are equipped with helmets and are riding along a designated trail ** subject ** runners ** activity ** running\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 18.69 s\n",
      "📝 Prompt Run 11 | CIDEr: 2.9291 | SPICE: 0.0851 | CosSim: 0.3421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 527.19 tokens per second.\n",
      "PTBTokenizer tokenized 157 tokens at 3966.00 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [12.24 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** people hiking terc ** activity ** hiking ** environment ** forest ** additional notes ** a group of hikers including children are seen hiking on a dirt path in a forested area the hikers are equipped with backpacks and are walking along a designated trail ** subject ** mountain bikers ** activity ** mountain biking ** environment ** mountain trail ** additional notes ** mountain bikers are seen riding on a trail in a forested area the bikers are equipped with helmets and are riding along a designated trail ** subject ** runners ** activity ** running\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.49 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 315.46 tokens per second.\n",
      "PTBTokenizer tokenized 157 tokens at 4200.24 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [11.753 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** people hiking terc ** activity ** hiking ** environment ** forest ** additional notes ** a group of hikers including children are seen hiking on a dirt path in a forested area the hikers are equipped with backpacks and are walking along a designated trail ** subject ** mountain bikers ** activity ** mountain biking ** environment ** mountain trail ** additional notes ** mountain bikers are seen riding on a trail in a forested area the bikers are equipped with helmets and are riding along a designated trail ** subject ** runners ** activity ** running\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.60 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 290.05 tokens per second.\n",
      "PTBTokenizer tokenized 157 tokens at 3303.17 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.3 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [13.62 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** people hiking terc ** activity ** hiking ** environment ** forest ** additional notes ** a group of hikers including children are seen hiking on a dirt path in a forested area the hikers are equipped with backpacks and are walking along a designated trail ** subject ** mountain bikers ** activity ** mountain biking ** environment ** mountain trail ** additional notes ** mountain bikers are seen riding on a trail in a forested area the bikers are equipped with helmets and are riding along a designated trail ** subject ** runners ** activity ** running\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 18.53 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 338.86 tokens per second.\n",
      "PTBTokenizer tokenized 157 tokens at 3724.95 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.3 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [13.736 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** people hiking terc ** activity ** hiking ** environment ** forest ** additional notes ** a group of hikers including children are seen hiking on a dirt path in a forested area the hikers are equipped with backpacks and are walking along a designated trail ** subject ** mountain bikers ** activity ** mountain biking ** environment ** mountain trail ** additional notes ** mountain bikers are seen riding on a trail in a forested area the bikers are equipped with helmets and are riding along a designated trail ** subject ** runners ** activity ** running\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 19.19 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 199.65 tokens per second.\n",
      "PTBTokenizer tokenized 157 tokens at 4126.79 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.3 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.4 sec].\n",
      "Threads( StanfordCoreNLP ) [11.786 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** people hiking terc ** activity ** hiking ** environment ** forest ** additional notes ** a group of hikers including children are seen hiking on a dirt path in a forested area the hikers are equipped with backpacks and are walking along a designated trail ** subject ** mountain bikers ** activity ** mountain biking ** environment ** mountain trail ** additional notes ** mountain bikers are seen riding on a trail in a forested area the bikers are equipped with helmets and are riding along a designated trail ** subject ** runners ** activity ** running\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.66 s\n",
      "📝 Prompt Run 12 | CIDEr: 2.9291 | SPICE: 0.0851 | CosSim: 0.3421\n",
      "\n",
      "🔍 Evaluating image ID: 2501 | Ground truths: 5 captions\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 30 tokens at 819.76 tokens per second.\n",
      "PTBTokenizer tokenized 76 tokens at 1981.53 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [0.930 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.378 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 404.05 tokens per second.\n",
      "PTBTokenizer tokenized 76 tokens at 1982.27 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 709.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 298.37 tokens per second.\n",
      "PTBTokenizer tokenized 76 tokens at 1972.63 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 671.0 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 316.30 tokens per second.\n",
      "PTBTokenizer tokenized 76 tokens at 1972.52 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 666.0 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 187.76 tokens per second.\n",
      "PTBTokenizer tokenized 76 tokens at 2007.82 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 673.9 ms\n",
      "📝 Prompt Run 1 | CIDEr: 2.5406 | SPICE: 0.0 | CosSim: 0.0286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 30 tokens at 801.56 tokens per second.\n",
      "PTBTokenizer tokenized 76 tokens at 1981.54 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 677.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 374.17 tokens per second.\n",
      "PTBTokenizer tokenized 76 tokens at 1539.97 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 659.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 297.58 tokens per second.\n",
      "PTBTokenizer tokenized 76 tokens at 1955.51 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 664.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 325.56 tokens per second.\n",
      "PTBTokenizer tokenized 76 tokens at 1861.57 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 699.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 166.06 tokens per second.\n",
      "PTBTokenizer tokenized 76 tokens at 1916.70 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 716.4 ms\n",
      "📝 Prompt Run 2 | CIDEr: 2.5406 | SPICE: 0.0 | CosSim: 0.0286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 30 tokens at 635.72 tokens per second.\n",
      "PTBTokenizer tokenized 28 tokens at 728.08 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.6 sec].\n",
      "Threads( StanfordCoreNLP ) [0.766 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.440 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 486.95 tokens per second.\n",
      "PTBTokenizer tokenized 28 tokens at 710.26 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 687.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 233.49 tokens per second.\n",
      "PTBTokenizer tokenized 28 tokens at 669.65 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 708.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 266.01 tokens per second.\n",
      "PTBTokenizer tokenized 28 tokens at 701.89 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 692.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 183.26 tokens per second.\n",
      "PTBTokenizer tokenized 28 tokens at 551.99 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 707.1 ms\n",
      "📝 Prompt Run 3 | CIDEr: 3.2 | SPICE: 0.1083 | CosSim: 0.1067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 30 tokens at 670.20 tokens per second.\n",
      "PTBTokenizer tokenized 28 tokens at 728.90 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 688.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 462.70 tokens per second.\n",
      "PTBTokenizer tokenized 28 tokens at 714.72 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 679.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 291.46 tokens per second.\n",
      "PTBTokenizer tokenized 28 tokens at 743.11 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 668.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 308.93 tokens per second.\n",
      "PTBTokenizer tokenized 28 tokens at 749.84 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 681.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 142.23 tokens per second.\n",
      "PTBTokenizer tokenized 28 tokens at 729.64 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 691.0 ms\n",
      "📝 Prompt Run 4 | CIDEr: 3.2 | SPICE: 0.1083 | CosSim: 0.1067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 30 tokens at 583.14 tokens per second.\n",
      "PTBTokenizer tokenized 24 tokens at 468.22 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [0.673 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.477 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 400.95 tokens per second.\n",
      "PTBTokenizer tokenized 24 tokens at 497.59 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 680.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 245.19 tokens per second.\n",
      "PTBTokenizer tokenized 24 tokens at 397.58 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 603.0 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 248.40 tokens per second.\n",
      "PTBTokenizer tokenized 24 tokens at 515.18 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 736.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 166.85 tokens per second.\n",
      "PTBTokenizer tokenized 24 tokens at 614.56 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 692.4 ms\n",
      "📝 Prompt Run 5 | CIDEr: 3.4922 | SPICE: 0.1145 | CosSim: 0.2026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 30 tokens at 782.00 tokens per second.\n",
      "PTBTokenizer tokenized 24 tokens at 557.28 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 693.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 383.13 tokens per second.\n",
      "PTBTokenizer tokenized 24 tokens at 639.65 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 732.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 293.81 tokens per second.\n",
      "PTBTokenizer tokenized 24 tokens at 577.17 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 683.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 299.18 tokens per second.\n",
      "PTBTokenizer tokenized 24 tokens at 457.78 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 687.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 121.28 tokens per second.\n",
      "PTBTokenizer tokenized 24 tokens at 438.24 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 778.9 ms\n",
      "📝 Prompt Run 6 | CIDEr: 3.4922 | SPICE: 0.1145 | CosSim: 0.2026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 30 tokens at 630.98 tokens per second.\n",
      "PTBTokenizer tokenized 126 tokens at 2962.60 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [7.846 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a food critic observing customer service at cafes describe the interaction happening in this scene.in the 1 the image depicts a playful and humorous scene where a young woman in a novelty t-shirt that reads cafe and a man wearing a bandana and a rubber duck impression of a mustache they are playfully ham it a game with a rubber in his a bib which is emblazoned in a rubber of a bib which is emblazoned in a bib which is emblazoned in a bib which is emblazoned in a bib which is emblazoned in a bib which is emblazoned in a bib which is embl\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.74 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 408.79 tokens per second.\n",
      "PTBTokenizer tokenized 126 tokens at 3215.55 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.3 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [7.413 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a food critic observing customer service at cafes describe the interaction happening in this scene.in the 1 the image depicts a playful and humorous scene where a young woman in a novelty t-shirt that reads cafe and a man wearing a bandana and a rubber duck impression of a mustache they are playfully ham it a game with a rubber in his a bib which is emblazoned in a rubber of a bib which is emblazoned in a bib which is emblazoned in a bib which is emblazoned in a bib which is emblazoned in a bib which is emblazoned in a bib which is embl\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 12.68 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 309.27 tokens per second.\n",
      "PTBTokenizer tokenized 126 tokens at 3455.74 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [7.352 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a food critic observing customer service at cafes describe the interaction happening in this scene.in the 1 the image depicts a playful and humorous scene where a young woman in a novelty t-shirt that reads cafe and a man wearing a bandana and a rubber duck impression of a mustache they are playfully ham it a game with a rubber in his a bib which is emblazoned in a rubber of a bib which is emblazoned in a bib which is emblazoned in a bib which is emblazoned in a bib which is emblazoned in a bib which is emblazoned in a bib which is embl\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.23 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 315.77 tokens per second.\n",
      "PTBTokenizer tokenized 126 tokens at 3058.87 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.4 sec].\n",
      "Threads( StanfordCoreNLP ) [7.149 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a food critic observing customer service at cafes describe the interaction happening in this scene.in the 1 the image depicts a playful and humorous scene where a young woman in a novelty t-shirt that reads cafe and a man wearing a bandana and a rubber duck impression of a mustache they are playfully ham it a game with a rubber in his a bib which is emblazoned in a rubber of a bib which is emblazoned in a bib which is emblazoned in a bib which is emblazoned in a bib which is emblazoned in a bib which is emblazoned in a bib which is embl\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 12.42 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 144.16 tokens per second.\n",
      "PTBTokenizer tokenized 126 tokens at 3266.01 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [7.386 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a food critic observing customer service at cafes describe the interaction happening in this scene.in the 1 the image depicts a playful and humorous scene where a young woman in a novelty t-shirt that reads cafe and a man wearing a bandana and a rubber duck impression of a mustache they are playfully ham it a game with a rubber in his a bib which is emblazoned in a rubber of a bib which is emblazoned in a bib which is emblazoned in a bib which is emblazoned in a bib which is emblazoned in a bib which is emblazoned in a bib which is embl\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.16 s\n",
      "📝 Prompt Run 7 | CIDEr: 3.9519 | SPICE: 0.074 | CosSim: 0.2917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 30 tokens at 628.14 tokens per second.\n",
      "PTBTokenizer tokenized 126 tokens at 3165.51 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [7.32 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a food critic observing customer service at cafes describe the interaction happening in this scene.in the 1 the image depicts a playful and humorous scene where a young woman in a novelty t-shirt that reads cafe and a man wearing a bandana and a rubber duck impression of a mustache they are playfully ham it a game with a rubber in his a bib which is emblazoned in a rubber of a bib which is emblazoned in a bib which is emblazoned in a bib which is emblazoned in a bib which is emblazoned in a bib which is emblazoned in a bib which is embl\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 12.70 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 452.83 tokens per second.\n",
      "PTBTokenizer tokenized 126 tokens at 3013.74 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [7.219 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a food critic observing customer service at cafes describe the interaction happening in this scene.in the 1 the image depicts a playful and humorous scene where a young woman in a novelty t-shirt that reads cafe and a man wearing a bandana and a rubber duck impression of a mustache they are playfully ham it a game with a rubber in his a bib which is emblazoned in a rubber of a bib which is emblazoned in a bib which is emblazoned in a bib which is emblazoned in a bib which is emblazoned in a bib which is emblazoned in a bib which is embl\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 12.79 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 204.35 tokens per second.\n",
      "PTBTokenizer tokenized 126 tokens at 3080.56 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [7.282 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a food critic observing customer service at cafes describe the interaction happening in this scene.in the 1 the image depicts a playful and humorous scene where a young woman in a novelty t-shirt that reads cafe and a man wearing a bandana and a rubber duck impression of a mustache they are playfully ham it a game with a rubber in his a bib which is emblazoned in a rubber of a bib which is emblazoned in a bib which is emblazoned in a bib which is emblazoned in a bib which is emblazoned in a bib which is emblazoned in a bib which is embl\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 12.96 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 327.89 tokens per second.\n",
      "PTBTokenizer tokenized 126 tokens at 3046.39 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [7.418 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a food critic observing customer service at cafes describe the interaction happening in this scene.in the 1 the image depicts a playful and humorous scene where a young woman in a novelty t-shirt that reads cafe and a man wearing a bandana and a rubber duck impression of a mustache they are playfully ham it a game with a rubber in his a bib which is emblazoned in a rubber of a bib which is emblazoned in a bib which is emblazoned in a bib which is emblazoned in a bib which is emblazoned in a bib which is emblazoned in a bib which is embl\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.13 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 191.93 tokens per second.\n",
      "PTBTokenizer tokenized 126 tokens at 2939.55 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [7.957 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a food critic observing customer service at cafes describe the interaction happening in this scene.in the 1 the image depicts a playful and humorous scene where a young woman in a novelty t-shirt that reads cafe and a man wearing a bandana and a rubber duck impression of a mustache they are playfully ham it a game with a rubber in his a bib which is emblazoned in a rubber of a bib which is emblazoned in a bib which is emblazoned in a bib which is emblazoned in a bib which is emblazoned in a bib which is emblazoned in a bib which is embl\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.91 s\n",
      "📝 Prompt Run 8 | CIDEr: 3.9519 | SPICE: 0.074 | CosSim: 0.2917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 30 tokens at 695.31 tokens per second.\n",
      "PTBTokenizer tokenized 108 tokens at 2343.58 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [6.639 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 12.63 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 422.38 tokens per second.\n",
      "PTBTokenizer tokenized 108 tokens at 2915.96 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 635.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 277.68 tokens per second.\n",
      "PTBTokenizer tokenized 108 tokens at 2396.65 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 785.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 280.59 tokens per second.\n",
      "PTBTokenizer tokenized 108 tokens at 2523.05 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 623.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 182.76 tokens per second.\n",
      "PTBTokenizer tokenized 108 tokens at 2803.11 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 680.9 ms\n",
      "📝 Prompt Run 9 | CIDEr: 2.8526 | SPICE: 0.0 | CosSim: 0.0718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 30 tokens at 800.69 tokens per second.\n",
      "PTBTokenizer tokenized 108 tokens at 2854.54 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 691.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 374.55 tokens per second.\n",
      "PTBTokenizer tokenized 108 tokens at 2813.52 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 717.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 293.87 tokens per second.\n",
      "PTBTokenizer tokenized 108 tokens at 2524.83 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 682.0 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 312.32 tokens per second.\n",
      "PTBTokenizer tokenized 108 tokens at 2754.24 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 732.3 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 207.85 tokens per second.\n",
      "PTBTokenizer tokenized 108 tokens at 2591.29 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 789.5 ms\n",
      "📝 Prompt Run 10 | CIDEr: 2.8526 | SPICE: 0.0 | CosSim: 0.0718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 30 tokens at 629.67 tokens per second.\n",
      "PTBTokenizer tokenized 162 tokens at 3521.66 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [12.514 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** two people a boy and a girl tercena ** activity ** the boy is kissing the girl on the cheek ** environment ** a crowded public place maybe a mall ** additional notes unterschied between their ages casual clothing public display of affection it seems there is a significant difference in the ages of the two as indicated by the difference in their physical appearances additionally their casual clothing styles also reflect this age difference the bold display of affection kissing on the cheek in a public place may also suggest a difference in their comfort levels with public displays of affection\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 18.17 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 446.12 tokens per second.\n",
      "PTBTokenizer tokenized 162 tokens at 3876.43 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [12.119 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** two people a boy and a girl tercena ** activity ** the boy is kissing the girl on the cheek ** environment ** a crowded public place maybe a mall ** additional notes unterschied between their ages casual clothing public display of affection it seems there is a significant difference in the ages of the two as indicated by the difference in their physical appearances additionally their casual clothing styles also reflect this age difference the bold display of affection kissing on the cheek in a public place may also suggest a difference in their comfort levels with public displays of affection\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.56 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 229.92 tokens per second.\n",
      "PTBTokenizer tokenized 162 tokens at 3450.48 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [12.511 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** two people a boy and a girl tercena ** activity ** the boy is kissing the girl on the cheek ** environment ** a crowded public place maybe a mall ** additional notes unterschied between their ages casual clothing public display of affection it seems there is a significant difference in the ages of the two as indicated by the difference in their physical appearances additionally their casual clothing styles also reflect this age difference the bold display of affection kissing on the cheek in a public place may also suggest a difference in their comfort levels with public displays of affection\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 18.25 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 256.81 tokens per second.\n",
      "PTBTokenizer tokenized 162 tokens at 3212.08 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [12.944 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** two people a boy and a girl tercena ** activity ** the boy is kissing the girl on the cheek ** environment ** a crowded public place maybe a mall ** additional notes unterschied between their ages casual clothing public display of affection it seems there is a significant difference in the ages of the two as indicated by the difference in their physical appearances additionally their casual clothing styles also reflect this age difference the bold display of affection kissing on the cheek in a public place may also suggest a difference in their comfort levels with public displays of affection\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 18.75 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 155.14 tokens per second.\n",
      "PTBTokenizer tokenized 162 tokens at 4161.94 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.4 sec].\n",
      "Threads( StanfordCoreNLP ) [12.812 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** two people a boy and a girl tercena ** activity ** the boy is kissing the girl on the cheek ** environment ** a crowded public place maybe a mall ** additional notes unterschied between their ages casual clothing public display of affection it seems there is a significant difference in the ages of the two as indicated by the difference in their physical appearances additionally their casual clothing styles also reflect this age difference the bold display of affection kissing on the cheek in a public place may also suggest a difference in their comfort levels with public displays of affection\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 18.01 s\n",
      "📝 Prompt Run 11 | CIDEr: 2.3682 | SPICE: 0.0 | CosSim: 0.1259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 30 tokens at 559.52 tokens per second.\n",
      "PTBTokenizer tokenized 162 tokens at 4182.85 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [12.928 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** two people a boy and a girl tercena ** activity ** the boy is kissing the girl on the cheek ** environment ** a crowded public place maybe a mall ** additional notes unterschied between their ages casual clothing public display of affection it seems there is a significant difference in the ages of the two as indicated by the difference in their physical appearances additionally their casual clothing styles also reflect this age difference the bold display of affection kissing on the cheek in a public place may also suggest a difference in their comfort levels with public displays of affection\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 18.64 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 470.78 tokens per second.\n",
      "PTBTokenizer tokenized 162 tokens at 3325.25 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [12.207 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** two people a boy and a girl tercena ** activity ** the boy is kissing the girl on the cheek ** environment ** a crowded public place maybe a mall ** additional notes unterschied between their ages casual clothing public display of affection it seems there is a significant difference in the ages of the two as indicated by the difference in their physical appearances additionally their casual clothing styles also reflect this age difference the bold display of affection kissing on the cheek in a public place may also suggest a difference in their comfort levels with public displays of affection\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.73 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 225.84 tokens per second.\n",
      "PTBTokenizer tokenized 162 tokens at 4008.91 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [12.357 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** two people a boy and a girl tercena ** activity ** the boy is kissing the girl on the cheek ** environment ** a crowded public place maybe a mall ** additional notes unterschied between their ages casual clothing public display of affection it seems there is a significant difference in the ages of the two as indicated by the difference in their physical appearances additionally their casual clothing styles also reflect this age difference the bold display of affection kissing on the cheek in a public place may also suggest a difference in their comfort levels with public displays of affection\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.92 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 311.05 tokens per second.\n",
      "PTBTokenizer tokenized 162 tokens at 4009.85 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [12.914 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** two people a boy and a girl tercena ** activity ** the boy is kissing the girl on the cheek ** environment ** a crowded public place maybe a mall ** additional notes unterschied between their ages casual clothing public display of affection it seems there is a significant difference in the ages of the two as indicated by the difference in their physical appearances additionally their casual clothing styles also reflect this age difference the bold display of affection kissing on the cheek in a public place may also suggest a difference in their comfort levels with public displays of affection\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 18.61 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 164.62 tokens per second.\n",
      "PTBTokenizer tokenized 162 tokens at 4128.85 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [11.957 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** two people a boy and a girl tercena ** activity ** the boy is kissing the girl on the cheek ** environment ** a crowded public place maybe a mall ** additional notes unterschied between their ages casual clothing public display of affection it seems there is a significant difference in the ages of the two as indicated by the difference in their physical appearances additionally their casual clothing styles also reflect this age difference the bold display of affection kissing on the cheek in a public place may also suggest a difference in their comfort levels with public displays of affection\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.60 s\n",
      "📝 Prompt Run 12 | CIDEr: 2.3682 | SPICE: 0.0 | CosSim: 0.1259\n",
      "\n",
      "🔍 Evaluating image ID: 2502 | Ground truths: 5 captions\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 28 tokens at 624.49 tokens per second.\n",
      "PTBTokenizer tokenized 73 tokens at 1868.81 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [2.413 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 9.062 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 26 tokens at 681.37 tokens per second.\n",
      "PTBTokenizer tokenized 73 tokens at 1859.76 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 687.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 8 tokens at 181.71 tokens per second.\n",
      "PTBTokenizer tokenized 73 tokens at 1820.06 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 676.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 230.67 tokens per second.\n",
      "PTBTokenizer tokenized 73 tokens at 1518.84 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 678.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 173.54 tokens per second.\n",
      "PTBTokenizer tokenized 73 tokens at 1650.47 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 713.8 ms\n",
      "📝 Prompt Run 1 | CIDEr: 2.406 | SPICE: 0.0571 | CosSim: 0.5765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 28 tokens at 709.55 tokens per second.\n",
      "PTBTokenizer tokenized 73 tokens at 1836.11 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 750.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 26 tokens at 658.47 tokens per second.\n",
      "PTBTokenizer tokenized 73 tokens at 1773.45 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 677.8 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 8 tokens at 174.99 tokens per second.\n",
      "PTBTokenizer tokenized 73 tokens at 1913.86 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 751.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 214.96 tokens per second.\n",
      "PTBTokenizer tokenized 73 tokens at 1421.82 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 654.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 184.00 tokens per second.\n",
      "PTBTokenizer tokenized 73 tokens at 1655.73 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 684.1 ms\n",
      "📝 Prompt Run 2 | CIDEr: 2.406 | SPICE: 0.0571 | CosSim: 0.5765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 28 tokens at 714.66 tokens per second.\n",
      "PTBTokenizer tokenized 24 tokens at 628.05 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [0.667 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.122 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 26 tokens at 681.47 tokens per second.\n",
      "PTBTokenizer tokenized 24 tokens at 601.23 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 705.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 8 tokens at 198.08 tokens per second.\n",
      "PTBTokenizer tokenized 24 tokens at 510.41 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 688.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 224.55 tokens per second.\n",
      "PTBTokenizer tokenized 24 tokens at 620.04 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 684.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 155.77 tokens per second.\n",
      "PTBTokenizer tokenized 24 tokens at 636.65 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 675.2 ms\n",
      "📝 Prompt Run 3 | CIDEr: 2.4427 | SPICE: 0.1101 | CosSim: 0.3815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 28 tokens at 692.14 tokens per second.\n",
      "PTBTokenizer tokenized 24 tokens at 635.69 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 714.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 26 tokens at 672.03 tokens per second.\n",
      "PTBTokenizer tokenized 24 tokens at 602.07 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 686.4 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 8 tokens at 204.77 tokens per second.\n",
      "PTBTokenizer tokenized 24 tokens at 503.08 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 685.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 185.47 tokens per second.\n",
      "PTBTokenizer tokenized 24 tokens at 623.27 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 730.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 173.29 tokens per second.\n",
      "PTBTokenizer tokenized 24 tokens at 629.45 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 607.3 ms\n",
      "📝 Prompt Run 4 | CIDEr: 2.4427 | SPICE: 0.1101 | CosSim: 0.3815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 28 tokens at 734.49 tokens per second.\n",
      "PTBTokenizer tokenized 36 tokens at 855.14 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.4 sec].\n",
      "Threads( StanfordCoreNLP ) [0.858 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 5.997 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 26 tokens at 669.29 tokens per second.\n",
      "PTBTokenizer tokenized 36 tokens at 933.44 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 647.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 8 tokens at 163.01 tokens per second.\n",
      "PTBTokenizer tokenized 36 tokens at 844.93 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 683.8 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 196.79 tokens per second.\n",
      "PTBTokenizer tokenized 36 tokens at 744.94 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 692.8 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 172.22 tokens per second.\n",
      "PTBTokenizer tokenized 36 tokens at 765.35 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 680.9 ms\n",
      "📝 Prompt Run 5 | CIDEr: 1.7603 | SPICE: 0.0285 | CosSim: 0.1596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 28 tokens at 613.69 tokens per second.\n",
      "PTBTokenizer tokenized 36 tokens at 927.19 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 713.0 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 26 tokens at 668.73 tokens per second.\n",
      "PTBTokenizer tokenized 36 tokens at 775.06 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 661.3 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 8 tokens at 203.58 tokens per second.\n",
      "PTBTokenizer tokenized 36 tokens at 892.68 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 687.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 201.00 tokens per second.\n",
      "PTBTokenizer tokenized 36 tokens at 927.20 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 687.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 178.61 tokens per second.\n",
      "PTBTokenizer tokenized 36 tokens at 761.31 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 696.1 ms\n",
      "📝 Prompt Run 6 | CIDEr: 1.7603 | SPICE: 0.0285 | CosSim: 0.1596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 28 tokens at 730.80 tokens per second.\n",
      "PTBTokenizer tokenized 125 tokens at 2940.73 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [11.518 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a weather reporter documenting children 's routines during rainy mornings describe what 's going on in this image.in the midst of a lush verdant garden two young adventurers each equipped with vibrant backpacks and umbreitas they embark on an expedition the first adventurer garbed in a blue raincoat and matching hat toting a brilliant yellow parasol strides forward a blue backpack strapped securely to their back parallel to them the second adventurer cloaked in a red raincoat and matching hat bears aloft a matching red parasol a green backpack riding high on their shoulders their path a winding trail of pebbles meanders through the garden\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.06 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 26 tokens at 543.78 tokens per second.\n",
      "PTBTokenizer tokenized 125 tokens at 2986.85 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.3 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [12.114 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a weather reporter documenting children 's routines during rainy mornings describe what 's going on in this image.in the midst of a lush verdant garden two young adventurers each equipped with vibrant backpacks and umbreitas they embark on an expedition the first adventurer garbed in a blue raincoat and matching hat toting a brilliant yellow parasol strides forward a blue backpack strapped securely to their back parallel to them the second adventurer cloaked in a red raincoat and matching hat bears aloft a matching red parasol a green backpack riding high on their shoulders their path a winding trail of pebbles meanders through the garden\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.07 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 8 tokens at 167.52 tokens per second.\n",
      "PTBTokenizer tokenized 125 tokens at 2566.19 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.6 sec].\n",
      "Threads( StanfordCoreNLP ) [11.855 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a weather reporter documenting children 's routines during rainy mornings describe what 's going on in this image.in the midst of a lush verdant garden two young adventurers each equipped with vibrant backpacks and umbreitas they embark on an expedition the first adventurer garbed in a blue raincoat and matching hat toting a brilliant yellow parasol strides forward a blue backpack strapped securely to their back parallel to them the second adventurer cloaked in a red raincoat and matching hat bears aloft a matching red parasol a green backpack riding high on their shoulders their path a winding trail of pebbles meanders through the garden\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.14 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 202.84 tokens per second.\n",
      "PTBTokenizer tokenized 125 tokens at 3237.61 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [12.850 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a weather reporter documenting children 's routines during rainy mornings describe what 's going on in this image.in the midst of a lush verdant garden two young adventurers each equipped with vibrant backpacks and umbreitas they embark on an expedition the first adventurer garbed in a blue raincoat and matching hat toting a brilliant yellow parasol strides forward a blue backpack strapped securely to their back parallel to them the second adventurer cloaked in a red raincoat and matching hat bears aloft a matching red parasol a green backpack riding high on their shoulders their path a winding trail of pebbles meanders through the garden\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 18.21 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 140.03 tokens per second.\n",
      "PTBTokenizer tokenized 125 tokens at 2580.44 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [11.942 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a weather reporter documenting children 's routines during rainy mornings describe what 's going on in this image.in the midst of a lush verdant garden two young adventurers each equipped with vibrant backpacks and umbreitas they embark on an expedition the first adventurer garbed in a blue raincoat and matching hat toting a brilliant yellow parasol strides forward a blue backpack strapped securely to their back parallel to them the second adventurer cloaked in a red raincoat and matching hat bears aloft a matching red parasol a green backpack riding high on their shoulders their path a winding trail of pebbles meanders through the garden\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.64 s\n",
      "📝 Prompt Run 7 | CIDEr: 2.3383 | SPICE: 0.0223 | CosSim: 0.3585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 28 tokens at 742.34 tokens per second.\n",
      "PTBTokenizer tokenized 125 tokens at 3162.19 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [12.148 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a weather reporter documenting children 's routines during rainy mornings describe what 's going on in this image.in the midst of a lush verdant garden two young adventurers each equipped with vibrant backpacks and umbreitas they embark on an expedition the first adventurer garbed in a blue raincoat and matching hat toting a brilliant yellow parasol strides forward a blue backpack strapped securely to their back parallel to them the second adventurer cloaked in a red raincoat and matching hat bears aloft a matching red parasol a green backpack riding high on their shoulders their path a winding trail of pebbles meanders through the garden\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.77 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 26 tokens at 670.04 tokens per second.\n",
      "PTBTokenizer tokenized 125 tokens at 3556.10 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [11.928 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a weather reporter documenting children 's routines during rainy mornings describe what 's going on in this image.in the midst of a lush verdant garden two young adventurers each equipped with vibrant backpacks and umbreitas they embark on an expedition the first adventurer garbed in a blue raincoat and matching hat toting a brilliant yellow parasol strides forward a blue backpack strapped securely to their back parallel to them the second adventurer cloaked in a red raincoat and matching hat bears aloft a matching red parasol a green backpack riding high on their shoulders their path a winding trail of pebbles meanders through the garden\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.38 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 8 tokens at 174.33 tokens per second.\n",
      "PTBTokenizer tokenized 125 tokens at 3178.16 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [12.68 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a weather reporter documenting children 's routines during rainy mornings describe what 's going on in this image.in the midst of a lush verdant garden two young adventurers each equipped with vibrant backpacks and umbreitas they embark on an expedition the first adventurer garbed in a blue raincoat and matching hat toting a brilliant yellow parasol strides forward a blue backpack strapped securely to their back parallel to them the second adventurer cloaked in a red raincoat and matching hat bears aloft a matching red parasol a green backpack riding high on their shoulders their path a winding trail of pebbles meanders through the garden\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.65 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 198.74 tokens per second.\n",
      "PTBTokenizer tokenized 125 tokens at 3106.02 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [11.402 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a weather reporter documenting children 's routines during rainy mornings describe what 's going on in this image.in the midst of a lush verdant garden two young adventurers each equipped with vibrant backpacks and umbreitas they embark on an expedition the first adventurer garbed in a blue raincoat and matching hat toting a brilliant yellow parasol strides forward a blue backpack strapped securely to their back parallel to them the second adventurer cloaked in a red raincoat and matching hat bears aloft a matching red parasol a green backpack riding high on their shoulders their path a winding trail of pebbles meanders through the garden\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.81 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 185.59 tokens per second.\n",
      "PTBTokenizer tokenized 125 tokens at 3177.41 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [11.502 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a weather reporter documenting children 's routines during rainy mornings describe what 's going on in this image.in the midst of a lush verdant garden two young adventurers each equipped with vibrant backpacks and umbreitas they embark on an expedition the first adventurer garbed in a blue raincoat and matching hat toting a brilliant yellow parasol strides forward a blue backpack strapped securely to their back parallel to them the second adventurer cloaked in a red raincoat and matching hat bears aloft a matching red parasol a green backpack riding high on their shoulders their path a winding trail of pebbles meanders through the garden\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.13 s\n",
      "📝 Prompt Run 8 | CIDEr: 2.3383 | SPICE: 0.0223 | CosSim: 0.3585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 28 tokens at 520.48 tokens per second.\n",
      "PTBTokenizer tokenized 75 tokens at 1702.48 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [3.43 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 8.652 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 26 tokens at 591.85 tokens per second.\n",
      "PTBTokenizer tokenized 75 tokens at 1938.82 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 679.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 8 tokens at 203.72 tokens per second.\n",
      "PTBTokenizer tokenized 75 tokens at 1934.25 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 693.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 206.64 tokens per second.\n",
      "PTBTokenizer tokenized 75 tokens at 1967.89 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 677.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 180.01 tokens per second.\n",
      "PTBTokenizer tokenized 75 tokens at 1958.25 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 715.1 ms\n",
      "📝 Prompt Run 9 | CIDEr: 3.2044 | SPICE: 0.0912 | CosSim: 0.5747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 28 tokens at 612.44 tokens per second.\n",
      "PTBTokenizer tokenized 75 tokens at 1906.11 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 690.8 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 26 tokens at 589.08 tokens per second.\n",
      "PTBTokenizer tokenized 75 tokens at 1899.93 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 705.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 8 tokens at 156.38 tokens per second.\n",
      "PTBTokenizer tokenized 75 tokens at 1850.60 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 700.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 236.04 tokens per second.\n",
      "PTBTokenizer tokenized 75 tokens at 1914.72 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 738.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 135.66 tokens per second.\n",
      "PTBTokenizer tokenized 75 tokens at 1693.39 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 698.2 ms\n",
      "📝 Prompt Run 10 | CIDEr: 3.2044 | SPICE: 0.0912 | CosSim: 0.5747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 28 tokens at 702.69 tokens per second.\n",
      "PTBTokenizer tokenized 126 tokens at 2620.24 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [8.483 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** subject children playing with umbrea and backpacks ** activity children playing with toy umbrellas and toy cameras ** environment garden path with flowers and puddles ** additional notes the children are enjoying themselves jumping in puddles with their toy umbrellas and cameras they are having a great time outdoors in the garden exploring and playing with their toys the garden is beautiful with flowers and a path for the children to jump in the puddles\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 14.11 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 26 tokens at 648.54 tokens per second.\n",
      "PTBTokenizer tokenized 126 tokens at 3026.49 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [8.709 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** subject children playing with umbrea and backpacks ** activity children playing with toy umbrellas and toy cameras ** environment garden path with flowers and puddles ** additional notes the children are enjoying themselves jumping in puddles with their toy umbrellas and cameras they are having a great time outdoors in the garden exploring and playing with their toys the garden is beautiful with flowers and a path for the children to jump in the puddles\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 14.34 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 8 tokens at 229.22 tokens per second.\n",
      "PTBTokenizer tokenized 126 tokens at 3184.01 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.3 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [8.721 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** subject children playing with umbrea and backpacks ** activity children playing with toy umbrellas and toy cameras ** environment garden path with flowers and puddles ** additional notes the children are enjoying themselves jumping in puddles with their toy umbrellas and cameras they are having a great time outdoors in the garden exploring and playing with their toys the garden is beautiful with flowers and a path for the children to jump in the puddles\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 14.02 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 231.12 tokens per second.\n",
      "PTBTokenizer tokenized 126 tokens at 2916.70 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [8.548 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** subject children playing with umbrea and backpacks ** activity children playing with toy umbrellas and toy cameras ** environment garden path with flowers and puddles ** additional notes the children are enjoying themselves jumping in puddles with their toy umbrellas and cameras they are having a great time outdoors in the garden exploring and playing with their toys the garden is beautiful with flowers and a path for the children to jump in the puddles\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 14.22 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 187.35 tokens per second.\n",
      "PTBTokenizer tokenized 126 tokens at 3300.72 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [8.722 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** subject children playing with umbrea and backpacks ** activity children playing with toy umbrellas and toy cameras ** environment garden path with flowers and puddles ** additional notes the children are enjoying themselves jumping in puddles with their toy umbrellas and cameras they are having a great time outdoors in the garden exploring and playing with their toys the garden is beautiful with flowers and a path for the children to jump in the puddles\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 14.40 s\n",
      "📝 Prompt Run 11 | CIDEr: 1.4269 | SPICE: 0.0345 | CosSim: 0.2545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 28 tokens at 639.44 tokens per second.\n",
      "PTBTokenizer tokenized 126 tokens at 3167.36 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [8.630 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** subject children playing with umbrea and backpacks ** activity children playing with toy umbrellas and toy cameras ** environment garden path with flowers and puddles ** additional notes the children are enjoying themselves jumping in puddles with their toy umbrellas and cameras they are having a great time outdoors in the garden exploring and playing with their toys the garden is beautiful with flowers and a path for the children to jump in the puddles\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 14.01 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 26 tokens at 640.48 tokens per second.\n",
      "PTBTokenizer tokenized 126 tokens at 2927.75 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [8.664 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** subject children playing with umbrea and backpacks ** activity children playing with toy umbrellas and toy cameras ** environment garden path with flowers and puddles ** additional notes the children are enjoying themselves jumping in puddles with their toy umbrellas and cameras they are having a great time outdoors in the garden exploring and playing with their toys the garden is beautiful with flowers and a path for the children to jump in the puddles\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 14.32 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 8 tokens at 201.01 tokens per second.\n",
      "PTBTokenizer tokenized 126 tokens at 3263.74 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [8.229 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** subject children playing with umbrea and backpacks ** activity children playing with toy umbrellas and toy cameras ** environment garden path with flowers and puddles ** additional notes the children are enjoying themselves jumping in puddles with their toy umbrellas and cameras they are having a great time outdoors in the garden exploring and playing with their toys the garden is beautiful with flowers and a path for the children to jump in the puddles\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.98 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 192.82 tokens per second.\n",
      "PTBTokenizer tokenized 126 tokens at 3012.19 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.3 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [8.999 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** subject children playing with umbrea and backpacks ** activity children playing with toy umbrellas and toy cameras ** environment garden path with flowers and puddles ** additional notes the children are enjoying themselves jumping in puddles with their toy umbrellas and cameras they are having a great time outdoors in the garden exploring and playing with their toys the garden is beautiful with flowers and a path for the children to jump in the puddles\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 14.72 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 124.38 tokens per second.\n",
      "PTBTokenizer tokenized 126 tokens at 3148.56 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [8.831 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** subject children playing with umbrea and backpacks ** activity children playing with toy umbrellas and toy cameras ** environment garden path with flowers and puddles ** additional notes the children are enjoying themselves jumping in puddles with their toy umbrellas and cameras they are having a great time outdoors in the garden exploring and playing with their toys the garden is beautiful with flowers and a path for the children to jump in the puddles\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 14.58 s\n",
      "📝 Prompt Run 12 | CIDEr: 1.4269 | SPICE: 0.0345 | CosSim: 0.2545\n",
      "\n",
      "🔍 Evaluating image ID: 2503 | Ground truths: 5 captions\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 443.37 tokens per second.\n",
      "May 15, 2025 10:16:18 AM edu.stanford.nlp.process.PTBLexer next\n",
      "WARNING: Untokenizable: � (U+FFFD, decimal: 65533)\n",
      "PTBTokenizer tokenized 55 tokens at 1004.89 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.6 sec].\n",
      "Threads( StanfordCoreNLP ) [1.352 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.922 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 231.87 tokens per second.\n",
      "May 15, 2025 10:16:26 AM edu.stanford.nlp.process.PTBLexer next\n",
      "WARNING: Untokenizable: � (U+FFFD, decimal: 65533)\n",
      "PTBTokenizer tokenized 55 tokens at 813.54 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 714.3 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 293.55 tokens per second.\n",
      "May 15, 2025 10:16:27 AM edu.stanford.nlp.process.PTBLexer next\n",
      "WARNING: Untokenizable: � (U+FFFD, decimal: 65533)\n",
      "PTBTokenizer tokenized 55 tokens at 727.39 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 689.0 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 247.18 tokens per second.\n",
      "May 15, 2025 10:16:29 AM edu.stanford.nlp.process.PTBLexer next\n",
      "WARNING: Untokenizable: � (U+FFFD, decimal: 65533)\n",
      "PTBTokenizer tokenized 55 tokens at 1021.08 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 698.3 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 262.65 tokens per second.\n",
      "May 15, 2025 10:16:30 AM edu.stanford.nlp.process.PTBLexer next\n",
      "WARNING: Untokenizable: � (U+FFFD, decimal: 65533)\n",
      "PTBTokenizer tokenized 55 tokens at 1044.98 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 705.3 ms\n",
      "📝 Prompt Run 1 | CIDEr: 2.7053 | SPICE: 0.0 | CosSim: 0.4794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 427.41 tokens per second.\n",
      "May 15, 2025 10:16:31 AM edu.stanford.nlp.process.PTBLexer next\n",
      "WARNING: Untokenizable: � (U+FFFD, decimal: 65533)\n",
      "PTBTokenizer tokenized 55 tokens at 801.60 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 718.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 247.51 tokens per second.\n",
      "May 15, 2025 10:16:33 AM edu.stanford.nlp.process.PTBLexer next\n",
      "WARNING: Untokenizable: � (U+FFFD, decimal: 65533)\n",
      "PTBTokenizer tokenized 55 tokens at 1051.96 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 723.3 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 220.35 tokens per second.\n",
      "May 15, 2025 10:16:34 AM edu.stanford.nlp.process.PTBLexer next\n",
      "WARNING: Untokenizable: � (U+FFFD, decimal: 65533)\n",
      "PTBTokenizer tokenized 55 tokens at 956.98 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 698.8 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 246.95 tokens per second.\n",
      "May 15, 2025 10:16:35 AM edu.stanford.nlp.process.PTBLexer next\n",
      "WARNING: Untokenizable: � (U+FFFD, decimal: 65533)\n",
      "PTBTokenizer tokenized 55 tokens at 1006.76 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 711.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 243.91 tokens per second.\n",
      "May 15, 2025 10:16:37 AM edu.stanford.nlp.process.PTBLexer next\n",
      "WARNING: Untokenizable: � (U+FFFD, decimal: 65533)\n",
      "PTBTokenizer tokenized 55 tokens at 870.99 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 677.9 ms\n",
      "📝 Prompt Run 2 | CIDEr: 2.7053 | SPICE: 0.0 | CosSim: 0.4794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 466.70 tokens per second.\n",
      "PTBTokenizer tokenized 38 tokens at 949.56 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [0.900 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.984 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 244.21 tokens per second.\n",
      "PTBTokenizer tokenized 38 tokens at 946.86 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 747.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 294.77 tokens per second.\n",
      "PTBTokenizer tokenized 38 tokens at 937.48 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 710.8 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 193.68 tokens per second.\n",
      "PTBTokenizer tokenized 38 tokens at 786.48 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 707.0 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 269.06 tokens per second.\n",
      "PTBTokenizer tokenized 38 tokens at 865.27 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 710.5 ms\n",
      "📝 Prompt Run 3 | CIDEr: 2.2122 | SPICE: 0.0129 | CosSim: 0.4146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 460.94 tokens per second.\n",
      "PTBTokenizer tokenized 38 tokens at 915.58 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 676.8 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 308.81 tokens per second.\n",
      "PTBTokenizer tokenized 38 tokens at 947.99 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 674.3 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 301.63 tokens per second.\n",
      "PTBTokenizer tokenized 38 tokens at 990.59 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 703.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 252.95 tokens per second.\n",
      "PTBTokenizer tokenized 38 tokens at 894.17 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 690.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 280.07 tokens per second.\n",
      "PTBTokenizer tokenized 38 tokens at 964.47 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 675.3 ms\n",
      "📝 Prompt Run 4 | CIDEr: 2.2122 | SPICE: 0.0129 | CosSim: 0.4146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 438.11 tokens per second.\n",
      "PTBTokenizer tokenized 109 tokens at 2729.46 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.4 sec].\n",
      "Threads( StanfordCoreNLP ) [6.345 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 11.40 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 260.95 tokens per second.\n",
      "PTBTokenizer tokenized 109 tokens at 1943.77 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 698.3 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 235.62 tokens per second.\n",
      "PTBTokenizer tokenized 109 tokens at 2711.78 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 658.4 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 241.89 tokens per second.\n",
      "PTBTokenizer tokenized 109 tokens at 2392.68 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 776.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 261.50 tokens per second.\n",
      "PTBTokenizer tokenized 109 tokens at 2190.78 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 790.7 ms\n",
      "📝 Prompt Run 5 | CIDEr: 3.6407 | SPICE: 0.0411 | CosSim: 0.3351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 471.81 tokens per second.\n",
      "PTBTokenizer tokenized 109 tokens at 2604.85 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 732.4 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 285.48 tokens per second.\n",
      "PTBTokenizer tokenized 109 tokens at 2725.79 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 752.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 285.76 tokens per second.\n",
      "PTBTokenizer tokenized 109 tokens at 2714.94 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 691.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 212.28 tokens per second.\n",
      "PTBTokenizer tokenized 109 tokens at 2690.03 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 728.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 278.10 tokens per second.\n",
      "PTBTokenizer tokenized 109 tokens at 2350.36 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 733.5 ms\n",
      "📝 Prompt Run 6 | CIDEr: 3.6407 | SPICE: 0.0411 | CosSim: 0.3351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 459.87 tokens per second.\n",
      "PTBTokenizer tokenized 110 tokens at 2764.65 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [3.698 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a journalist covering a small-town parade describe the role and setting of the clown in this festive scene.in the scene aicularly clown costume a colorful the festive atmosphere of the festivities a part of a clown 's a colorful costume the merrifai ?? -lsb- ^ mischar with a festive the is a clown 's a festive atmosphere the mwith a festive the merringly with a festive the merringly ___ a the migh with a the merringly a festive the charm of a festive the charmingly a festive the charmingly a festive the charmingly a the charmingly a festive the charmingly a the charm\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 9.363 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 282.51 tokens per second.\n",
      "PTBTokenizer tokenized 110 tokens at 2874.46 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [3.824 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a journalist covering a small-town parade describe the role and setting of the clown in this festive scene.in the scene aicularly clown costume a colorful the festive atmosphere of the festivities a part of a clown 's a colorful costume the merrifai ?? -lsb- ^ mischar with a festive the is a clown 's a festive atmosphere the mwith a festive the merringly with a festive the merringly ___ a the migh with a the merringly a festive the charm of a festive the charmingly a festive the charmingly a festive the charmingly a the charmingly a festive the charmingly a the charm\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 9.644 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 300.86 tokens per second.\n",
      "PTBTokenizer tokenized 110 tokens at 2855.64 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [3.854 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a journalist covering a small-town parade describe the role and setting of the clown in this festive scene.in the scene aicularly clown costume a colorful the festive atmosphere of the festivities a part of a clown 's a colorful costume the merrifai ?? -lsb- ^ mischar with a festive the is a clown 's a festive atmosphere the mwith a festive the merringly with a festive the merringly ___ a the migh with a the merringly a festive the charm of a festive the charmingly a festive the charmingly a festive the charmingly a the charmingly a festive the charmingly a the charm\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 9.379 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 236.31 tokens per second.\n",
      "PTBTokenizer tokenized 110 tokens at 2712.46 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [3.630 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a journalist covering a small-town parade describe the role and setting of the clown in this festive scene.in the scene aicularly clown costume a colorful the festive atmosphere of the festivities a part of a clown 's a colorful costume the merrifai ?? -lsb- ^ mischar with a festive the is a clown 's a festive atmosphere the mwith a festive the merringly with a festive the merringly ___ a the migh with a the merringly a festive the charm of a festive the charmingly a festive the charmingly a festive the charmingly a the charmingly a festive the charmingly a the charm\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 9.383 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 270.89 tokens per second.\n",
      "PTBTokenizer tokenized 110 tokens at 2765.00 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [3.894 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a journalist covering a small-town parade describe the role and setting of the clown in this festive scene.in the scene aicularly clown costume a colorful the festive atmosphere of the festivities a part of a clown 's a colorful costume the merrifai ?? -lsb- ^ mischar with a festive the is a clown 's a festive atmosphere the mwith a festive the merringly with a festive the merringly ___ a the migh with a the merringly a festive the charm of a festive the charmingly a festive the charmingly a festive the charmingly a the charmingly a festive the charmingly a the charm\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 9.690 s\n",
      "📝 Prompt Run 7 | CIDEr: 3.6947 | SPICE: 0.0489 | CosSim: 0.4755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 426.29 tokens per second.\n",
      "PTBTokenizer tokenized 110 tokens at 2669.23 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [3.661 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a journalist covering a small-town parade describe the role and setting of the clown in this festive scene.in the scene aicularly clown costume a colorful the festive atmosphere of the festivities a part of a clown 's a colorful costume the merrifai ?? -lsb- ^ mischar with a festive the is a clown 's a festive atmosphere the mwith a festive the merringly with a festive the merringly ___ a the migh with a the merringly a festive the charm of a festive the charmingly a festive the charmingly a festive the charmingly a the charmingly a festive the charmingly a the charm\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 9.081 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 279.86 tokens per second.\n",
      "PTBTokenizer tokenized 110 tokens at 2104.99 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [3.887 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a journalist covering a small-town parade describe the role and setting of the clown in this festive scene.in the scene aicularly clown costume a colorful the festive atmosphere of the festivities a part of a clown 's a colorful costume the merrifai ?? -lsb- ^ mischar with a festive the is a clown 's a festive atmosphere the mwith a festive the merringly with a festive the merringly ___ a the migh with a the merringly a festive the charm of a festive the charmingly a festive the charmingly a festive the charmingly a the charmingly a festive the charmingly a the charm\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 9.673 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 293.41 tokens per second.\n",
      "PTBTokenizer tokenized 110 tokens at 2699.24 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [3.895 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a journalist covering a small-town parade describe the role and setting of the clown in this festive scene.in the scene aicularly clown costume a colorful the festive atmosphere of the festivities a part of a clown 's a colorful costume the merrifai ?? -lsb- ^ mischar with a festive the is a clown 's a festive atmosphere the mwith a festive the merringly with a festive the merringly ___ a the migh with a the merringly a festive the charm of a festive the charmingly a festive the charmingly a festive the charmingly a the charmingly a festive the charmingly a the charm\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 9.698 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 233.75 tokens per second.\n",
      "PTBTokenizer tokenized 110 tokens at 2195.77 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [4.4 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a journalist covering a small-town parade describe the role and setting of the clown in this festive scene.in the scene aicularly clown costume a colorful the festive atmosphere of the festivities a part of a clown 's a colorful costume the merrifai ?? -lsb- ^ mischar with a festive the is a clown 's a festive atmosphere the mwith a festive the merringly with a festive the merringly ___ a the migh with a the merringly a festive the charm of a festive the charmingly a festive the charmingly a festive the charmingly a the charmingly a festive the charmingly a the charm\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 9.866 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 242.50 tokens per second.\n",
      "PTBTokenizer tokenized 110 tokens at 2380.15 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [3.525 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a journalist covering a small-town parade describe the role and setting of the clown in this festive scene.in the scene aicularly clown costume a colorful the festive atmosphere of the festivities a part of a clown 's a colorful costume the merrifai ?? -lsb- ^ mischar with a festive the is a clown 's a festive atmosphere the mwith a festive the merringly with a festive the merringly ___ a the migh with a the merringly a festive the charm of a festive the charmingly a festive the charmingly a festive the charmingly a the charmingly a festive the charmingly a the charm\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 9.325 s\n",
      "📝 Prompt Run 8 | CIDEr: 3.6947 | SPICE: 0.0489 | CosSim: 0.4755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 445.11 tokens per second.\n",
      "PTBTokenizer tokenized 37 tokens at 716.40 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [1.96 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.895 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 242.71 tokens per second.\n",
      "PTBTokenizer tokenized 37 tokens at 873.01 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 823.0 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 271.15 tokens per second.\n",
      "PTBTokenizer tokenized 37 tokens at 821.88 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 750.4 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 229.95 tokens per second.\n",
      "PTBTokenizer tokenized 37 tokens at 674.68 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 705.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 242.11 tokens per second.\n",
      "PTBTokenizer tokenized 37 tokens at 895.65 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 753.3 ms\n",
      "📝 Prompt Run 9 | CIDEr: 3.1566 | SPICE: 0.041 | CosSim: 0.3653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 424.75 tokens per second.\n",
      "PTBTokenizer tokenized 37 tokens at 867.20 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 727.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 273.45 tokens per second.\n",
      "PTBTokenizer tokenized 37 tokens at 865.52 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 762.8 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 250.98 tokens per second.\n",
      "PTBTokenizer tokenized 37 tokens at 857.83 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 754.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 230.90 tokens per second.\n",
      "PTBTokenizer tokenized 37 tokens at 689.11 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 740.0 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 254.66 tokens per second.\n",
      "PTBTokenizer tokenized 37 tokens at 806.94 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 745.4 ms\n",
      "📝 Prompt Run 10 | CIDEr: 3.1566 | SPICE: 0.041 | CosSim: 0.3653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 429.60 tokens per second.\n",
      "PTBTokenizer tokenized 140 tokens at 2684.86 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [14.490 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** terc performing as a clown at a. performing as a. brightly lit festive and colorful costume with exaggerated makeup and a festive small town festive with a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a fest\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 19.83 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 282.91 tokens per second.\n",
      "PTBTokenizer tokenized 140 tokens at 3210.51 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [14.316 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** terc performing as a clown at a. performing as a. brightly lit festive and colorful costume with exaggerated makeup and a festive small town festive with a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a fest\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 19.95 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 291.22 tokens per second.\n",
      "PTBTokenizer tokenized 140 tokens at 3423.52 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [15.164 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** terc performing as a clown at a. performing as a. brightly lit festive and colorful costume with exaggerated makeup and a festive small town festive with a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a fest\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 20.67 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 232.15 tokens per second.\n",
      "PTBTokenizer tokenized 140 tokens at 3342.12 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [14.327 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** terc performing as a clown at a. performing as a. brightly lit festive and colorful costume with exaggerated makeup and a festive small town festive with a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a fest\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 20.00 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 255.89 tokens per second.\n",
      "PTBTokenizer tokenized 140 tokens at 2900.59 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.3 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.4 sec].\n",
      "Threads( StanfordCoreNLP ) [14.620 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** terc performing as a clown at a. performing as a. brightly lit festive and colorful costume with exaggerated makeup and a festive small town festive with a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a fest\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 19.51 s\n",
      "📝 Prompt Run 11 | CIDEr: 2.2911 | SPICE: 0.0363 | CosSim: 0.359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 329.22 tokens per second.\n",
      "PTBTokenizer tokenized 140 tokens at 2799.09 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [14.763 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** terc performing as a clown at a. performing as a. brightly lit festive and colorful costume with exaggerated makeup and a festive small town festive with a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a fest\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 20.41 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 239.20 tokens per second.\n",
      "PTBTokenizer tokenized 140 tokens at 3366.74 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.3 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [14.445 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** terc performing as a clown at a. performing as a. brightly lit festive and colorful costume with exaggerated makeup and a festive small town festive with a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a fest\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 19.72 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 288.79 tokens per second.\n",
      "PTBTokenizer tokenized 140 tokens at 2912.74 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [15.83 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** terc performing as a clown at a. performing as a. brightly lit festive and colorful costume with exaggerated makeup and a festive small town festive with a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a fest\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 20.54 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 234.81 tokens per second.\n",
      "PTBTokenizer tokenized 140 tokens at 2425.28 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [14.191 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** terc performing as a clown at a. performing as a. brightly lit festive and colorful costume with exaggerated makeup and a festive small town festive with a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a fest\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 19.65 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 255.33 tokens per second.\n",
      "PTBTokenizer tokenized 140 tokens at 3297.69 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [14.169 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** terc performing as a clown at a. performing as a. brightly lit festive and colorful costume with exaggerated makeup and a festive small town festive with a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a fest\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 19.85 s\n",
      "📝 Prompt Run 12 | CIDEr: 2.2911 | SPICE: 0.0363 | CosSim: 0.359\n",
      "\n",
      "🔍 Evaluating image ID: 2504 | Ground truths: 5 captions\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 15 tokens at 350.74 tokens per second.\n",
      "PTBTokenizer tokenized 47 tokens at 942.78 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [1.536 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 7.215 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 277.53 tokens per second.\n",
      "PTBTokenizer tokenized 47 tokens at 1121.64 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 762.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 291.80 tokens per second.\n",
      "PTBTokenizer tokenized 47 tokens at 1111.01 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 769.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 230.00 tokens per second.\n",
      "PTBTokenizer tokenized 47 tokens at 1149.90 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 781.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 158.89 tokens per second.\n",
      "PTBTokenizer tokenized 47 tokens at 1134.62 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 750.4 ms\n",
      "📝 Prompt Run 1 | CIDEr: 2.1329 | SPICE: 0.0 | CosSim: 0.1857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 15 tokens at 330.57 tokens per second.\n",
      "PTBTokenizer tokenized 47 tokens at 1093.23 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 751.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 279.49 tokens per second.\n",
      "PTBTokenizer tokenized 47 tokens at 879.41 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 734.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 297.89 tokens per second.\n",
      "PTBTokenizer tokenized 47 tokens at 858.41 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 746.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 227.42 tokens per second.\n",
      "PTBTokenizer tokenized 47 tokens at 1058.33 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 766.0 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 162.83 tokens per second.\n",
      "PTBTokenizer tokenized 47 tokens at 1156.44 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 745.8 ms\n",
      "📝 Prompt Run 2 | CIDEr: 2.1329 | SPICE: 0.0 | CosSim: 0.1857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 15 tokens at 358.67 tokens per second.\n",
      "PTBTokenizer tokenized 21 tokens at 492.73 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [0.486 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.348 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 282.48 tokens per second.\n",
      "PTBTokenizer tokenized 21 tokens at 488.91 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 708.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 309.72 tokens per second.\n",
      "PTBTokenizer tokenized 21 tokens at 452.97 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 783.3 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 232.64 tokens per second.\n",
      "PTBTokenizer tokenized 21 tokens at 492.05 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 784.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 165.25 tokens per second.\n",
      "PTBTokenizer tokenized 21 tokens at 440.51 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 773.6 ms\n",
      "📝 Prompt Run 3 | CIDEr: 1.4719 | SPICE: 0.0623 | CosSim: 0.0732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 15 tokens at 346.22 tokens per second.\n",
      "PTBTokenizer tokenized 21 tokens at 395.91 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 743.8 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 256.69 tokens per second.\n",
      "PTBTokenizer tokenized 21 tokens at 397.26 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 740.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 272.54 tokens per second.\n",
      "PTBTokenizer tokenized 21 tokens at 516.15 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 766.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 227.40 tokens per second.\n",
      "PTBTokenizer tokenized 21 tokens at 415.68 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 741.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 164.92 tokens per second.\n",
      "PTBTokenizer tokenized 21 tokens at 498.31 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 682.8 ms\n",
      "📝 Prompt Run 4 | CIDEr: 1.4719 | SPICE: 0.0623 | CosSim: 0.0732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 15 tokens at 329.33 tokens per second.\n",
      "PTBTokenizer tokenized 13 tokens at 302.13 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [0.393 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.324 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 244.49 tokens per second.\n",
      "PTBTokenizer tokenized 13 tokens at 315.35 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 762.8 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 286.87 tokens per second.\n",
      "PTBTokenizer tokenized 13 tokens at 315.09 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 767.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 232.68 tokens per second.\n",
      "PTBTokenizer tokenized 13 tokens at 306.28 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 754.3 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 148.84 tokens per second.\n",
      "PTBTokenizer tokenized 13 tokens at 229.69 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 733.6 ms\n",
      "📝 Prompt Run 5 | CIDEr: 0.1782 | SPICE: 0.0 | CosSim: 0.0846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 15 tokens at 328.09 tokens per second.\n",
      "PTBTokenizer tokenized 13 tokens at 313.35 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 730.8 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 223.02 tokens per second.\n",
      "PTBTokenizer tokenized 13 tokens at 309.42 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 726.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 306.82 tokens per second.\n",
      "PTBTokenizer tokenized 13 tokens at 257.50 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 738.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 181.48 tokens per second.\n",
      "PTBTokenizer tokenized 13 tokens at 316.15 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 806.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 161.08 tokens per second.\n",
      "PTBTokenizer tokenized 13 tokens at 271.75 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 739.8 ms\n",
      "📝 Prompt Run 6 | CIDEr: 0.1782 | SPICE: 0.0 | CosSim: 0.0846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 15 tokens at 347.62 tokens per second.\n",
      "PTBTokenizer tokenized 134 tokens at 2915.07 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [11.704 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a winter sports photographer recounting a joyful moment you captured describe the scene with vivid detail.in the heart of the majestic snow-capped peaks stretched out before us their triumphant poses their jubilant their jubilant anted in jubilant ant the sky their joyous ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.68 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 261.71 tokens per second.\n",
      "PTBTokenizer tokenized 134 tokens at 2265.44 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [13.65 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a winter sports photographer recounting a joyful moment you captured describe the scene with vivid detail.in the heart of the majestic snow-capped peaks stretched out before us their triumphant poses their jubilant their jubilant anted in jubilant ant the sky their joyous ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 18.72 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 245.34 tokens per second.\n",
      "PTBTokenizer tokenized 134 tokens at 3084.37 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [11.319 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a winter sports photographer recounting a joyful moment you captured describe the scene with vivid detail.in the heart of the majestic snow-capped peaks stretched out before us their triumphant poses their jubilant their jubilant anted in jubilant ant the sky their joyous ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.18 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 234.48 tokens per second.\n",
      "PTBTokenizer tokenized 134 tokens at 3194.55 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [11.889 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a winter sports photographer recounting a joyful moment you captured describe the scene with vivid detail.in the heart of the majestic snow-capped peaks stretched out before us their triumphant poses their jubilant their jubilant anted in jubilant ant the sky their joyous ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.54 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 165.05 tokens per second.\n",
      "PTBTokenizer tokenized 134 tokens at 3183.42 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [11.527 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a winter sports photographer recounting a joyful moment you captured describe the scene with vivid detail.in the heart of the majestic snow-capped peaks stretched out before us their triumphant poses their jubilant their jubilant anted in jubilant ant the sky their joyous ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.29 s\n",
      "📝 Prompt Run 7 | CIDEr: 1.427 | SPICE: 0.0 | CosSim: 0.2652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 15 tokens at 406.42 tokens per second.\n",
      "PTBTokenizer tokenized 134 tokens at 3370.66 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.3 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [11.792 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a winter sports photographer recounting a joyful moment you captured describe the scene with vivid detail.in the heart of the majestic snow-capped peaks stretched out before us their triumphant poses their jubilant their jubilant anted in jubilant ant the sky their joyous ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.97 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 251.16 tokens per second.\n",
      "PTBTokenizer tokenized 134 tokens at 3209.62 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [11.594 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a winter sports photographer recounting a joyful moment you captured describe the scene with vivid detail.in the heart of the majestic snow-capped peaks stretched out before us their triumphant poses their jubilant their jubilant anted in jubilant ant the sky their joyous ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.06 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 327.95 tokens per second.\n",
      "PTBTokenizer tokenized 134 tokens at 3225.42 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [11.381 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a winter sports photographer recounting a joyful moment you captured describe the scene with vivid detail.in the heart of the majestic snow-capped peaks stretched out before us their triumphant poses their jubilant their jubilant anted in jubilant ant the sky their joyous ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.06 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 289.13 tokens per second.\n",
      "PTBTokenizer tokenized 134 tokens at 2996.08 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [12.15 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a winter sports photographer recounting a joyful moment you captured describe the scene with vivid detail.in the heart of the majestic snow-capped peaks stretched out before us their triumphant poses their jubilant their jubilant anted in jubilant ant the sky their joyous ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.57 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 165.91 tokens per second.\n",
      "PTBTokenizer tokenized 134 tokens at 3297.16 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [11.613 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a winter sports photographer recounting a joyful moment you captured describe the scene with vivid detail.in the heart of the majestic snow-capped peaks stretched out before us their triumphant poses their jubilant their jubilant anted in jubilant ant the sky their joyous ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.32 s\n",
      "📝 Prompt Run 8 | CIDEr: 1.427 | SPICE: 0.0 | CosSim: 0.2652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 15 tokens at 392.99 tokens per second.\n",
      "PTBTokenizer tokenized 61 tokens at 1644.96 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.3 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [2.96 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 7.157 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 302.19 tokens per second.\n",
      "PTBTokenizer tokenized 61 tokens at 1577.53 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 735.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 320.19 tokens per second.\n",
      "PTBTokenizer tokenized 61 tokens at 1588.17 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 677.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 240.53 tokens per second.\n",
      "PTBTokenizer tokenized 61 tokens at 1461.73 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 684.3 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 164.57 tokens per second.\n",
      "PTBTokenizer tokenized 61 tokens at 1618.83 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 694.8 ms\n",
      "📝 Prompt Run 9 | CIDEr: 3.1842 | SPICE: 0.0861 | CosSim: 0.4393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 15 tokens at 344.06 tokens per second.\n",
      "PTBTokenizer tokenized 61 tokens at 1490.83 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 689.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 295.91 tokens per second.\n",
      "PTBTokenizer tokenized 61 tokens at 1463.10 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 692.3 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 342.72 tokens per second.\n",
      "PTBTokenizer tokenized 61 tokens at 1537.36 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 691.4 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 258.25 tokens per second.\n",
      "PTBTokenizer tokenized 61 tokens at 1555.02 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 724.8 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 149.74 tokens per second.\n",
      "PTBTokenizer tokenized 61 tokens at 1496.10 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 795.8 ms\n",
      "📝 Prompt Run 10 | CIDEr: 3.1842 | SPICE: 0.0861 | CosSim: 0.4393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 15 tokens at 326.70 tokens per second.\n",
      "PTBTokenizer tokenized 71 tokens at 905.35 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.3 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [2.752 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 7.796 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 295.44 tokens per second.\n",
      "PTBTokenizer tokenized 71 tokens at 1925.30 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 679.4 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 343.93 tokens per second.\n",
      "PTBTokenizer tokenized 71 tokens at 1730.85 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 704.0 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 213.40 tokens per second.\n",
      "PTBTokenizer tokenized 71 tokens at 1884.61 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 677.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 156.44 tokens per second.\n",
      "PTBTokenizer tokenized 71 tokens at 1876.51 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 705.7 ms\n",
      "📝 Prompt Run 11 | CIDEr: 1.5141 | SPICE: 0.0757 | CosSim: 0.181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 15 tokens at 262.60 tokens per second.\n",
      "PTBTokenizer tokenized 71 tokens at 1883.23 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 674.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 242.74 tokens per second.\n",
      "PTBTokenizer tokenized 71 tokens at 1838.18 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 671.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 337.88 tokens per second.\n",
      "PTBTokenizer tokenized 71 tokens at 1827.80 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 677.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 223.21 tokens per second.\n",
      "PTBTokenizer tokenized 71 tokens at 1897.37 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 656.0 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 159.54 tokens per second.\n",
      "PTBTokenizer tokenized 71 tokens at 1803.17 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 713.4 ms\n",
      "📝 Prompt Run 12 | CIDEr: 1.5141 | SPICE: 0.0757 | CosSim: 0.181\n",
      "\n",
      "🔍 Evaluating image ID: 2505 | Ground truths: 5 captions\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 27 tokens at 553.22 tokens per second.\n",
      "PTBTokenizer tokenized 25 tokens at 574.70 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [0.629 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.372 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 451.31 tokens per second.\n",
      "PTBTokenizer tokenized 25 tokens at 580.87 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 676.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 15 tokens at 230.02 tokens per second.\n",
      "PTBTokenizer tokenized 25 tokens at 662.48 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 698.0 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 373.07 tokens per second.\n",
      "PTBTokenizer tokenized 25 tokens at 636.54 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 719.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 264.21 tokens per second.\n",
      "PTBTokenizer tokenized 25 tokens at 667.86 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 706.8 ms\n",
      "📝 Prompt Run 1 | CIDEr: 1.1847 | SPICE: 0.0707 | CosSim: 0.3579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 27 tokens at 683.35 tokens per second.\n",
      "PTBTokenizer tokenized 25 tokens at 661.30 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 696.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 380.74 tokens per second.\n",
      "PTBTokenizer tokenized 25 tokens at 656.65 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 691.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 15 tokens at 358.99 tokens per second.\n",
      "PTBTokenizer tokenized 25 tokens at 425.63 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 777.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 231.42 tokens per second.\n",
      "PTBTokenizer tokenized 25 tokens at 620.58 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 746.0 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 220.39 tokens per second.\n",
      "PTBTokenizer tokenized 25 tokens at 553.38 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 776.1 ms\n",
      "📝 Prompt Run 2 | CIDEr: 1.1847 | SPICE: 0.0707 | CosSim: 0.3579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 27 tokens at 474.30 tokens per second.\n",
      "PTBTokenizer tokenized 23 tokens at 562.86 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [0.517 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.031 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 468.06 tokens per second.\n",
      "PTBTokenizer tokenized 23 tokens at 610.23 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 687.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 15 tokens at 387.71 tokens per second.\n",
      "PTBTokenizer tokenized 23 tokens at 600.41 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 699.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 352.00 tokens per second.\n",
      "PTBTokenizer tokenized 23 tokens at 612.00 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 695.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 249.70 tokens per second.\n",
      "PTBTokenizer tokenized 23 tokens at 609.56 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 676.2 ms\n",
      "📝 Prompt Run 3 | CIDEr: 1.3378 | SPICE: 0.0348 | CosSim: 0.2155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 27 tokens at 709.10 tokens per second.\n",
      "PTBTokenizer tokenized 23 tokens at 581.75 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 707.4 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 472.05 tokens per second.\n",
      "PTBTokenizer tokenized 23 tokens at 585.66 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 681.4 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 15 tokens at 324.60 tokens per second.\n",
      "PTBTokenizer tokenized 23 tokens at 605.19 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 717.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 368.98 tokens per second.\n",
      "PTBTokenizer tokenized 23 tokens at 605.90 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 685.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 204.20 tokens per second.\n",
      "PTBTokenizer tokenized 23 tokens at 545.95 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 616.5 ms\n",
      "📝 Prompt Run 4 | CIDEr: 1.3378 | SPICE: 0.0348 | CosSim: 0.2155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 27 tokens at 566.84 tokens per second.\n",
      "PTBTokenizer tokenized 22 tokens at 637.81 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [0.595 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.473 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 420.32 tokens per second.\n",
      "PTBTokenizer tokenized 22 tokens at 515.72 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 809.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 15 tokens at 290.12 tokens per second.\n",
      "PTBTokenizer tokenized 22 tokens at 511.72 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 618.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 362.68 tokens per second.\n",
      "PTBTokenizer tokenized 22 tokens at 568.67 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 697.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 228.97 tokens per second.\n",
      "PTBTokenizer tokenized 22 tokens at 575.34 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 705.6 ms\n",
      "📝 Prompt Run 5 | CIDEr: 1.4134 | SPICE: 0.047 | CosSim: 0.2959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 27 tokens at 709.98 tokens per second.\n",
      "PTBTokenizer tokenized 22 tokens at 530.86 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 674.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 363.41 tokens per second.\n",
      "PTBTokenizer tokenized 22 tokens at 495.65 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 667.3 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 15 tokens at 381.17 tokens per second.\n",
      "PTBTokenizer tokenized 22 tokens at 537.69 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 671.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 350.46 tokens per second.\n",
      "PTBTokenizer tokenized 22 tokens at 560.92 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 663.3 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 212.42 tokens per second.\n",
      "PTBTokenizer tokenized 22 tokens at 584.00 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 696.1 ms\n",
      "📝 Prompt Run 6 | CIDEr: 1.4134 | SPICE: 0.047 | CosSim: 0.2959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 27 tokens at 689.85 tokens per second.\n",
      "PTBTokenizer tokenized 130 tokens at 3201.85 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [7.785 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a market researcher documenting traditional grocery stores describe what the boy is doing and what the store looks like.the scene depicts a bustling well-stocked traditional grocery store bustling with a variety of products the store is characterized by its rustic charm with wooden shelves stacked high with an assortment of canned goods jars and other staples the store 's interior is warmly illuminated by flickering light bulbs casting a cozy glow over the scene in the midst of the store a boy is engrossed in his task meticulously scooping cereal from a large bin into a bag his focus is unwavering a testament to his dedication to his duty the store 's atmosphere is\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.67 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 456.57 tokens per second.\n",
      "PTBTokenizer tokenized 130 tokens at 3326.56 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [7.868 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a market researcher documenting traditional grocery stores describe what the boy is doing and what the store looks like.the scene depicts a bustling well-stocked traditional grocery store bustling with a variety of products the store is characterized by its rustic charm with wooden shelves stacked high with an assortment of canned goods jars and other staples the store 's interior is warmly illuminated by flickering light bulbs casting a cozy glow over the scene in the midst of the store a boy is engrossed in his task meticulously scooping cereal from a large bin into a bag his focus is unwavering a testament to his dedication to his duty the store 's atmosphere is\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.46 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 15 tokens at 383.72 tokens per second.\n",
      "PTBTokenizer tokenized 130 tokens at 3223.59 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [7.580 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a market researcher documenting traditional grocery stores describe what the boy is doing and what the store looks like.the scene depicts a bustling well-stocked traditional grocery store bustling with a variety of products the store is characterized by its rustic charm with wooden shelves stacked high with an assortment of canned goods jars and other staples the store 's interior is warmly illuminated by flickering light bulbs casting a cozy glow over the scene in the midst of the store a boy is engrossed in his task meticulously scooping cereal from a large bin into a bag his focus is unwavering a testament to his dedication to his duty the store 's atmosphere is\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 12.99 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 231.69 tokens per second.\n",
      "PTBTokenizer tokenized 130 tokens at 2453.93 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [7.973 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a market researcher documenting traditional grocery stores describe what the boy is doing and what the store looks like.the scene depicts a bustling well-stocked traditional grocery store bustling with a variety of products the store is characterized by its rustic charm with wooden shelves stacked high with an assortment of canned goods jars and other staples the store 's interior is warmly illuminated by flickering light bulbs casting a cozy glow over the scene in the midst of the store a boy is engrossed in his task meticulously scooping cereal from a large bin into a bag his focus is unwavering a testament to his dedication to his duty the store 's atmosphere is\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.38 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 259.38 tokens per second.\n",
      "PTBTokenizer tokenized 130 tokens at 3192.27 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [7.706 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a market researcher documenting traditional grocery stores describe what the boy is doing and what the store looks like.the scene depicts a bustling well-stocked traditional grocery store bustling with a variety of products the store is characterized by its rustic charm with wooden shelves stacked high with an assortment of canned goods jars and other staples the store 's interior is warmly illuminated by flickering light bulbs casting a cozy glow over the scene in the midst of the store a boy is engrossed in his task meticulously scooping cereal from a large bin into a bag his focus is unwavering a testament to his dedication to his duty the store 's atmosphere is\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.40 s\n",
      "📝 Prompt Run 7 | CIDEr: 2.3595 | SPICE: 0.0149 | CosSim: 0.3983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 27 tokens at 624.23 tokens per second.\n",
      "PTBTokenizer tokenized 130 tokens at 2297.66 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [7.302 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a market researcher documenting traditional grocery stores describe what the boy is doing and what the store looks like.the scene depicts a bustling well-stocked traditional grocery store bustling with a variety of products the store is characterized by its rustic charm with wooden shelves stacked high with an assortment of canned goods jars and other staples the store 's interior is warmly illuminated by flickering light bulbs casting a cozy glow over the scene in the midst of the store a boy is engrossed in his task meticulously scooping cereal from a large bin into a bag his focus is unwavering a testament to his dedication to his duty the store 's atmosphere is\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.08 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 474.99 tokens per second.\n",
      "PTBTokenizer tokenized 130 tokens at 2788.26 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [7.744 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a market researcher documenting traditional grocery stores describe what the boy is doing and what the store looks like.the scene depicts a bustling well-stocked traditional grocery store bustling with a variety of products the store is characterized by its rustic charm with wooden shelves stacked high with an assortment of canned goods jars and other staples the store 's interior is warmly illuminated by flickering light bulbs casting a cozy glow over the scene in the midst of the store a boy is engrossed in his task meticulously scooping cereal from a large bin into a bag his focus is unwavering a testament to his dedication to his duty the store 's atmosphere is\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.28 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 15 tokens at 345.03 tokens per second.\n",
      "PTBTokenizer tokenized 130 tokens at 3258.09 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [7.680 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a market researcher documenting traditional grocery stores describe what the boy is doing and what the store looks like.the scene depicts a bustling well-stocked traditional grocery store bustling with a variety of products the store is characterized by its rustic charm with wooden shelves stacked high with an assortment of canned goods jars and other staples the store 's interior is warmly illuminated by flickering light bulbs casting a cozy glow over the scene in the midst of the store a boy is engrossed in his task meticulously scooping cereal from a large bin into a bag his focus is unwavering a testament to his dedication to his duty the store 's atmosphere is\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.16 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 366.37 tokens per second.\n",
      "PTBTokenizer tokenized 130 tokens at 3383.30 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [7.841 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a market researcher documenting traditional grocery stores describe what the boy is doing and what the store looks like.the scene depicts a bustling well-stocked traditional grocery store bustling with a variety of products the store is characterized by its rustic charm with wooden shelves stacked high with an assortment of canned goods jars and other staples the store 's interior is warmly illuminated by flickering light bulbs casting a cozy glow over the scene in the midst of the store a boy is engrossed in his task meticulously scooping cereal from a large bin into a bag his focus is unwavering a testament to his dedication to his duty the store 's atmosphere is\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.50 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 246.48 tokens per second.\n",
      "PTBTokenizer tokenized 130 tokens at 3318.75 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [7.599 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a market researcher documenting traditional grocery stores describe what the boy is doing and what the store looks like.the scene depicts a bustling well-stocked traditional grocery store bustling with a variety of products the store is characterized by its rustic charm with wooden shelves stacked high with an assortment of canned goods jars and other staples the store 's interior is warmly illuminated by flickering light bulbs casting a cozy glow over the scene in the midst of the store a boy is engrossed in his task meticulously scooping cereal from a large bin into a bag his focus is unwavering a testament to his dedication to his duty the store 's atmosphere is\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.23 s\n",
      "📝 Prompt Run 8 | CIDEr: 2.3595 | SPICE: 0.0149 | CosSim: 0.3983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 27 tokens at 600.41 tokens per second.\n",
      "PTBTokenizer tokenized 50 tokens at 1331.23 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [1.355 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 7.064 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 365.91 tokens per second.\n",
      "PTBTokenizer tokenized 50 tokens at 1316.05 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 663.8 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 15 tokens at 366.59 tokens per second.\n",
      "PTBTokenizer tokenized 50 tokens at 838.72 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 691.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 363.32 tokens per second.\n",
      "PTBTokenizer tokenized 50 tokens at 1091.48 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 672.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 262.49 tokens per second.\n",
      "PTBTokenizer tokenized 50 tokens at 1309.03 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 679.5 ms\n",
      "📝 Prompt Run 9 | CIDEr: 3.5081 | SPICE: 0.0745 | CosSim: 0.3357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 27 tokens at 563.30 tokens per second.\n",
      "PTBTokenizer tokenized 50 tokens at 1282.27 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 674.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 465.26 tokens per second.\n",
      "PTBTokenizer tokenized 50 tokens at 1286.35 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 688.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 15 tokens at 394.67 tokens per second.\n",
      "PTBTokenizer tokenized 50 tokens at 1333.35 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 691.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 303.59 tokens per second.\n",
      "PTBTokenizer tokenized 50 tokens at 1279.55 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 692.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 247.42 tokens per second.\n",
      "PTBTokenizer tokenized 50 tokens at 1323.83 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 709.8 ms\n",
      "📝 Prompt Run 10 | CIDEr: 3.5081 | SPICE: 0.0745 | CosSim: 0.3357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 27 tokens at 673.05 tokens per second.\n",
      "PTBTokenizer tokenized 133 tokens at 3367.14 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [13.174 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** image of a large store with vast assortment of goods tercet ** activity ** shoppers browsing and selecting items ** environment ** busy indoor store with wide aisles of products ** additional notes ** the store specializes in a huge selection of candies and snacks with numerous bins of bulk candy and shelves of packaged goods the store appears well-stocked and well-lit with a classic retro feel there are signs in multiple languages indicating a diverse customer base\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 18.62 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 473.89 tokens per second.\n",
      "PTBTokenizer tokenized 133 tokens at 2889.95 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [12.883 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** image of a large store with vast assortment of goods tercet ** activity ** shoppers browsing and selecting items ** environment ** busy indoor store with wide aisles of products ** additional notes ** the store specializes in a huge selection of candies and snacks with numerous bins of bulk candy and shelves of packaged goods the store appears well-stocked and well-lit with a classic retro feel there are signs in multiple languages indicating a diverse customer base\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 18.56 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 15 tokens at 388.05 tokens per second.\n",
      "PTBTokenizer tokenized 133 tokens at 3090.15 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.6 sec].\n",
      "Threads( StanfordCoreNLP ) [13.82 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** image of a large store with vast assortment of goods tercet ** activity ** shoppers browsing and selecting items ** environment ** busy indoor store with wide aisles of products ** additional notes ** the store specializes in a huge selection of candies and snacks with numerous bins of bulk candy and shelves of packaged goods the store appears well-stocked and well-lit with a classic retro feel there are signs in multiple languages indicating a diverse customer base\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 18.56 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 389.94 tokens per second.\n",
      "PTBTokenizer tokenized 133 tokens at 3196.89 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.4 sec].\n",
      "Threads( StanfordCoreNLP ) [12.230 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** image of a large store with vast assortment of goods tercet ** activity ** shoppers browsing and selecting items ** environment ** busy indoor store with wide aisles of products ** additional notes ** the store specializes in a huge selection of candies and snacks with numerous bins of bulk candy and shelves of packaged goods the store appears well-stocked and well-lit with a classic retro feel there are signs in multiple languages indicating a diverse customer base\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.49 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 264.95 tokens per second.\n",
      "PTBTokenizer tokenized 133 tokens at 2862.50 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [12.530 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** image of a large store with vast assortment of goods tercet ** activity ** shoppers browsing and selecting items ** environment ** busy indoor store with wide aisles of products ** additional notes ** the store specializes in a huge selection of candies and snacks with numerous bins of bulk candy and shelves of packaged goods the store appears well-stocked and well-lit with a classic retro feel there are signs in multiple languages indicating a diverse customer base\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 18.04 s\n",
      "📝 Prompt Run 11 | CIDEr: 2.0752 | SPICE: 0.0421 | CosSim: 0.2835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 27 tokens at 642.21 tokens per second.\n",
      "PTBTokenizer tokenized 133 tokens at 3460.22 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [12.400 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** image of a large store with vast assortment of goods tercet ** activity ** shoppers browsing and selecting items ** environment ** busy indoor store with wide aisles of products ** additional notes ** the store specializes in a huge selection of candies and snacks with numerous bins of bulk candy and shelves of packaged goods the store appears well-stocked and well-lit with a classic retro feel there are signs in multiple languages indicating a diverse customer base\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 18.06 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 409.18 tokens per second.\n",
      "PTBTokenizer tokenized 133 tokens at 3098.29 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [13.55 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** image of a large store with vast assortment of goods tercet ** activity ** shoppers browsing and selecting items ** environment ** busy indoor store with wide aisles of products ** additional notes ** the store specializes in a huge selection of candies and snacks with numerous bins of bulk candy and shelves of packaged goods the store appears well-stocked and well-lit with a classic retro feel there are signs in multiple languages indicating a diverse customer base\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 18.85 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 15 tokens at 376.32 tokens per second.\n",
      "PTBTokenizer tokenized 133 tokens at 3154.28 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [12.724 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** image of a large store with vast assortment of goods tercet ** activity ** shoppers browsing and selecting items ** environment ** busy indoor store with wide aisles of products ** additional notes ** the store specializes in a huge selection of candies and snacks with numerous bins of bulk candy and shelves of packaged goods the store appears well-stocked and well-lit with a classic retro feel there are signs in multiple languages indicating a diverse customer base\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 18.38 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 405.72 tokens per second.\n",
      "PTBTokenizer tokenized 133 tokens at 3255.45 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.3 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [12.334 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** image of a large store with vast assortment of goods tercet ** activity ** shoppers browsing and selecting items ** environment ** busy indoor store with wide aisles of products ** additional notes ** the store specializes in a huge selection of candies and snacks with numerous bins of bulk candy and shelves of packaged goods the store appears well-stocked and well-lit with a classic retro feel there are signs in multiple languages indicating a diverse customer base\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.69 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 238.89 tokens per second.\n",
      "PTBTokenizer tokenized 133 tokens at 2439.75 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [12.862 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** image of a large store with vast assortment of goods tercet ** activity ** shoppers browsing and selecting items ** environment ** busy indoor store with wide aisles of products ** additional notes ** the store specializes in a huge selection of candies and snacks with numerous bins of bulk candy and shelves of packaged goods the store appears well-stocked and well-lit with a classic retro feel there are signs in multiple languages indicating a diverse customer base\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 18.69 s\n",
      "📝 Prompt Run 12 | CIDEr: 2.0752 | SPICE: 0.0421 | CosSim: 0.2835\n",
      "\n",
      "🔍 Evaluating image ID: 2506 | Ground truths: 5 captions\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 31 tokens at 706.62 tokens per second.\n",
      "PTBTokenizer tokenized 72 tokens at 1697.32 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [2.202 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 8.521 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 24 tokens at 589.34 tokens per second.\n",
      "PTBTokenizer tokenized 72 tokens at 1593.49 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 736.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 26 tokens at 782.68 tokens per second.\n",
      "PTBTokenizer tokenized 72 tokens at 1718.08 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 613.4 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 490.52 tokens per second.\n",
      "PTBTokenizer tokenized 72 tokens at 1846.52 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 706.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 390.88 tokens per second.\n",
      "PTBTokenizer tokenized 72 tokens at 1669.20 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 734.6 ms\n",
      "📝 Prompt Run 1 | CIDEr: 2.6611 | SPICE: 0.0224 | CosSim: 0.3904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 31 tokens at 571.19 tokens per second.\n",
      "PTBTokenizer tokenized 72 tokens at 1721.39 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 758.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 24 tokens at 510.26 tokens per second.\n",
      "PTBTokenizer tokenized 72 tokens at 1708.91 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 765.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 26 tokens at 619.44 tokens per second.\n",
      "PTBTokenizer tokenized 72 tokens at 1625.18 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 762.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 378.92 tokens per second.\n",
      "PTBTokenizer tokenized 72 tokens at 1659.65 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 766.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 332.63 tokens per second.\n",
      "PTBTokenizer tokenized 72 tokens at 1388.38 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 727.4 ms\n",
      "📝 Prompt Run 2 | CIDEr: 2.6611 | SPICE: 0.0224 | CosSim: 0.3904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 31 tokens at 719.93 tokens per second.\n",
      "PTBTokenizer tokenized 28 tokens at 665.35 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [0.679 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.633 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 24 tokens at 512.58 tokens per second.\n",
      "PTBTokenizer tokenized 28 tokens at 618.55 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 735.4 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 26 tokens at 603.16 tokens per second.\n",
      "PTBTokenizer tokenized 28 tokens at 701.27 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 768.3 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 401.28 tokens per second.\n",
      "PTBTokenizer tokenized 28 tokens at 665.62 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 770.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 262.60 tokens per second.\n",
      "PTBTokenizer tokenized 28 tokens at 642.34 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 773.4 ms\n",
      "📝 Prompt Run 3 | CIDEr: 2.6322 | SPICE: 0.0634 | CosSim: 0.394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 31 tokens at 720.03 tokens per second.\n",
      "PTBTokenizer tokenized 28 tokens at 641.37 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 759.3 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 24 tokens at 583.21 tokens per second.\n",
      "PTBTokenizer tokenized 28 tokens at 665.92 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 749.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 26 tokens at 591.29 tokens per second.\n",
      "PTBTokenizer tokenized 28 tokens at 675.46 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 772.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 443.36 tokens per second.\n",
      "PTBTokenizer tokenized 28 tokens at 657.41 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 746.0 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 321.68 tokens per second.\n",
      "PTBTokenizer tokenized 28 tokens at 633.34 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 769.5 ms\n",
      "📝 Prompt Run 4 | CIDEr: 2.6322 | SPICE: 0.0634 | CosSim: 0.394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 31 tokens at 651.99 tokens per second.\n",
      "PTBTokenizer tokenized 55 tokens at 1277.50 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [1.658 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.950 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 24 tokens at 569.42 tokens per second.\n",
      "PTBTokenizer tokenized 55 tokens at 1299.61 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 804.4 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 26 tokens at 521.80 tokens per second.\n",
      "PTBTokenizer tokenized 55 tokens at 1266.65 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 741.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 419.27 tokens per second.\n",
      "PTBTokenizer tokenized 55 tokens at 1268.02 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 732.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 277.94 tokens per second.\n",
      "PTBTokenizer tokenized 55 tokens at 1286.63 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 791.1 ms\n",
      "📝 Prompt Run 5 | CIDEr: 3.4233 | SPICE: 0.1026 | CosSim: 0.5301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 31 tokens at 705.92 tokens per second.\n",
      "PTBTokenizer tokenized 55 tokens at 1320.31 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 738.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 24 tokens at 548.90 tokens per second.\n",
      "PTBTokenizer tokenized 55 tokens at 1323.00 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 780.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 26 tokens at 613.81 tokens per second.\n",
      "PTBTokenizer tokenized 55 tokens at 1314.54 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 728.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 375.92 tokens per second.\n",
      "PTBTokenizer tokenized 55 tokens at 1277.04 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 738.0 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 329.24 tokens per second.\n",
      "PTBTokenizer tokenized 55 tokens at 1235.64 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 748.4 ms\n",
      "📝 Prompt Run 6 | CIDEr: 3.4233 | SPICE: 0.1026 | CosSim: 0.5301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 31 tokens at 729.63 tokens per second.\n",
      "PTBTokenizer tokenized 135 tokens at 2612.59 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [9.336 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are an it workplace culture analyst describe the work environment and team dynamic shown in this image.the work environment depicted in the image appears to portray a casual and informal office culture the central figure is seen working on a laptop while seated on an oversized unconventional office chair which resembles a giant hand suggesting a playful and relaxed atmosphere the walls are adorned with humorous and lighthearted posters reinforcing the informal vibe another individual is casually leaning against a wall dressed in casual attire further emphasizing the informal dress code the presence of various tech gadgets such as headphones and a laptop indicates a tech-savvy and modern workplace the overall scene suggests a dynamic and friendly team dynamic\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.13 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 24 tokens at 581.62 tokens per second.\n",
      "PTBTokenizer tokenized 135 tokens at 3318.39 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [9.362 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are an it workplace culture analyst describe the work environment and team dynamic shown in this image.the work environment depicted in the image appears to portray a casual and informal office culture the central figure is seen working on a laptop while seated on an oversized unconventional office chair which resembles a giant hand suggesting a playful and relaxed atmosphere the walls are adorned with humorous and lighthearted posters reinforcing the informal vibe another individual is casually leaning against a wall dressed in casual attire further emphasizing the informal dress code the presence of various tech gadgets such as headphones and a laptop indicates a tech-savvy and modern workplace the overall scene suggests a dynamic and friendly team dynamic\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.09 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 26 tokens at 616.27 tokens per second.\n",
      "PTBTokenizer tokenized 135 tokens at 2887.47 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [9.557 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are an it workplace culture analyst describe the work environment and team dynamic shown in this image.the work environment depicted in the image appears to portray a casual and informal office culture the central figure is seen working on a laptop while seated on an oversized unconventional office chair which resembles a giant hand suggesting a playful and relaxed atmosphere the walls are adorned with humorous and lighthearted posters reinforcing the informal vibe another individual is casually leaning against a wall dressed in casual attire further emphasizing the informal dress code the presence of various tech gadgets such as headphones and a laptop indicates a tech-savvy and modern workplace the overall scene suggests a dynamic and friendly team dynamic\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.29 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 426.45 tokens per second.\n",
      "PTBTokenizer tokenized 135 tokens at 3263.13 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [9.863 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are an it workplace culture analyst describe the work environment and team dynamic shown in this image.the work environment depicted in the image appears to portray a casual and informal office culture the central figure is seen working on a laptop while seated on an oversized unconventional office chair which resembles a giant hand suggesting a playful and relaxed atmosphere the walls are adorned with humorous and lighthearted posters reinforcing the informal vibe another individual is casually leaning against a wall dressed in casual attire further emphasizing the informal dress code the presence of various tech gadgets such as headphones and a laptop indicates a tech-savvy and modern workplace the overall scene suggests a dynamic and friendly team dynamic\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.60 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 337.42 tokens per second.\n",
      "PTBTokenizer tokenized 135 tokens at 3138.50 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [9.699 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are an it workplace culture analyst describe the work environment and team dynamic shown in this image.the work environment depicted in the image appears to portray a casual and informal office culture the central figure is seen working on a laptop while seated on an oversized unconventional office chair which resembles a giant hand suggesting a playful and relaxed atmosphere the walls are adorned with humorous and lighthearted posters reinforcing the informal vibe another individual is casually leaning against a wall dressed in casual attire further emphasizing the informal dress code the presence of various tech gadgets such as headphones and a laptop indicates a tech-savvy and modern workplace the overall scene suggests a dynamic and friendly team dynamic\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.38 s\n",
      "📝 Prompt Run 7 | CIDEr: 2.5925 | SPICE: 0.0221 | CosSim: 0.3672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 31 tokens at 695.60 tokens per second.\n",
      "PTBTokenizer tokenized 135 tokens at 2687.51 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [9.921 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are an it workplace culture analyst describe the work environment and team dynamic shown in this image.the work environment depicted in the image appears to portray a casual and informal office culture the central figure is seen working on a laptop while seated on an oversized unconventional office chair which resembles a giant hand suggesting a playful and relaxed atmosphere the walls are adorned with humorous and lighthearted posters reinforcing the informal vibe another individual is casually leaning against a wall dressed in casual attire further emphasizing the informal dress code the presence of various tech gadgets such as headphones and a laptop indicates a tech-savvy and modern workplace the overall scene suggests a dynamic and friendly team dynamic\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.55 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 24 tokens at 577.90 tokens per second.\n",
      "PTBTokenizer tokenized 135 tokens at 2499.81 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [9.658 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are an it workplace culture analyst describe the work environment and team dynamic shown in this image.the work environment depicted in the image appears to portray a casual and informal office culture the central figure is seen working on a laptop while seated on an oversized unconventional office chair which resembles a giant hand suggesting a playful and relaxed atmosphere the walls are adorned with humorous and lighthearted posters reinforcing the informal vibe another individual is casually leaning against a wall dressed in casual attire further emphasizing the informal dress code the presence of various tech gadgets such as headphones and a laptop indicates a tech-savvy and modern workplace the overall scene suggests a dynamic and friendly team dynamic\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.49 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 26 tokens at 550.32 tokens per second.\n",
      "PTBTokenizer tokenized 135 tokens at 3526.11 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [9.715 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are an it workplace culture analyst describe the work environment and team dynamic shown in this image.the work environment depicted in the image appears to portray a casual and informal office culture the central figure is seen working on a laptop while seated on an oversized unconventional office chair which resembles a giant hand suggesting a playful and relaxed atmosphere the walls are adorned with humorous and lighthearted posters reinforcing the informal vibe another individual is casually leaning against a wall dressed in casual attire further emphasizing the informal dress code the presence of various tech gadgets such as headphones and a laptop indicates a tech-savvy and modern workplace the overall scene suggests a dynamic and friendly team dynamic\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.42 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 365.99 tokens per second.\n",
      "PTBTokenizer tokenized 135 tokens at 3039.99 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [9.542 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are an it workplace culture analyst describe the work environment and team dynamic shown in this image.the work environment depicted in the image appears to portray a casual and informal office culture the central figure is seen working on a laptop while seated on an oversized unconventional office chair which resembles a giant hand suggesting a playful and relaxed atmosphere the walls are adorned with humorous and lighthearted posters reinforcing the informal vibe another individual is casually leaning against a wall dressed in casual attire further emphasizing the informal dress code the presence of various tech gadgets such as headphones and a laptop indicates a tech-savvy and modern workplace the overall scene suggests a dynamic and friendly team dynamic\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.03 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 357.50 tokens per second.\n",
      "PTBTokenizer tokenized 135 tokens at 2491.41 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [9.785 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are an it workplace culture analyst describe the work environment and team dynamic shown in this image.the work environment depicted in the image appears to portray a casual and informal office culture the central figure is seen working on a laptop while seated on an oversized unconventional office chair which resembles a giant hand suggesting a playful and relaxed atmosphere the walls are adorned with humorous and lighthearted posters reinforcing the informal vibe another individual is casually leaning against a wall dressed in casual attire further emphasizing the informal dress code the presence of various tech gadgets such as headphones and a laptop indicates a tech-savvy and modern workplace the overall scene suggests a dynamic and friendly team dynamic\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.65 s\n",
      "📝 Prompt Run 8 | CIDEr: 2.5925 | SPICE: 0.0221 | CosSim: 0.3672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 31 tokens at 770.74 tokens per second.\n",
      "PTBTokenizer tokenized 127 tokens at 3018.44 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.3 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [5.828 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"a <text_1> is using a laptop at a desk while two <text_2> are in the background.sure here 's a detailed summary of the passage properly formatted and with the changes highlighted accordingly a <text_1> is using a laptop at a desk while two <text_2> are in the background please replace the following text with the highlighted text original text <text_1> is using a laptop at a desk while two <text_2> are in the background formatted and highlighted text a <text_1> is using a laptop at a desk while two <text_2> are in the background this revision ensures the text is properly formatted and the highlighted changes are incorporated\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 11.03 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 24 tokens at 542.89 tokens per second.\n",
      "PTBTokenizer tokenized 127 tokens at 2863.07 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [5.978 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"a <text_1> is using a laptop at a desk while two <text_2> are in the background.sure here 's a detailed summary of the passage properly formatted and with the changes highlighted accordingly a <text_1> is using a laptop at a desk while two <text_2> are in the background please replace the following text with the highlighted text original text <text_1> is using a laptop at a desk while two <text_2> are in the background formatted and highlighted text a <text_1> is using a laptop at a desk while two <text_2> are in the background this revision ensures the text is properly formatted and the highlighted changes are incorporated\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 11.36 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 26 tokens at 646.72 tokens per second.\n",
      "PTBTokenizer tokenized 127 tokens at 3001.75 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [5.903 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"a <text_1> is using a laptop at a desk while two <text_2> are in the background.sure here 's a detailed summary of the passage properly formatted and with the changes highlighted accordingly a <text_1> is using a laptop at a desk while two <text_2> are in the background please replace the following text with the highlighted text original text <text_1> is using a laptop at a desk while two <text_2> are in the background formatted and highlighted text a <text_1> is using a laptop at a desk while two <text_2> are in the background this revision ensures the text is properly formatted and the highlighted changes are incorporated\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 11.26 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 350.61 tokens per second.\n",
      "PTBTokenizer tokenized 127 tokens at 3000.22 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [5.864 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"a <text_1> is using a laptop at a desk while two <text_2> are in the background.sure here 's a detailed summary of the passage properly formatted and with the changes highlighted accordingly a <text_1> is using a laptop at a desk while two <text_2> are in the background please replace the following text with the highlighted text original text <text_1> is using a laptop at a desk while two <text_2> are in the background formatted and highlighted text a <text_1> is using a laptop at a desk while two <text_2> are in the background this revision ensures the text is properly formatted and the highlighted changes are incorporated\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 11.59 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 342.17 tokens per second.\n",
      "PTBTokenizer tokenized 127 tokens at 2842.37 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [5.816 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"a <text_1> is using a laptop at a desk while two <text_2> are in the background.sure here 's a detailed summary of the passage properly formatted and with the changes highlighted accordingly a <text_1> is using a laptop at a desk while two <text_2> are in the background please replace the following text with the highlighted text original text <text_1> is using a laptop at a desk while two <text_2> are in the background formatted and highlighted text a <text_1> is using a laptop at a desk while two <text_2> are in the background this revision ensures the text is properly formatted and the highlighted changes are incorporated\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 11.55 s\n",
      "📝 Prompt Run 9 | CIDEr: 3.8803 | SPICE: 0.0749 | CosSim: 0.3193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 31 tokens at 721.81 tokens per second.\n",
      "PTBTokenizer tokenized 127 tokens at 2470.61 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.3 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [5.610 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"a <text_1> is using a laptop at a desk while two <text_2> are in the background.sure here 's a detailed summary of the passage properly formatted and with the changes highlighted accordingly a <text_1> is using a laptop at a desk while two <text_2> are in the background please replace the following text with the highlighted text original text <text_1> is using a laptop at a desk while two <text_2> are in the background formatted and highlighted text a <text_1> is using a laptop at a desk while two <text_2> are in the background this revision ensures the text is properly formatted and the highlighted changes are incorporated\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 10.76 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 24 tokens at 538.15 tokens per second.\n",
      "PTBTokenizer tokenized 127 tokens at 2254.82 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [5.498 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"a <text_1> is using a laptop at a desk while two <text_2> are in the background.sure here 's a detailed summary of the passage properly formatted and with the changes highlighted accordingly a <text_1> is using a laptop at a desk while two <text_2> are in the background please replace the following text with the highlighted text original text <text_1> is using a laptop at a desk while two <text_2> are in the background formatted and highlighted text a <text_1> is using a laptop at a desk while two <text_2> are in the background this revision ensures the text is properly formatted and the highlighted changes are incorporated\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 11.18 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 26 tokens at 521.93 tokens per second.\n",
      "PTBTokenizer tokenized 127 tokens at 3130.13 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [6.49 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"a <text_1> is using a laptop at a desk while two <text_2> are in the background.sure here 's a detailed summary of the passage properly formatted and with the changes highlighted accordingly a <text_1> is using a laptop at a desk while two <text_2> are in the background please replace the following text with the highlighted text original text <text_1> is using a laptop at a desk while two <text_2> are in the background formatted and highlighted text a <text_1> is using a laptop at a desk while two <text_2> are in the background this revision ensures the text is properly formatted and the highlighted changes are incorporated\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 11.54 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 398.28 tokens per second.\n",
      "PTBTokenizer tokenized 127 tokens at 2472.86 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [5.781 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"a <text_1> is using a laptop at a desk while two <text_2> are in the background.sure here 's a detailed summary of the passage properly formatted and with the changes highlighted accordingly a <text_1> is using a laptop at a desk while two <text_2> are in the background please replace the following text with the highlighted text original text <text_1> is using a laptop at a desk while two <text_2> are in the background formatted and highlighted text a <text_1> is using a laptop at a desk while two <text_2> are in the background this revision ensures the text is properly formatted and the highlighted changes are incorporated\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 11.49 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 342.51 tokens per second.\n",
      "PTBTokenizer tokenized 127 tokens at 2512.53 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [5.451 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"a <text_1> is using a laptop at a desk while two <text_2> are in the background.sure here 's a detailed summary of the passage properly formatted and with the changes highlighted accordingly a <text_1> is using a laptop at a desk while two <text_2> are in the background please replace the following text with the highlighted text original text <text_1> is using a laptop at a desk while two <text_2> are in the background formatted and highlighted text a <text_1> is using a laptop at a desk while two <text_2> are in the background this revision ensures the text is properly formatted and the highlighted changes are incorporated\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 11.13 s\n",
      "📝 Prompt Run 10 | CIDEr: 3.8803 | SPICE: 0.0749 | CosSim: 0.3193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 31 tokens at 591.93 tokens per second.\n",
      "PTBTokenizer tokenized 135 tokens at 3061.21 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [8.600 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** subject man working on a laptop ** activity ** sitting at a desk using a laptop ** environment ** office setting with a desk chair and posters on the wall ** additional notes ** a man is intensely working on his laptop seemingly in a casual office environment with humorous posters on the wall including one depicting a character from a popular show another man is standing and observing the seated man adding a casual and relaxed atmosphere to the workspace\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 14.63 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 24 tokens at 444.55 tokens per second.\n",
      "PTBTokenizer tokenized 135 tokens at 3161.77 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [8.560 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** subject man working on a laptop ** activity ** sitting at a desk using a laptop ** environment ** office setting with a desk chair and posters on the wall ** additional notes ** a man is intensely working on his laptop seemingly in a casual office environment with humorous posters on the wall including one depicting a character from a popular show another man is standing and observing the seated man adding a casual and relaxed atmosphere to the workspace\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 14.44 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 26 tokens at 603.78 tokens per second.\n",
      "PTBTokenizer tokenized 135 tokens at 3186.50 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [8.5 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** subject man working on a laptop ** activity ** sitting at a desk using a laptop ** environment ** office setting with a desk chair and posters on the wall ** additional notes ** a man is intensely working on his laptop seemingly in a casual office environment with humorous posters on the wall including one depicting a character from a popular show another man is standing and observing the seated man adding a casual and relaxed atmosphere to the workspace\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.82 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 345.39 tokens per second.\n",
      "PTBTokenizer tokenized 135 tokens at 3207.68 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [8.194 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** subject man working on a laptop ** activity ** sitting at a desk using a laptop ** environment ** office setting with a desk chair and posters on the wall ** additional notes ** a man is intensely working on his laptop seemingly in a casual office environment with humorous posters on the wall including one depicting a character from a popular show another man is standing and observing the seated man adding a casual and relaxed atmosphere to the workspace\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.92 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 338.37 tokens per second.\n",
      "PTBTokenizer tokenized 135 tokens at 3184.58 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [8.93 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** subject man working on a laptop ** activity ** sitting at a desk using a laptop ** environment ** office setting with a desk chair and posters on the wall ** additional notes ** a man is intensely working on his laptop seemingly in a casual office environment with humorous posters on the wall including one depicting a character from a popular show another man is standing and observing the seated man adding a casual and relaxed atmosphere to the workspace\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.78 s\n",
      "📝 Prompt Run 11 | CIDEr: 3.4453 | SPICE: 0.074 | CosSim: 0.4598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 31 tokens at 428.23 tokens per second.\n",
      "PTBTokenizer tokenized 135 tokens at 2993.30 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [8.189 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** subject man working on a laptop ** activity ** sitting at a desk using a laptop ** environment ** office setting with a desk chair and posters on the wall ** additional notes ** a man is intensely working on his laptop seemingly in a casual office environment with humorous posters on the wall including one depicting a character from a popular show another man is standing and observing the seated man adding a casual and relaxed atmosphere to the workspace\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.90 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 24 tokens at 590.84 tokens per second.\n",
      "PTBTokenizer tokenized 135 tokens at 2780.77 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [8.21 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** subject man working on a laptop ** activity ** sitting at a desk using a laptop ** environment ** office setting with a desk chair and posters on the wall ** additional notes ** a man is intensely working on his laptop seemingly in a casual office environment with humorous posters on the wall including one depicting a character from a popular show another man is standing and observing the seated man adding a casual and relaxed atmosphere to the workspace\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.70 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 26 tokens at 626.32 tokens per second.\n",
      "PTBTokenizer tokenized 135 tokens at 2598.50 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [8.447 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** subject man working on a laptop ** activity ** sitting at a desk using a laptop ** environment ** office setting with a desk chair and posters on the wall ** additional notes ** a man is intensely working on his laptop seemingly in a casual office environment with humorous posters on the wall including one depicting a character from a popular show another man is standing and observing the seated man adding a casual and relaxed atmosphere to the workspace\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 14.39 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 400.13 tokens per second.\n",
      "PTBTokenizer tokenized 135 tokens at 3207.90 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [8.220 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** subject man working on a laptop ** activity ** sitting at a desk using a laptop ** environment ** office setting with a desk chair and posters on the wall ** additional notes ** a man is intensely working on his laptop seemingly in a casual office environment with humorous posters on the wall including one depicting a character from a popular show another man is standing and observing the seated man adding a casual and relaxed atmosphere to the workspace\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 14.03 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 312.99 tokens per second.\n",
      "PTBTokenizer tokenized 135 tokens at 2508.70 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [8.29 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** subject man working on a laptop ** activity ** sitting at a desk using a laptop ** environment ** office setting with a desk chair and posters on the wall ** additional notes ** a man is intensely working on his laptop seemingly in a casual office environment with humorous posters on the wall including one depicting a character from a popular show another man is standing and observing the seated man adding a casual and relaxed atmosphere to the workspace\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.81 s\n",
      "📝 Prompt Run 12 | CIDEr: 3.4453 | SPICE: 0.074 | CosSim: 0.4598\n",
      "\n",
      "🔍 Evaluating image ID: 2507 | Ground truths: 5 captions\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 17 tokens at 389.92 tokens per second.\n",
      "PTBTokenizer tokenized 12 tokens at 273.38 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [0.350 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.158 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 311.46 tokens per second.\n",
      "PTBTokenizer tokenized 12 tokens at 219.03 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 731.3 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 226.09 tokens per second.\n",
      "PTBTokenizer tokenized 12 tokens at 276.17 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 739.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 276.57 tokens per second.\n",
      "PTBTokenizer tokenized 12 tokens at 268.21 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 738.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 254.60 tokens per second.\n",
      "PTBTokenizer tokenized 12 tokens at 276.44 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 754.2 ms\n",
      "📝 Prompt Run 1 | CIDEr: 1.7539 | SPICE: 0.1547 | CosSim: 0.3283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 17 tokens at 389.69 tokens per second.\n",
      "PTBTokenizer tokenized 12 tokens at 277.20 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 750.0 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 305.94 tokens per second.\n",
      "PTBTokenizer tokenized 12 tokens at 285.81 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 790.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 200.06 tokens per second.\n",
      "PTBTokenizer tokenized 12 tokens at 289.22 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 734.3 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 222.03 tokens per second.\n",
      "PTBTokenizer tokenized 12 tokens at 277.00 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 769.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 251.69 tokens per second.\n",
      "PTBTokenizer tokenized 12 tokens at 286.07 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 689.7 ms\n",
      "📝 Prompt Run 2 | CIDEr: 1.7539 | SPICE: 0.1547 | CosSim: 0.3283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 17 tokens at 381.12 tokens per second.\n",
      "PTBTokenizer tokenized 71 tokens at 1590.89 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [3.90 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 9.941 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 350.75 tokens per second.\n",
      "PTBTokenizer tokenized 71 tokens at 1708.33 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 707.4 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 264.03 tokens per second.\n",
      "PTBTokenizer tokenized 71 tokens at 1902.63 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 868.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 355.30 tokens per second.\n",
      "PTBTokenizer tokenized 71 tokens at 1838.00 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 728.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 227.74 tokens per second.\n",
      "PTBTokenizer tokenized 71 tokens at 1550.74 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 729.1 ms\n",
      "📝 Prompt Run 3 | CIDEr: 4.3697 | SPICE: 0.0278 | CosSim: 0.1898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 17 tokens at 363.96 tokens per second.\n",
      "PTBTokenizer tokenized 71 tokens at 1753.36 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 796.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 273.93 tokens per second.\n",
      "PTBTokenizer tokenized 71 tokens at 1466.41 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 780.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 263.94 tokens per second.\n",
      "PTBTokenizer tokenized 71 tokens at 1565.27 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 724.4 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 227.06 tokens per second.\n",
      "PTBTokenizer tokenized 71 tokens at 1614.60 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 798.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 259.39 tokens per second.\n",
      "PTBTokenizer tokenized 71 tokens at 1740.53 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 719.6 ms\n",
      "📝 Prompt Run 4 | CIDEr: 4.3697 | SPICE: 0.0278 | CosSim: 0.1898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 17 tokens at 320.07 tokens per second.\n",
      "PTBTokenizer tokenized 10 tokens at 239.97 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [0.329 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.369 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 322.36 tokens per second.\n",
      "PTBTokenizer tokenized 10 tokens at 235.87 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 780.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 262.09 tokens per second.\n",
      "PTBTokenizer tokenized 10 tokens at 77.11 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 712.4 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 278.01 tokens per second.\n",
      "PTBTokenizer tokenized 10 tokens at 241.76 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 745.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 257.41 tokens per second.\n",
      "PTBTokenizer tokenized 10 tokens at 227.29 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 813.0 ms\n",
      "📝 Prompt Run 5 | CIDEr: 0.0 | SPICE: 0.0 | CosSim: 0.1331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 17 tokens at 389.38 tokens per second.\n",
      "PTBTokenizer tokenized 10 tokens at 232.84 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 768.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 336.16 tokens per second.\n",
      "PTBTokenizer tokenized 10 tokens at 237.84 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 772.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 214.60 tokens per second.\n",
      "PTBTokenizer tokenized 10 tokens at 237.27 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 742.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 237.51 tokens per second.\n",
      "PTBTokenizer tokenized 10 tokens at 242.94 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 742.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 207.90 tokens per second.\n",
      "PTBTokenizer tokenized 10 tokens at 231.88 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 764.1 ms\n",
      "📝 Prompt Run 6 | CIDEr: 0.0 | SPICE: 0.0 | CosSim: 0.1331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 17 tokens at 395.36 tokens per second.\n",
      "PTBTokenizer tokenized 148 tokens at 2735.49 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [12.43 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a canine trainer assessing a working dog 's field behavior describe the dog 's posture and role based on the scene the image depicts a small fluffy black and white dog wearing a reflective harness with an orange and green design on its back the harness has reflective strips and a handle on top for leading the dog is standing on patch of grass looking eagerly upward with an object in its mouth appears to be tug toy which is gripping in its jaws the dog 's ears are perked up and its eyes are wide open indicating excitement and focus the scene suggests playful outdoor activity such as a game of fetch or tug-of-war the harness and reflective strips on it suggest that the dog is well-equipped for\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.66 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 346.07 tokens per second.\n",
      "PTBTokenizer tokenized 148 tokens at 2723.28 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.6 sec].\n",
      "Threads( StanfordCoreNLP ) [11.339 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a canine trainer assessing a working dog 's field behavior describe the dog 's posture and role based on the scene the image depicts a small fluffy black and white dog wearing a reflective harness with an orange and green design on its back the harness has reflective strips and a handle on top for leading the dog is standing on patch of grass looking eagerly upward with an object in its mouth appears to be tug toy which is gripping in its jaws the dog 's ears are perked up and its eyes are wide open indicating excitement and focus the scene suggests playful outdoor activity such as a game of fetch or tug-of-war the harness and reflective strips on it suggest that the dog is well-equipped for\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.67 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 273.09 tokens per second.\n",
      "PTBTokenizer tokenized 148 tokens at 3045.15 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [11.716 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a canine trainer assessing a working dog 's field behavior describe the dog 's posture and role based on the scene the image depicts a small fluffy black and white dog wearing a reflective harness with an orange and green design on its back the harness has reflective strips and a handle on top for leading the dog is standing on patch of grass looking eagerly upward with an object in its mouth appears to be tug toy which is gripping in its jaws the dog 's ears are perked up and its eyes are wide open indicating excitement and focus the scene suggests playful outdoor activity such as a game of fetch or tug-of-war the harness and reflective strips on it suggest that the dog is well-equipped for\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.20 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 285.80 tokens per second.\n",
      "PTBTokenizer tokenized 148 tokens at 3298.91 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [10.805 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a canine trainer assessing a working dog 's field behavior describe the dog 's posture and role based on the scene the image depicts a small fluffy black and white dog wearing a reflective harness with an orange and green design on its back the harness has reflective strips and a handle on top for leading the dog is standing on patch of grass looking eagerly upward with an object in its mouth appears to be tug toy which is gripping in its jaws the dog 's ears are perked up and its eyes are wide open indicating excitement and focus the scene suggests playful outdoor activity such as a game of fetch or tug-of-war the harness and reflective strips on it suggest that the dog is well-equipped for\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.37 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 203.43 tokens per second.\n",
      "PTBTokenizer tokenized 148 tokens at 4366.94 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [10.966 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a canine trainer assessing a working dog 's field behavior describe the dog 's posture and role based on the scene the image depicts a small fluffy black and white dog wearing a reflective harness with an orange and green design on its back the harness has reflective strips and a handle on top for leading the dog is standing on patch of grass looking eagerly upward with an object in its mouth appears to be tug toy which is gripping in its jaws the dog 's ears are perked up and its eyes are wide open indicating excitement and focus the scene suggests playful outdoor activity such as a game of fetch or tug-of-war the harness and reflective strips on it suggest that the dog is well-equipped for\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.95 s\n",
      "📝 Prompt Run 7 | CIDEr: 4.3762 | SPICE: 0.0843 | CosSim: 0.5652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 17 tokens at 394.41 tokens per second.\n",
      "PTBTokenizer tokenized 148 tokens at 3567.26 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [10.598 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a canine trainer assessing a working dog 's field behavior describe the dog 's posture and role based on the scene the image depicts a small fluffy black and white dog wearing a reflective harness with an orange and green design on its back the harness has reflective strips and a handle on top for leading the dog is standing on patch of grass looking eagerly upward with an object in its mouth appears to be tug toy which is gripping in its jaws the dog 's ears are perked up and its eyes are wide open indicating excitement and focus the scene suggests playful outdoor activity such as a game of fetch or tug-of-war the harness and reflective strips on it suggest that the dog is well-equipped for\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.10 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 352.27 tokens per second.\n",
      "PTBTokenizer tokenized 148 tokens at 3197.66 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [10.159 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a canine trainer assessing a working dog 's field behavior describe the dog 's posture and role based on the scene the image depicts a small fluffy black and white dog wearing a reflective harness with an orange and green design on its back the harness has reflective strips and a handle on top for leading the dog is standing on patch of grass looking eagerly upward with an object in its mouth appears to be tug toy which is gripping in its jaws the dog 's ears are perked up and its eyes are wide open indicating excitement and focus the scene suggests playful outdoor activity such as a game of fetch or tug-of-war the harness and reflective strips on it suggest that the dog is well-equipped for\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.05 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 283.44 tokens per second.\n",
      "PTBTokenizer tokenized 148 tokens at 3176.86 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [10.436 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a canine trainer assessing a working dog 's field behavior describe the dog 's posture and role based on the scene the image depicts a small fluffy black and white dog wearing a reflective harness with an orange and green design on its back the harness has reflective strips and a handle on top for leading the dog is standing on patch of grass looking eagerly upward with an object in its mouth appears to be tug toy which is gripping in its jaws the dog 's ears are perked up and its eyes are wide open indicating excitement and focus the scene suggests playful outdoor activity such as a game of fetch or tug-of-war the harness and reflective strips on it suggest that the dog is well-equipped for\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.12 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 239.91 tokens per second.\n",
      "PTBTokenizer tokenized 148 tokens at 3487.46 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.1 sec].\n",
      "Threads( StanfordCoreNLP ) [11.772 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a canine trainer assessing a working dog 's field behavior describe the dog 's posture and role based on the scene the image depicts a small fluffy black and white dog wearing a reflective harness with an orange and green design on its back the harness has reflective strips and a handle on top for leading the dog is standing on patch of grass looking eagerly upward with an object in its mouth appears to be tug toy which is gripping in its jaws the dog 's ears are perked up and its eyes are wide open indicating excitement and focus the scene suggests playful outdoor activity such as a game of fetch or tug-of-war the harness and reflective strips on it suggest that the dog is well-equipped for\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.81 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 276.81 tokens per second.\n",
      "PTBTokenizer tokenized 148 tokens at 3489.56 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [11.808 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a canine trainer assessing a working dog 's field behavior describe the dog 's posture and role based on the scene the image depicts a small fluffy black and white dog wearing a reflective harness with an orange and green design on its back the harness has reflective strips and a handle on top for leading the dog is standing on patch of grass looking eagerly upward with an object in its mouth appears to be tug toy which is gripping in its jaws the dog 's ears are perked up and its eyes are wide open indicating excitement and focus the scene suggests playful outdoor activity such as a game of fetch or tug-of-war the harness and reflective strips on it suggest that the dog is well-equipped for\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.46 s\n",
      "📝 Prompt Run 8 | CIDEr: 4.3762 | SPICE: 0.0843 | CosSim: 0.5652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 17 tokens at 385.37 tokens per second.\n",
      "PTBTokenizer tokenized 135 tokens at 3785.12 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [7.533 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.55 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 236.91 tokens per second.\n",
      "PTBTokenizer tokenized 135 tokens at 2485.42 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 834.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 261.97 tokens per second.\n",
      "PTBTokenizer tokenized 135 tokens at 3252.09 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 844.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 275.06 tokens per second.\n",
      "PTBTokenizer tokenized 135 tokens at 2577.11 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 899.8 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 211.69 tokens per second.\n",
      "PTBTokenizer tokenized 135 tokens at 2884.83 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 746.3 ms\n",
      "📝 Prompt Run 9 | CIDEr: 1.8423 | SPICE: 0.01 | CosSim: 0.2607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 17 tokens at 356.21 tokens per second.\n",
      "PTBTokenizer tokenized 135 tokens at 3152.23 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 758.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 295.28 tokens per second.\n",
      "PTBTokenizer tokenized 135 tokens at 2886.56 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 791.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 256.68 tokens per second.\n",
      "PTBTokenizer tokenized 135 tokens at 3022.18 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 762.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 250.03 tokens per second.\n",
      "PTBTokenizer tokenized 135 tokens at 3209.53 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 850.8 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 216.49 tokens per second.\n",
      "PTBTokenizer tokenized 135 tokens at 2969.12 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 739.9 ms\n",
      "📝 Prompt Run 10 | CIDEr: 1.8423 | SPICE: 0.01 | CosSim: 0.2607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 17 tokens at 389.00 tokens per second.\n",
      "PTBTokenizer tokenized 150 tokens at 2786.07 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.6 sec].\n",
      "Threads( StanfordCoreNLP ) [10.12 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** dog playing with a toy terc ** activity ** tug of war ** environment ** park ** additional notes ** the dog appears to be a border terrier known for their tenacity and agility the toy is a large stick suitable for a strong play the harness the dog is wearing is brightly colored ensuring high visibility during outdoor activities the environment seems to be a natural open space ideal for play the dog 's focused and engaged in the play indicating enjoyment and stimulation\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.67 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 346.77 tokens per second.\n",
      "PTBTokenizer tokenized 150 tokens at 3520.89 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [11.118 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** dog playing with a toy terc ** activity ** tug of war ** environment ** park ** additional notes ** the dog appears to be a border terrier known for their tenacity and agility the toy is a large stick suitable for a strong play the harness the dog is wearing is brightly colored ensuring high visibility during outdoor activities the environment seems to be a natural open space ideal for play the dog 's focused and engaged in the play indicating enjoyment and stimulation\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.94 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 273.70 tokens per second.\n",
      "PTBTokenizer tokenized 150 tokens at 3320.26 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [10.405 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** dog playing with a toy terc ** activity ** tug of war ** environment ** park ** additional notes ** the dog appears to be a border terrier known for their tenacity and agility the toy is a large stick suitable for a strong play the harness the dog is wearing is brightly colored ensuring high visibility during outdoor activities the environment seems to be a natural open space ideal for play the dog 's focused and engaged in the play indicating enjoyment and stimulation\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.17 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 239.76 tokens per second.\n",
      "PTBTokenizer tokenized 150 tokens at 3080.59 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [10.905 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** dog playing with a toy terc ** activity ** tug of war ** environment ** park ** additional notes ** the dog appears to be a border terrier known for their tenacity and agility the toy is a large stick suitable for a strong play the harness the dog is wearing is brightly colored ensuring high visibility during outdoor activities the environment seems to be a natural open space ideal for play the dog 's focused and engaged in the play indicating enjoyment and stimulation\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.72 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 303.96 tokens per second.\n",
      "PTBTokenizer tokenized 150 tokens at 4124.00 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.3 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [10.661 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** dog playing with a toy terc ** activity ** tug of war ** environment ** park ** additional notes ** the dog appears to be a border terrier known for their tenacity and agility the toy is a large stick suitable for a strong play the harness the dog is wearing is brightly colored ensuring high visibility during outdoor activities the environment seems to be a natural open space ideal for play the dog 's focused and engaged in the play indicating enjoyment and stimulation\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.00 s\n",
      "📝 Prompt Run 11 | CIDEr: 2.9872 | SPICE: 0.0649 | CosSim: 0.3912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 17 tokens at 450.02 tokens per second.\n",
      "PTBTokenizer tokenized 150 tokens at 3146.09 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [9.859 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** dog playing with a toy terc ** activity ** tug of war ** environment ** park ** additional notes ** the dog appears to be a border terrier known for their tenacity and agility the toy is a large stick suitable for a strong play the harness the dog is wearing is brightly colored ensuring high visibility during outdoor activities the environment seems to be a natural open space ideal for play the dog 's focused and engaged in the play indicating enjoyment and stimulation\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.54 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 350.79 tokens per second.\n",
      "PTBTokenizer tokenized 150 tokens at 3461.27 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [10.451 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** dog playing with a toy terc ** activity ** tug of war ** environment ** park ** additional notes ** the dog appears to be a border terrier known for their tenacity and agility the toy is a large stick suitable for a strong play the harness the dog is wearing is brightly colored ensuring high visibility during outdoor activities the environment seems to be a natural open space ideal for play the dog 's focused and engaged in the play indicating enjoyment and stimulation\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.12 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 210.68 tokens per second.\n",
      "PTBTokenizer tokenized 150 tokens at 4220.95 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [11.878 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** dog playing with a toy terc ** activity ** tug of war ** environment ** park ** additional notes ** the dog appears to be a border terrier known for their tenacity and agility the toy is a large stick suitable for a strong play the harness the dog is wearing is brightly colored ensuring high visibility during outdoor activities the environment seems to be a natural open space ideal for play the dog 's focused and engaged in the play indicating enjoyment and stimulation\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.72 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 292.52 tokens per second.\n",
      "PTBTokenizer tokenized 150 tokens at 3549.82 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [10.280 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** dog playing with a toy terc ** activity ** tug of war ** environment ** park ** additional notes ** the dog appears to be a border terrier known for their tenacity and agility the toy is a large stick suitable for a strong play the harness the dog is wearing is brightly colored ensuring high visibility during outdoor activities the environment seems to be a natural open space ideal for play the dog 's focused and engaged in the play indicating enjoyment and stimulation\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.97 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 266.63 tokens per second.\n",
      "PTBTokenizer tokenized 150 tokens at 3335.98 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [11.150 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** dog playing with a toy terc ** activity ** tug of war ** environment ** park ** additional notes ** the dog appears to be a border terrier known for their tenacity and agility the toy is a large stick suitable for a strong play the harness the dog is wearing is brightly colored ensuring high visibility during outdoor activities the environment seems to be a natural open space ideal for play the dog 's focused and engaged in the play indicating enjoyment and stimulation\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.11 s\n",
      "📝 Prompt Run 12 | CIDEr: 2.9872 | SPICE: 0.0649 | CosSim: 0.3912\n",
      "\n",
      "🔍 Evaluating image ID: 2508 | Ground truths: 5 captions\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 27 tokens at 634.58 tokens per second.\n",
      "PTBTokenizer tokenized 60 tokens at 1526.48 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [1.668 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 7.076 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 24 tokens at 449.83 tokens per second.\n",
      "PTBTokenizer tokenized 60 tokens at 1383.48 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 754.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 288.78 tokens per second.\n",
      "PTBTokenizer tokenized 60 tokens at 1462.02 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 751.4 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 277.64 tokens per second.\n",
      "PTBTokenizer tokenized 60 tokens at 1422.06 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 755.0 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 191.35 tokens per second.\n",
      "PTBTokenizer tokenized 60 tokens at 1421.97 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 738.3 ms\n",
      "📝 Prompt Run 1 | CIDEr: 2.822 | SPICE: 0.0129 | CosSim: 0.0973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 27 tokens at 653.12 tokens per second.\n",
      "PTBTokenizer tokenized 60 tokens at 1411.71 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 744.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 24 tokens at 561.08 tokens per second.\n",
      "PTBTokenizer tokenized 60 tokens at 1193.92 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 688.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 314.84 tokens per second.\n",
      "PTBTokenizer tokenized 60 tokens at 1126.37 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 730.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 290.57 tokens per second.\n",
      "PTBTokenizer tokenized 60 tokens at 1478.13 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 763.4 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 213.56 tokens per second.\n",
      "PTBTokenizer tokenized 60 tokens at 1440.29 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 751.7 ms\n",
      "📝 Prompt Run 2 | CIDEr: 2.822 | SPICE: 0.0129 | CosSim: 0.0973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 27 tokens at 633.81 tokens per second.\n",
      "PTBTokenizer tokenized 121 tokens at 2757.71 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [6.415 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 12.25 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 24 tokens at 551.61 tokens per second.\n",
      "PTBTokenizer tokenized 121 tokens at 2844.79 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 777.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 304.33 tokens per second.\n",
      "PTBTokenizer tokenized 121 tokens at 3222.99 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 700.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 301.32 tokens per second.\n",
      "PTBTokenizer tokenized 121 tokens at 3426.30 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 813.0 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 213.39 tokens per second.\n",
      "PTBTokenizer tokenized 121 tokens at 2897.65 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 763.4 ms\n",
      "📝 Prompt Run 3 | CIDEr: 2.9575 | SPICE: 0.0 | CosSim: 0.0749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 27 tokens at 752.73 tokens per second.\n",
      "PTBTokenizer tokenized 121 tokens at 2922.52 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 735.4 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 24 tokens at 567.57 tokens per second.\n",
      "PTBTokenizer tokenized 121 tokens at 2801.34 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 750.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 330.78 tokens per second.\n",
      "PTBTokenizer tokenized 121 tokens at 2921.16 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 759.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 272.61 tokens per second.\n",
      "PTBTokenizer tokenized 121 tokens at 2859.96 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 827.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 209.72 tokens per second.\n",
      "PTBTokenizer tokenized 121 tokens at 2706.01 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 736.0 ms\n",
      "📝 Prompt Run 4 | CIDEr: 2.9575 | SPICE: 0.0 | CosSim: 0.0749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 27 tokens at 532.16 tokens per second.\n",
      "PTBTokenizer tokenized 100 tokens at 2474.13 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [4.200 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 10.09 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 24 tokens at 631.20 tokens per second.\n",
      "PTBTokenizer tokenized 100 tokens at 2603.34 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 692.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 359.36 tokens per second.\n",
      "PTBTokenizer tokenized 100 tokens at 2023.39 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 681.0 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 305.68 tokens per second.\n",
      "PTBTokenizer tokenized 100 tokens at 2539.01 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 777.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 185.11 tokens per second.\n",
      "PTBTokenizer tokenized 100 tokens at 2253.71 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 762.4 ms\n",
      "📝 Prompt Run 5 | CIDEr: 3.5265 | SPICE: 0.0438 | CosSim: 0.3042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 27 tokens at 672.69 tokens per second.\n",
      "PTBTokenizer tokenized 100 tokens at 2106.82 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 722.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 24 tokens at 611.02 tokens per second.\n",
      "PTBTokenizer tokenized 100 tokens at 2052.96 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 766.8 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 306.56 tokens per second.\n",
      "PTBTokenizer tokenized 100 tokens at 2525.98 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 730.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 269.65 tokens per second.\n",
      "PTBTokenizer tokenized 100 tokens at 1854.19 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 734.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 172.49 tokens per second.\n",
      "PTBTokenizer tokenized 100 tokens at 2345.57 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 770.8 ms\n",
      "📝 Prompt Run 6 | CIDEr: 3.5265 | SPICE: 0.0438 | CosSim: 0.3042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 27 tokens at 467.44 tokens per second.\n",
      "PTBTokenizer tokenized 139 tokens at 3250.89 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [7.349 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a cultural anthropologist documenting traditional street labor describe what the person is doing and how they are carrying the items.in the image a person is depicted engaging in the traditional street labor specifically they are seen carrying a large bundle strapped to their back using a traditional shoulder pole a form of headwear known as a coolie hat is popular in many parts of a southeast asia the person is dressed in a light colored long-sleeved shirt light-colored pants with a distinctive pattern and flip-flops they are walking on a even paved surface adjacent to a plain light-colored wall the individual is transporting two large woven baskets one in each hand suspended from end of a long\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.39 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 24 tokens at 510.40 tokens per second.\n",
      "PTBTokenizer tokenized 139 tokens at 3190.32 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [7.119 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a cultural anthropologist documenting traditional street labor describe what the person is doing and how they are carrying the items.in the image a person is depicted engaging in the traditional street labor specifically they are seen carrying a large bundle strapped to their back using a traditional shoulder pole a form of headwear known as a coolie hat is popular in many parts of a southeast asia the person is dressed in a light colored long-sleeved shirt light-colored pants with a distinctive pattern and flip-flops they are walking on a even paved surface adjacent to a plain light-colored wall the individual is transporting two large woven baskets one in each hand suspended from end of a long\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.01 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 326.38 tokens per second.\n",
      "PTBTokenizer tokenized 139 tokens at 3108.59 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [6.886 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a cultural anthropologist documenting traditional street labor describe what the person is doing and how they are carrying the items.in the image a person is depicted engaging in the traditional street labor specifically they are seen carrying a large bundle strapped to their back using a traditional shoulder pole a form of headwear known as a coolie hat is popular in many parts of a southeast asia the person is dressed in a light colored long-sleeved shirt light-colored pants with a distinctive pattern and flip-flops they are walking on a even paved surface adjacent to a plain light-colored wall the individual is transporting two large woven baskets one in each hand suspended from end of a long\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 12.75 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 243.29 tokens per second.\n",
      "PTBTokenizer tokenized 139 tokens at 4136.92 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [6.932 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a cultural anthropologist documenting traditional street labor describe what the person is doing and how they are carrying the items.in the image a person is depicted engaging in the traditional street labor specifically they are seen carrying a large bundle strapped to their back using a traditional shoulder pole a form of headwear known as a coolie hat is popular in many parts of a southeast asia the person is dressed in a light colored long-sleeved shirt light-colored pants with a distinctive pattern and flip-flops they are walking on a even paved surface adjacent to a plain light-colored wall the individual is transporting two large woven baskets one in each hand suspended from end of a long\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 12.65 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 218.44 tokens per second.\n",
      "PTBTokenizer tokenized 139 tokens at 3618.10 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [6.990 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a cultural anthropologist documenting traditional street labor describe what the person is doing and how they are carrying the items.in the image a person is depicted engaging in the traditional street labor specifically they are seen carrying a large bundle strapped to their back using a traditional shoulder pole a form of headwear known as a coolie hat is popular in many parts of a southeast asia the person is dressed in a light colored long-sleeved shirt light-colored pants with a distinctive pattern and flip-flops they are walking on a even paved surface adjacent to a plain light-colored wall the individual is transporting two large woven baskets one in each hand suspended from end of a long\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 12.72 s\n",
      "📝 Prompt Run 7 | CIDEr: 3.4876 | SPICE: 0.0354 | CosSim: 0.4468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 27 tokens at 756.86 tokens per second.\n",
      "PTBTokenizer tokenized 139 tokens at 3316.77 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [7.80 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a cultural anthropologist documenting traditional street labor describe what the person is doing and how they are carrying the items.in the image a person is depicted engaging in the traditional street labor specifically they are seen carrying a large bundle strapped to their back using a traditional shoulder pole a form of headwear known as a coolie hat is popular in many parts of a southeast asia the person is dressed in a light colored long-sleeved shirt light-colored pants with a distinctive pattern and flip-flops they are walking on a even paved surface adjacent to a plain light-colored wall the individual is transporting two large woven baskets one in each hand suspended from end of a long\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 12.99 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 24 tokens at 510.04 tokens per second.\n",
      "PTBTokenizer tokenized 139 tokens at 2396.49 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [7.49 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a cultural anthropologist documenting traditional street labor describe what the person is doing and how they are carrying the items.in the image a person is depicted engaging in the traditional street labor specifically they are seen carrying a large bundle strapped to their back using a traditional shoulder pole a form of headwear known as a coolie hat is popular in many parts of a southeast asia the person is dressed in a light colored long-sleeved shirt light-colored pants with a distinctive pattern and flip-flops they are walking on a even paved surface adjacent to a plain light-colored wall the individual is transporting two large woven baskets one in each hand suspended from end of a long\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 12.89 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 298.87 tokens per second.\n",
      "PTBTokenizer tokenized 139 tokens at 3061.23 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [7.390 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a cultural anthropologist documenting traditional street labor describe what the person is doing and how they are carrying the items.in the image a person is depicted engaging in the traditional street labor specifically they are seen carrying a large bundle strapped to their back using a traditional shoulder pole a form of headwear known as a coolie hat is popular in many parts of a southeast asia the person is dressed in a light colored long-sleeved shirt light-colored pants with a distinctive pattern and flip-flops they are walking on a even paved surface adjacent to a plain light-colored wall the individual is transporting two large woven baskets one in each hand suspended from end of a long\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.13 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 220.25 tokens per second.\n",
      "PTBTokenizer tokenized 139 tokens at 3292.85 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.3 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [7.678 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a cultural anthropologist documenting traditional street labor describe what the person is doing and how they are carrying the items.in the image a person is depicted engaging in the traditional street labor specifically they are seen carrying a large bundle strapped to their back using a traditional shoulder pole a form of headwear known as a coolie hat is popular in many parts of a southeast asia the person is dressed in a light colored long-sleeved shirt light-colored pants with a distinctive pattern and flip-flops they are walking on a even paved surface adjacent to a plain light-colored wall the individual is transporting two large woven baskets one in each hand suspended from end of a long\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.03 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 169.62 tokens per second.\n",
      "PTBTokenizer tokenized 139 tokens at 3351.82 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.4 sec].\n",
      "Threads( StanfordCoreNLP ) [6.943 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a cultural anthropologist documenting traditional street labor describe what the person is doing and how they are carrying the items.in the image a person is depicted engaging in the traditional street labor specifically they are seen carrying a large bundle strapped to their back using a traditional shoulder pole a form of headwear known as a coolie hat is popular in many parts of a southeast asia the person is dressed in a light colored long-sleeved shirt light-colored pants with a distinctive pattern and flip-flops they are walking on a even paved surface adjacent to a plain light-colored wall the individual is transporting two large woven baskets one in each hand suspended from end of a long\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 12.15 s\n",
      "📝 Prompt Run 8 | CIDEr: 3.4876 | SPICE: 0.0354 | CosSim: 0.4468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 27 tokens at 520.23 tokens per second.\n",
      "PTBTokenizer tokenized 129 tokens at 3063.67 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [4.870 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 10.72 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 24 tokens at 543.24 tokens per second.\n",
      "PTBTokenizer tokenized 129 tokens at 2265.19 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 785.3 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 324.88 tokens per second.\n",
      "PTBTokenizer tokenized 129 tokens at 3069.02 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 785.8 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 254.31 tokens per second.\n",
      "PTBTokenizer tokenized 129 tokens at 2507.47 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 813.0 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 193.42 tokens per second.\n",
      "PTBTokenizer tokenized 129 tokens at 2711.40 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 795.9 ms\n",
      "📝 Prompt Run 9 | CIDEr: 2.5518 | SPICE: 0.0138 | CosSim: 0.2313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 27 tokens at 590.44 tokens per second.\n",
      "PTBTokenizer tokenized 129 tokens at 3000.79 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 751.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 24 tokens at 545.45 tokens per second.\n",
      "PTBTokenizer tokenized 129 tokens at 3065.23 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 795.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 305.77 tokens per second.\n",
      "PTBTokenizer tokenized 129 tokens at 3070.16 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 731.0 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 259.87 tokens per second.\n",
      "PTBTokenizer tokenized 129 tokens at 2975.84 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 778.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 198.17 tokens per second.\n",
      "PTBTokenizer tokenized 129 tokens at 2919.11 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 738.6 ms\n",
      "📝 Prompt Run 10 | CIDEr: 2.5518 | SPICE: 0.0138 | CosSim: 0.2313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 27 tokens at 614.49 tokens per second.\n",
      "PTBTokenizer tokenized 158 tokens at 2834.28 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [12.95 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** subject playful and whimsical playtime scene ** activity ** a child is playfully balancing a basket scale with a conical hat and bags ** environment ** a sunny and bright with a plain white wall and ground backdrop ** additional notes ** the child seems to be enjoying the play wearing mismatched outfit with a conical hat and the scale is creatively used as a toy here are the details in the specified format ** subject ** playful playtime scene ** activity ** a child is playfully balancing a basket scale with a conical hat and bags ** environment ** a sunny\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.72 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 24 tokens at 554.30 tokens per second.\n",
      "PTBTokenizer tokenized 158 tokens at 3100.32 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [12.681 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** subject playful and whimsical playtime scene ** activity ** a child is playfully balancing a basket scale with a conical hat and bags ** environment ** a sunny and bright with a plain white wall and ground backdrop ** additional notes ** the child seems to be enjoying the play wearing mismatched outfit with a conical hat and the scale is creatively used as a toy here are the details in the specified format ** subject ** playful playtime scene ** activity ** a child is playfully balancing a basket scale with a conical hat and bags ** environment ** a sunny\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 18.55 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 328.52 tokens per second.\n",
      "PTBTokenizer tokenized 158 tokens at 3659.29 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [12.381 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** subject playful and whimsical playtime scene ** activity ** a child is playfully balancing a basket scale with a conical hat and bags ** environment ** a sunny and bright with a plain white wall and ground backdrop ** additional notes ** the child seems to be enjoying the play wearing mismatched outfit with a conical hat and the scale is creatively used as a toy here are the details in the specified format ** subject ** playful playtime scene ** activity ** a child is playfully balancing a basket scale with a conical hat and bags ** environment ** a sunny\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 18.15 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 282.30 tokens per second.\n",
      "PTBTokenizer tokenized 158 tokens at 3535.36 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [13.318 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** subject playful and whimsical playtime scene ** activity ** a child is playfully balancing a basket scale with a conical hat and bags ** environment ** a sunny and bright with a plain white wall and ground backdrop ** additional notes ** the child seems to be enjoying the play wearing mismatched outfit with a conical hat and the scale is creatively used as a toy here are the details in the specified format ** subject ** playful playtime scene ** activity ** a child is playfully balancing a basket scale with a conical hat and bags ** environment ** a sunny\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 19.04 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 215.84 tokens per second.\n",
      "PTBTokenizer tokenized 158 tokens at 3800.13 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.3 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [13.623 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** subject playful and whimsical playtime scene ** activity ** a child is playfully balancing a basket scale with a conical hat and bags ** environment ** a sunny and bright with a plain white wall and ground backdrop ** additional notes ** the child seems to be enjoying the play wearing mismatched outfit with a conical hat and the scale is creatively used as a toy here are the details in the specified format ** subject ** playful playtime scene ** activity ** a child is playfully balancing a basket scale with a conical hat and bags ** environment ** a sunny\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 19.19 s\n",
      "📝 Prompt Run 11 | CIDEr: 2.9088 | SPICE: 0.0269 | CosSim: 0.1443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 27 tokens at 471.41 tokens per second.\n",
      "PTBTokenizer tokenized 158 tokens at 2984.32 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [12.555 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** subject playful and whimsical playtime scene ** activity ** a child is playfully balancing a basket scale with a conical hat and bags ** environment ** a sunny and bright with a plain white wall and ground backdrop ** additional notes ** the child seems to be enjoying the play wearing mismatched outfit with a conical hat and the scale is creatively used as a toy here are the details in the specified format ** subject ** playful playtime scene ** activity ** a child is playfully balancing a basket scale with a conical hat and bags ** environment ** a sunny\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 18.18 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 24 tokens at 455.20 tokens per second.\n",
      "PTBTokenizer tokenized 158 tokens at 3407.01 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [12.968 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** subject playful and whimsical playtime scene ** activity ** a child is playfully balancing a basket scale with a conical hat and bags ** environment ** a sunny and bright with a plain white wall and ground backdrop ** additional notes ** the child seems to be enjoying the play wearing mismatched outfit with a conical hat and the scale is creatively used as a toy here are the details in the specified format ** subject ** playful playtime scene ** activity ** a child is playfully balancing a basket scale with a conical hat and bags ** environment ** a sunny\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 18.74 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 335.08 tokens per second.\n",
      "PTBTokenizer tokenized 158 tokens at 3763.93 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.3 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [12.447 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** subject playful and whimsical playtime scene ** activity ** a child is playfully balancing a basket scale with a conical hat and bags ** environment ** a sunny and bright with a plain white wall and ground backdrop ** additional notes ** the child seems to be enjoying the play wearing mismatched outfit with a conical hat and the scale is creatively used as a toy here are the details in the specified format ** subject ** playful playtime scene ** activity ** a child is playfully balancing a basket scale with a conical hat and bags ** environment ** a sunny\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.86 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 283.09 tokens per second.\n",
      "PTBTokenizer tokenized 158 tokens at 3692.97 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [12.541 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** subject playful and whimsical playtime scene ** activity ** a child is playfully balancing a basket scale with a conical hat and bags ** environment ** a sunny and bright with a plain white wall and ground backdrop ** additional notes ** the child seems to be enjoying the play wearing mismatched outfit with a conical hat and the scale is creatively used as a toy here are the details in the specified format ** subject ** playful playtime scene ** activity ** a child is playfully balancing a basket scale with a conical hat and bags ** environment ** a sunny\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 18.31 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 193.83 tokens per second.\n",
      "PTBTokenizer tokenized 158 tokens at 3723.92 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [13.36 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** subject playful and whimsical playtime scene ** activity ** a child is playfully balancing a basket scale with a conical hat and bags ** environment ** a sunny and bright with a plain white wall and ground backdrop ** additional notes ** the child seems to be enjoying the play wearing mismatched outfit with a conical hat and the scale is creatively used as a toy here are the details in the specified format ** subject ** playful playtime scene ** activity ** a child is playfully balancing a basket scale with a conical hat and bags ** environment ** a sunny\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 18.49 s\n",
      "📝 Prompt Run 12 | CIDEr: 2.9088 | SPICE: 0.0269 | CosSim: 0.1443\n",
      "\n",
      "🔍 Evaluating image ID: 2509 | Ground truths: 5 captions\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 19 tokens at 473.60 tokens per second.\n",
      "PTBTokenizer tokenized 47 tokens at 1026.72 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [1.155 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 7.010 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 430.88 tokens per second.\n",
      "PTBTokenizer tokenized 47 tokens at 1097.92 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 782.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 17 tokens at 397.23 tokens per second.\n",
      "PTBTokenizer tokenized 47 tokens at 1090.25 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 770.8 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 334.92 tokens per second.\n",
      "PTBTokenizer tokenized 47 tokens at 990.42 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 743.0 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 310.01 tokens per second.\n",
      "PTBTokenizer tokenized 47 tokens at 1239.11 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 699.1 ms\n",
      "📝 Prompt Run 1 | CIDEr: 3.6187 | SPICE: 0.0758 | CosSim: 0.2805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 19 tokens at 432.97 tokens per second.\n",
      "PTBTokenizer tokenized 47 tokens at 1192.76 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 707.3 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 464.61 tokens per second.\n",
      "PTBTokenizer tokenized 47 tokens at 1040.74 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 738.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 17 tokens at 364.95 tokens per second.\n",
      "PTBTokenizer tokenized 47 tokens at 953.79 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 686.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 311.50 tokens per second.\n",
      "PTBTokenizer tokenized 47 tokens at 1094.64 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 754.8 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 262.52 tokens per second.\n",
      "PTBTokenizer tokenized 47 tokens at 892.29 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 625.3 ms\n",
      "📝 Prompt Run 2 | CIDEr: 3.6187 | SPICE: 0.0758 | CosSim: 0.2805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 19 tokens at 466.27 tokens per second.\n",
      "PTBTokenizer tokenized 27 tokens at 773.60 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.3 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [0.736 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 5.836 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 481.52 tokens per second.\n",
      "PTBTokenizer tokenized 27 tokens at 701.25 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 626.3 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 17 tokens at 377.38 tokens per second.\n",
      "PTBTokenizer tokenized 27 tokens at 720.23 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 711.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 285.02 tokens per second.\n",
      "PTBTokenizer tokenized 27 tokens at 601.17 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 699.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 283.13 tokens per second.\n",
      "PTBTokenizer tokenized 27 tokens at 693.84 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 678.9 ms\n",
      "📝 Prompt Run 3 | CIDEr: 2.1254 | SPICE: 0.0584 | CosSim: 0.1856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 19 tokens at 488.12 tokens per second.\n",
      "PTBTokenizer tokenized 27 tokens at 562.59 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 679.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 421.06 tokens per second.\n",
      "PTBTokenizer tokenized 27 tokens at 694.61 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 712.0 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 17 tokens at 444.40 tokens per second.\n",
      "PTBTokenizer tokenized 27 tokens at 635.86 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 696.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 359.84 tokens per second.\n",
      "PTBTokenizer tokenized 27 tokens at 581.47 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 676.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 242.40 tokens per second.\n",
      "PTBTokenizer tokenized 27 tokens at 594.73 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 703.4 ms\n",
      "📝 Prompt Run 4 | CIDEr: 2.1254 | SPICE: 0.0584 | CosSim: 0.1856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 19 tokens at 425.39 tokens per second.\n",
      "PTBTokenizer tokenized 16 tokens at 417.92 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [0.481 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.383 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 412.73 tokens per second.\n",
      "PTBTokenizer tokenized 16 tokens at 339.37 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 684.4 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 17 tokens at 377.76 tokens per second.\n",
      "PTBTokenizer tokenized 16 tokens at 426.73 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 699.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 301.04 tokens per second.\n",
      "PTBTokenizer tokenized 16 tokens at 406.98 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 704.4 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 232.88 tokens per second.\n",
      "PTBTokenizer tokenized 16 tokens at 390.95 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 676.9 ms\n",
      "📝 Prompt Run 5 | CIDEr: 1.72 | SPICE: 0.1521 | CosSim: 0.2722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 19 tokens at 386.98 tokens per second.\n",
      "PTBTokenizer tokenized 16 tokens at 432.60 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 714.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 432.56 tokens per second.\n",
      "PTBTokenizer tokenized 16 tokens at 416.12 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 712.3 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 17 tokens at 404.24 tokens per second.\n",
      "PTBTokenizer tokenized 16 tokens at 333.20 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 733.4 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 267.28 tokens per second.\n",
      "PTBTokenizer tokenized 16 tokens at 396.40 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 740.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 313.10 tokens per second.\n",
      "PTBTokenizer tokenized 16 tokens at 394.81 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 718.3 ms\n",
      "📝 Prompt Run 6 | CIDEr: 1.72 | SPICE: 0.1521 | CosSim: 0.2722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 19 tokens at 500.54 tokens per second.\n",
      "PTBTokenizer tokenized 145 tokens at 3731.57 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [10.439 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a museum docent giving a tour describe the activity of the woman in the context of the art gallery.as a woman in the art gallery a young woman is standing in the gif you aready to the latter the latter and the a the better to the v a the latter only other the seem to the more the woman is the in the and to the of a the large and the of the and is the in the of the and the of the and the and the and the and the and the and the and the and the and the of the my the and the of the and the of the and the of the more the of the more the and the and the and the and the of\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.22 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 428.31 tokens per second.\n",
      "PTBTokenizer tokenized 145 tokens at 2908.51 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [10.286 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a museum docent giving a tour describe the activity of the woman in the context of the art gallery.as a woman in the art gallery a young woman is standing in the gif you aready to the latter the latter and the a the better to the v a the latter only other the seem to the more the woman is the in the and to the of a the large and the of the and is the in the of the and the of the and the and the and the and the and the and the and the and the and the of the my the and the of the and the of the and the of the more the of the more the and the and the and the and the of\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.15 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 17 tokens at 426.40 tokens per second.\n",
      "PTBTokenizer tokenized 145 tokens at 3442.66 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [10.343 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a museum docent giving a tour describe the activity of the woman in the context of the art gallery.as a woman in the art gallery a young woman is standing in the gif you aready to the latter the latter and the a the better to the v a the latter only other the seem to the more the woman is the in the and to the of a the large and the of the and is the in the of the and the of the and the and the and the and the and the and the and the and the and the of the my the and the of the and the of the and the of the more the of the more the and the and the and the and the of\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.28 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 312.28 tokens per second.\n",
      "PTBTokenizer tokenized 145 tokens at 3629.32 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [12.559 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a museum docent giving a tour describe the activity of the woman in the context of the art gallery.as a woman in the art gallery a young woman is standing in the gif you aready to the latter the latter and the a the better to the v a the latter only other the seem to the more the woman is the in the and to the of a the large and the of the and is the in the of the and the of the and the and the and the and the and the and the and the and the and the of the my the and the of the and the of the and the of the more the of the more the and the and the and the and the of\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.93 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 281.85 tokens per second.\n",
      "PTBTokenizer tokenized 145 tokens at 3238.93 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [11.349 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a museum docent giving a tour describe the activity of the woman in the context of the art gallery.as a woman in the art gallery a young woman is standing in the gif you aready to the latter the latter and the a the better to the v a the latter only other the seem to the more the woman is the in the and to the of a the large and the of the and is the in the of the and the of the and the and the and the and the and the and the and the and the and the of the my the and the of the and the of the and the of the more the of the more the and the and the and the and the of\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.07 s\n",
      "📝 Prompt Run 7 | CIDEr: 3.4029 | SPICE: 0.0406 | CosSim: 0.2351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 19 tokens at 500.81 tokens per second.\n",
      "PTBTokenizer tokenized 145 tokens at 3908.51 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [9.781 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a museum docent giving a tour describe the activity of the woman in the context of the art gallery.as a woman in the art gallery a young woman is standing in the gif you aready to the latter the latter and the a the better to the v a the latter only other the seem to the more the woman is the in the and to the of a the large and the of the and is the in the of the and the of the and the and the and the and the and the and the and the and the and the of the my the and the of the and the of the and the of the more the of the more the and the and the and the and the of\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.21 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 465.60 tokens per second.\n",
      "PTBTokenizer tokenized 145 tokens at 3279.53 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [10.386 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a museum docent giving a tour describe the activity of the woman in the context of the art gallery.as a woman in the art gallery a young woman is standing in the gif you aready to the latter the latter and the a the better to the v a the latter only other the seem to the more the woman is the in the and to the of a the large and the of the and is the in the of the and the of the and the and the and the and the and the and the and the and the and the of the my the and the of the and the of the and the of the more the of the more the and the and the and the and the of\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.08 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 17 tokens at 364.77 tokens per second.\n",
      "PTBTokenizer tokenized 145 tokens at 3756.95 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [10.816 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a museum docent giving a tour describe the activity of the woman in the context of the art gallery.as a woman in the art gallery a young woman is standing in the gif you aready to the latter the latter and the a the better to the v a the latter only other the seem to the more the woman is the in the and to the of a the large and the of the and is the in the of the and the of the and the and the and the and the and the and the and the and the and the of the my the and the of the and the of the and the of the more the of the more the and the and the and the and the of\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.70 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 244.93 tokens per second.\n",
      "PTBTokenizer tokenized 145 tokens at 3631.36 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [11.120 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a museum docent giving a tour describe the activity of the woman in the context of the art gallery.as a woman in the art gallery a young woman is standing in the gif you aready to the latter the latter and the a the better to the v a the latter only other the seem to the more the woman is the in the and to the of a the large and the of the and is the in the of the and the of the and the and the and the and the and the and the and the and the and the of the my the and the of the and the of the and the of the more the of the more the and the and the and the and the of\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.56 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 289.01 tokens per second.\n",
      "PTBTokenizer tokenized 145 tokens at 3500.83 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [10.424 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a museum docent giving a tour describe the activity of the woman in the context of the art gallery.as a woman in the art gallery a young woman is standing in the gif you aready to the latter the latter and the a the better to the v a the latter only other the seem to the more the woman is the in the and to the of a the large and the of the and is the in the of the and the of the and the and the and the and the and the and the and the and the and the of the my the and the of the and the of the and the of the more the of the more the and the and the and the and the of\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.28 s\n",
      "📝 Prompt Run 8 | CIDEr: 3.4029 | SPICE: 0.0406 | CosSim: 0.2351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 19 tokens at 448.49 tokens per second.\n",
      "PTBTokenizer tokenized 128 tokens at 3250.64 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [4.618 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 10.08 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 415.07 tokens per second.\n",
      "PTBTokenizer tokenized 128 tokens at 2200.02 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 789.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 17 tokens at 382.66 tokens per second.\n",
      "PTBTokenizer tokenized 128 tokens at 3028.93 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 1.015 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 326.99 tokens per second.\n",
      "PTBTokenizer tokenized 128 tokens at 2661.38 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 786.4 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 286.09 tokens per second.\n",
      "PTBTokenizer tokenized 128 tokens at 2897.95 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 847.1 ms\n",
      "📝 Prompt Run 9 | CIDEr: 0.7535 | SPICE: 0.0232 | CosSim: 0.299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 19 tokens at 438.84 tokens per second.\n",
      "PTBTokenizer tokenized 128 tokens at 2893.29 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 830.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 393.03 tokens per second.\n",
      "PTBTokenizer tokenized 128 tokens at 2958.93 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 890.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 17 tokens at 387.26 tokens per second.\n",
      "PTBTokenizer tokenized 128 tokens at 2194.75 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 768.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 257.12 tokens per second.\n",
      "PTBTokenizer tokenized 128 tokens at 2850.61 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 767.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 246.92 tokens per second.\n",
      "PTBTokenizer tokenized 128 tokens at 2995.73 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 766.3 ms\n",
      "📝 Prompt Run 10 | CIDEr: 0.7535 | SPICE: 0.0232 | CosSim: 0.299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 19 tokens at 442.32 tokens per second.\n",
      "PTBTokenizer tokenized 159 tokens at 3457.44 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [10.82 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** terc?subject museum visit art museum indoors the person is indoors inside a museum admiring famous paintings additional notes the person is holding a clipboard and examining the artwork closely examining a painting in a museum the person is in a museum observing art observing a painting in a gallery the person is in an art museum looking at a painting in a gallery the person is in a museum viewing art the person is in an art gallery gazing at a painting the person is in a national museum viewing art the person is in an art\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.92 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 412.14 tokens per second.\n",
      "PTBTokenizer tokenized 159 tokens at 3774.50 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [10.677 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** terc?subject museum visit art museum indoors the person is indoors inside a museum admiring famous paintings additional notes the person is holding a clipboard and examining the artwork closely examining a painting in a museum the person is in a museum observing art observing a painting in a gallery the person is in an art museum looking at a painting in a gallery the person is in a museum viewing art the person is in an art gallery gazing at a painting the person is in a national museum viewing art the person is in an art\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.41 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 17 tokens at 380.58 tokens per second.\n",
      "PTBTokenizer tokenized 159 tokens at 3775.01 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [10.849 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** terc?subject museum visit art museum indoors the person is indoors inside a museum admiring famous paintings additional notes the person is holding a clipboard and examining the artwork closely examining a painting in a museum the person is in a museum observing art observing a painting in a gallery the person is in an art museum looking at a painting in a gallery the person is in a museum viewing art the person is in an art gallery gazing at a painting the person is in a national museum viewing art the person is in an art\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.29 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 341.99 tokens per second.\n",
      "PTBTokenizer tokenized 159 tokens at 4044.99 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [10.438 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** terc?subject museum visit art museum indoors the person is indoors inside a museum admiring famous paintings additional notes the person is holding a clipboard and examining the artwork closely examining a painting in a museum the person is in a museum observing art observing a painting in a gallery the person is in an art museum looking at a painting in a gallery the person is in a museum viewing art the person is in an art gallery gazing at a painting the person is in a national museum viewing art the person is in an art\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.18 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 317.74 tokens per second.\n",
      "PTBTokenizer tokenized 159 tokens at 3213.10 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [10.579 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** terc?subject museum visit art museum indoors the person is indoors inside a museum admiring famous paintings additional notes the person is holding a clipboard and examining the artwork closely examining a painting in a museum the person is in a museum observing art observing a painting in a gallery the person is in an art museum looking at a painting in a gallery the person is in a museum viewing art the person is in an art gallery gazing at a painting the person is in a national museum viewing art the person is in an art\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.99 s\n",
      "📝 Prompt Run 11 | CIDEr: 3.9204 | SPICE: 0.0389 | CosSim: 0.2195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 19 tokens at 496.31 tokens per second.\n",
      "PTBTokenizer tokenized 159 tokens at 3802.59 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [10.76 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** terc?subject museum visit art museum indoors the person is indoors inside a museum admiring famous paintings additional notes the person is holding a clipboard and examining the artwork closely examining a painting in a museum the person is in a museum observing art observing a painting in a gallery the person is in an art museum looking at a painting in a gallery the person is in a museum viewing art the person is in an art gallery gazing at a painting the person is in a national museum viewing art the person is in an art\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.83 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 425.34 tokens per second.\n",
      "PTBTokenizer tokenized 159 tokens at 3731.99 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [10.303 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** terc?subject museum visit art museum indoors the person is indoors inside a museum admiring famous paintings additional notes the person is holding a clipboard and examining the artwork closely examining a painting in a museum the person is in a museum observing art observing a painting in a gallery the person is in an art museum looking at a painting in a gallery the person is in a museum viewing art the person is in an art gallery gazing at a painting the person is in a national museum viewing art the person is in an art\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.98 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 17 tokens at 402.78 tokens per second.\n",
      "PTBTokenizer tokenized 159 tokens at 3269.27 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [10.198 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** terc?subject museum visit art museum indoors the person is indoors inside a museum admiring famous paintings additional notes the person is holding a clipboard and examining the artwork closely examining a painting in a museum the person is in a museum observing art observing a painting in a gallery the person is in an art museum looking at a painting in a gallery the person is in a museum viewing art the person is in an art gallery gazing at a painting the person is in a national museum viewing art the person is in an art\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.65 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 331.19 tokens per second.\n",
      "PTBTokenizer tokenized 159 tokens at 3893.91 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [10.211 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** terc?subject museum visit art museum indoors the person is indoors inside a museum admiring famous paintings additional notes the person is holding a clipboard and examining the artwork closely examining a painting in a museum the person is in a museum observing art observing a painting in a gallery the person is in an art museum looking at a painting in a gallery the person is in a museum viewing art the person is in an art gallery gazing at a painting the person is in a national museum viewing art the person is in an art\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.95 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 276.29 tokens per second.\n",
      "PTBTokenizer tokenized 159 tokens at 3717.83 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [10.329 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** terc?subject museum visit art museum indoors the person is indoors inside a museum admiring famous paintings additional notes the person is holding a clipboard and examining the artwork closely examining a painting in a museum the person is in a museum observing art observing a painting in a gallery the person is in an art museum looking at a painting in a gallery the person is in a museum viewing art the person is in an art gallery gazing at a painting the person is in a national museum viewing art the person is in an art\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.95 s\n",
      "📝 Prompt Run 12 | CIDEr: 3.9204 | SPICE: 0.0389 | CosSim: 0.2195\n"
     ]
    }
   ],
   "source": [
    "all_metrics_scores = {}\n",
    "\n",
    "for img_id, outputs in all_outputs.items():\n",
    "    row = test_dataset.filter(lambda x: x[\"img_id\"] == str(img_id))\n",
    "    if len(row) == 0:\n",
    "        print(f\"[WARNING] No ground truth found for img_id {img_id}\")\n",
    "        continue\n",
    "\n",
    "    ground_truths = row[0][\"caption\"]  # This is a list of 5 captions\n",
    "    print(f\"\\n🔍 Evaluating image ID: {img_id} | Ground truths: {len(ground_truths)} captions\\n{'-'*80}\")\n",
    "    \n",
    "    scores_for_image = []\n",
    "\n",
    "    for idx, gen_output in enumerate(outputs):  # 12 outputs (6 prompts x 2 runs)\n",
    "        cider_total, spice_total, cos_total = 0.0, 0.0, 0.0\n",
    "\n",
    "        for ref in ground_truths:\n",
    "            metrics = evaluate_all_metrics(ref, gen_output)\n",
    "            cider_total += metrics[\"CIDEr\"]\n",
    "            spice_total += metrics[\"SPICE\"]\n",
    "            cos_total += metrics[\"cosine_similarity\"]\n",
    "\n",
    "        n_refs = len(ground_truths)\n",
    "        avg_metrics = {\n",
    "            \"CIDEr\": round(cider_total / n_refs, 4),\n",
    "            \"SPICE\": round(spice_total / n_refs, 4),\n",
    "            \"cosine_similarity\": round(cos_total / n_refs, 4)\n",
    "        }\n",
    "\n",
    "        print(f\"📝 Prompt Run {idx+1} | CIDEr: {avg_metrics['CIDEr']} | SPICE: {avg_metrics['SPICE']} | CosSim: {avg_metrics['cosine_similarity']}\")\n",
    "        scores_for_image.append(avg_metrics)\n",
    "\n",
    "    all_metrics_scores[img_id] = scores_for_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06bb9241-3a16-469b-849c-eb7d669d0393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📸 Image ID: 2500\n",
      "------------------------------------------------------------\n",
      "                   CIDEr   SPICE  cosine_similarity\n",
      "Prompt 1 (Run 1)  2.8409  0.0174             0.3718\n",
      "Prompt 1 (Run 2)  2.8409  0.0174             0.3718\n",
      "Prompt 2 (Run 1)  3.7694  0.0560             0.0784\n",
      "Prompt 2 (Run 2)  3.7694  0.0560             0.0784\n",
      "Prompt 3 (Run 1)  2.4533  0.0752             0.1246\n",
      "Prompt 3 (Run 2)  2.4533  0.0752             0.1246\n",
      "Prompt 4 (Run 1)  2.6577  0.0234             0.2707\n",
      "Prompt 4 (Run 2)  2.6577  0.0234             0.2707\n",
      "Prompt 5 (Run 1)  2.9260  0.0129             0.2002\n",
      "Prompt 5 (Run 2)  2.9260  0.0129             0.2002\n",
      "Prompt 6 (Run 1)  2.9291  0.0851             0.3421\n",
      "Prompt 6 (Run 2)  2.9291  0.0851             0.3421\n",
      "============================================================\n",
      "\n",
      "📸 Image ID: 2501\n",
      "------------------------------------------------------------\n",
      "                   CIDEr   SPICE  cosine_similarity\n",
      "Prompt 1 (Run 1)  2.5406  0.0000             0.0286\n",
      "Prompt 1 (Run 2)  2.5406  0.0000             0.0286\n",
      "Prompt 2 (Run 1)  3.2000  0.1083             0.1067\n",
      "Prompt 2 (Run 2)  3.2000  0.1083             0.1067\n",
      "Prompt 3 (Run 1)  3.4922  0.1145             0.2026\n",
      "Prompt 3 (Run 2)  3.4922  0.1145             0.2026\n",
      "Prompt 4 (Run 1)  3.9519  0.0740             0.2917\n",
      "Prompt 4 (Run 2)  3.9519  0.0740             0.2917\n",
      "Prompt 5 (Run 1)  2.8526  0.0000             0.0718\n",
      "Prompt 5 (Run 2)  2.8526  0.0000             0.0718\n",
      "Prompt 6 (Run 1)  2.3682  0.0000             0.1259\n",
      "Prompt 6 (Run 2)  2.3682  0.0000             0.1259\n",
      "============================================================\n",
      "\n",
      "📸 Image ID: 2502\n",
      "------------------------------------------------------------\n",
      "                   CIDEr   SPICE  cosine_similarity\n",
      "Prompt 1 (Run 1)  2.4060  0.0571             0.5765\n",
      "Prompt 1 (Run 2)  2.4060  0.0571             0.5765\n",
      "Prompt 2 (Run 1)  2.4427  0.1101             0.3815\n",
      "Prompt 2 (Run 2)  2.4427  0.1101             0.3815\n",
      "Prompt 3 (Run 1)  1.7603  0.0285             0.1596\n",
      "Prompt 3 (Run 2)  1.7603  0.0285             0.1596\n",
      "Prompt 4 (Run 1)  2.3383  0.0223             0.3585\n",
      "Prompt 4 (Run 2)  2.3383  0.0223             0.3585\n",
      "Prompt 5 (Run 1)  3.2044  0.0912             0.5747\n",
      "Prompt 5 (Run 2)  3.2044  0.0912             0.5747\n",
      "Prompt 6 (Run 1)  1.4269  0.0345             0.2545\n",
      "Prompt 6 (Run 2)  1.4269  0.0345             0.2545\n",
      "============================================================\n",
      "\n",
      "📸 Image ID: 2503\n",
      "------------------------------------------------------------\n",
      "                   CIDEr   SPICE  cosine_similarity\n",
      "Prompt 1 (Run 1)  2.7053  0.0000             0.4794\n",
      "Prompt 1 (Run 2)  2.7053  0.0000             0.4794\n",
      "Prompt 2 (Run 1)  2.2122  0.0129             0.4146\n",
      "Prompt 2 (Run 2)  2.2122  0.0129             0.4146\n",
      "Prompt 3 (Run 1)  3.6407  0.0411             0.3351\n",
      "Prompt 3 (Run 2)  3.6407  0.0411             0.3351\n",
      "Prompt 4 (Run 1)  3.6947  0.0489             0.4755\n",
      "Prompt 4 (Run 2)  3.6947  0.0489             0.4755\n",
      "Prompt 5 (Run 1)  3.1566  0.0410             0.3653\n",
      "Prompt 5 (Run 2)  3.1566  0.0410             0.3653\n",
      "Prompt 6 (Run 1)  2.2911  0.0363             0.3590\n",
      "Prompt 6 (Run 2)  2.2911  0.0363             0.3590\n",
      "============================================================\n",
      "\n",
      "📸 Image ID: 2504\n",
      "------------------------------------------------------------\n",
      "                   CIDEr   SPICE  cosine_similarity\n",
      "Prompt 1 (Run 1)  2.1329  0.0000             0.1857\n",
      "Prompt 1 (Run 2)  2.1329  0.0000             0.1857\n",
      "Prompt 2 (Run 1)  1.4719  0.0623             0.0732\n",
      "Prompt 2 (Run 2)  1.4719  0.0623             0.0732\n",
      "Prompt 3 (Run 1)  0.1782  0.0000             0.0846\n",
      "Prompt 3 (Run 2)  0.1782  0.0000             0.0846\n",
      "Prompt 4 (Run 1)  1.4270  0.0000             0.2652\n",
      "Prompt 4 (Run 2)  1.4270  0.0000             0.2652\n",
      "Prompt 5 (Run 1)  3.1842  0.0861             0.4393\n",
      "Prompt 5 (Run 2)  3.1842  0.0861             0.4393\n",
      "Prompt 6 (Run 1)  1.5141  0.0757             0.1810\n",
      "Prompt 6 (Run 2)  1.5141  0.0757             0.1810\n",
      "============================================================\n",
      "\n",
      "📸 Image ID: 2505\n",
      "------------------------------------------------------------\n",
      "                   CIDEr   SPICE  cosine_similarity\n",
      "Prompt 1 (Run 1)  1.1847  0.0707             0.3579\n",
      "Prompt 1 (Run 2)  1.1847  0.0707             0.3579\n",
      "Prompt 2 (Run 1)  1.3378  0.0348             0.2155\n",
      "Prompt 2 (Run 2)  1.3378  0.0348             0.2155\n",
      "Prompt 3 (Run 1)  1.4134  0.0470             0.2959\n",
      "Prompt 3 (Run 2)  1.4134  0.0470             0.2959\n",
      "Prompt 4 (Run 1)  2.3595  0.0149             0.3983\n",
      "Prompt 4 (Run 2)  2.3595  0.0149             0.3983\n",
      "Prompt 5 (Run 1)  3.5081  0.0745             0.3357\n",
      "Prompt 5 (Run 2)  3.5081  0.0745             0.3357\n",
      "Prompt 6 (Run 1)  2.0752  0.0421             0.2835\n",
      "Prompt 6 (Run 2)  2.0752  0.0421             0.2835\n",
      "============================================================\n",
      "\n",
      "📸 Image ID: 2506\n",
      "------------------------------------------------------------\n",
      "                   CIDEr   SPICE  cosine_similarity\n",
      "Prompt 1 (Run 1)  2.6611  0.0224             0.3904\n",
      "Prompt 1 (Run 2)  2.6611  0.0224             0.3904\n",
      "Prompt 2 (Run 1)  2.6322  0.0634             0.3940\n",
      "Prompt 2 (Run 2)  2.6322  0.0634             0.3940\n",
      "Prompt 3 (Run 1)  3.4233  0.1026             0.5301\n",
      "Prompt 3 (Run 2)  3.4233  0.1026             0.5301\n",
      "Prompt 4 (Run 1)  2.5925  0.0221             0.3672\n",
      "Prompt 4 (Run 2)  2.5925  0.0221             0.3672\n",
      "Prompt 5 (Run 1)  3.8803  0.0749             0.3193\n",
      "Prompt 5 (Run 2)  3.8803  0.0749             0.3193\n",
      "Prompt 6 (Run 1)  3.4453  0.0740             0.4598\n",
      "Prompt 6 (Run 2)  3.4453  0.0740             0.4598\n",
      "============================================================\n",
      "\n",
      "📸 Image ID: 2507\n",
      "------------------------------------------------------------\n",
      "                   CIDEr   SPICE  cosine_similarity\n",
      "Prompt 1 (Run 1)  1.7539  0.1547             0.3283\n",
      "Prompt 1 (Run 2)  1.7539  0.1547             0.3283\n",
      "Prompt 2 (Run 1)  4.3697  0.0278             0.1898\n",
      "Prompt 2 (Run 2)  4.3697  0.0278             0.1898\n",
      "Prompt 3 (Run 1)  0.0000  0.0000             0.1331\n",
      "Prompt 3 (Run 2)  0.0000  0.0000             0.1331\n",
      "Prompt 4 (Run 1)  4.3762  0.0843             0.5652\n",
      "Prompt 4 (Run 2)  4.3762  0.0843             0.5652\n",
      "Prompt 5 (Run 1)  1.8423  0.0100             0.2607\n",
      "Prompt 5 (Run 2)  1.8423  0.0100             0.2607\n",
      "Prompt 6 (Run 1)  2.9872  0.0649             0.3912\n",
      "Prompt 6 (Run 2)  2.9872  0.0649             0.3912\n",
      "============================================================\n",
      "\n",
      "📸 Image ID: 2508\n",
      "------------------------------------------------------------\n",
      "                   CIDEr   SPICE  cosine_similarity\n",
      "Prompt 1 (Run 1)  2.8220  0.0129             0.0973\n",
      "Prompt 1 (Run 2)  2.8220  0.0129             0.0973\n",
      "Prompt 2 (Run 1)  2.9575  0.0000             0.0749\n",
      "Prompt 2 (Run 2)  2.9575  0.0000             0.0749\n",
      "Prompt 3 (Run 1)  3.5265  0.0438             0.3042\n",
      "Prompt 3 (Run 2)  3.5265  0.0438             0.3042\n",
      "Prompt 4 (Run 1)  3.4876  0.0354             0.4468\n",
      "Prompt 4 (Run 2)  3.4876  0.0354             0.4468\n",
      "Prompt 5 (Run 1)  2.5518  0.0138             0.2313\n",
      "Prompt 5 (Run 2)  2.5518  0.0138             0.2313\n",
      "Prompt 6 (Run 1)  2.9088  0.0269             0.1443\n",
      "Prompt 6 (Run 2)  2.9088  0.0269             0.1443\n",
      "============================================================\n",
      "\n",
      "📸 Image ID: 2509\n",
      "------------------------------------------------------------\n",
      "                   CIDEr   SPICE  cosine_similarity\n",
      "Prompt 1 (Run 1)  3.6187  0.0758             0.2805\n",
      "Prompt 1 (Run 2)  3.6187  0.0758             0.2805\n",
      "Prompt 2 (Run 1)  2.1254  0.0584             0.1856\n",
      "Prompt 2 (Run 2)  2.1254  0.0584             0.1856\n",
      "Prompt 3 (Run 1)  1.7200  0.1521             0.2722\n",
      "Prompt 3 (Run 2)  1.7200  0.1521             0.2722\n",
      "Prompt 4 (Run 1)  3.4029  0.0406             0.2351\n",
      "Prompt 4 (Run 2)  3.4029  0.0406             0.2351\n",
      "Prompt 5 (Run 1)  0.7535  0.0232             0.2990\n",
      "Prompt 5 (Run 2)  0.7535  0.0232             0.2990\n",
      "Prompt 6 (Run 1)  3.9204  0.0389             0.2195\n",
      "Prompt 6 (Run 2)  3.9204  0.0389             0.2195\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "for img_id, scores in all_metrics_scores.items():\n",
    "    print(f\"\\n📸 Image ID: {img_id}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    df_temp = pd.DataFrame(scores)\n",
    "    prompt_labels = []\n",
    "    for i in range(len(scores)):\n",
    "        prompt_num = (i // 2) + 1  # Prompts 1–6\n",
    "        run_num = (i % 2) + 1      # Run 1 or Run 2\n",
    "        prompt_labels.append(f\"Prompt {prompt_num} (Run {run_num})\")\n",
    "\n",
    "    df_temp.index = prompt_labels\n",
    "    print(df_temp.round(4))\n",
    "    print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4105eb03-b144-401d-8020-6b2e1e714aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log results table\n",
    "table = wandb.Table(columns=[\"img_id\", \"prompt_type\", \"run\", \"image\", \"ground_truth\", \"prediction\"])\n",
    "\n",
    "for img_id in all_outputs:\n",
    "    filename_row = df[df[\"img_id\"].astype(str) == str(img_id)]\n",
    "    if filename_row.empty:\n",
    "        continue\n",
    "\n",
    "    filename = filename_row.iloc[0][\"filename\"]\n",
    "    gt_captions = filename_row.iloc[0][\"caption\"]\n",
    "    image_row = test_dataset.filter(lambda x: x[\"img_id\"] == str(img_id))\n",
    "    if len(image_row) == 0:\n",
    "        continue\n",
    "    image_pil = image_row[0][\"image\"]  # This is already PIL.Image\n",
    "\n",
    "    for prompt_index in range(6):\n",
    "        for run in range(2):\n",
    "            row_idx = prompt_index * 2 + run\n",
    "            prediction = all_outputs[img_id][row_idx] if row_idx < len(all_outputs[img_id]) else \"N/A\"\n",
    "\n",
    "            table.add_data(\n",
    "                str(img_id),\n",
    "                f\"Prompt {prompt_index + 1}\",\n",
    "                f\"Run {run + 1}\",\n",
    "                wandb.Image(image_pil),\n",
    "                gt_captions[0],  # only logging first GT\n",
    "                prediction\n",
    "            )\n",
    "\n",
    "wandb.log({\"Prompting Comparison Results\": table})\n",
    "\n",
    "# Log metrics for each prompt run\n",
    "for img_id, scores in all_metrics_scores.items():\n",
    "    for i, score in enumerate(scores):\n",
    "        wandb.log({\n",
    "            f\"{img_id}/Prompt {i//2 + 1}/Run {i%2 + 1}/CIDEr\": score[\"CIDEr\"],\n",
    "            f\"{img_id}/Prompt {i//2 + 1}/Run {i%2 + 1}/SPICE\": score[\"SPICE\"],\n",
    "            f\"{img_id}/Prompt {i//2 + 1}/Run {i%2 + 1}/Cosine\": score[\"cosine_similarity\"]\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b457f5c9-36a8-4888-84bd-9b14db901a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_prompt_metrics_to_excel(\n",
    "    img_id: str,\n",
    "    model_name: str,\n",
    "    inference_outputs: list,\n",
    "    metrics: list,\n",
    "    inference_times: list,\n",
    "    vram_usages: list,\n",
    "    df: pd.DataFrame,\n",
    "    test_dataset,\n",
    "    output_excel_path: str = \"prompt_tuning_results_flickr_pixtral.xlsx\"\n",
    "):\n",
    "    from openpyxl import Workbook, load_workbook\n",
    "    from openpyxl.drawing.image import Image as ExcelImage\n",
    "    from openpyxl.styles import Alignment\n",
    "    from PIL import Image as PILImage\n",
    "    import os\n",
    "\n",
    "    # Extract from test_dataset using img_id\n",
    "    row = test_dataset.filter(lambda x: x[\"img_id\"] == str(img_id))[0]\n",
    "    filename = row[\"filename\"]\n",
    "    image_path = os.path.join(\"/workspace/data/filtered_dataset\", filename)\n",
    "    original_caption = row[\"caption\"]\n",
    "    original_caption_text = \"\\n\".join(original_caption) if isinstance(original_caption, list) else str(original_caption)\n",
    "\n",
    "    # Load or create Excel file\n",
    "    if os.path.exists(output_excel_path):\n",
    "        wb = load_workbook(output_excel_path)\n",
    "        ws = wb.active\n",
    "    else:\n",
    "        wb = Workbook()\n",
    "        ws = wb.active\n",
    "        ws.title = \"Prompt Evaluation\"\n",
    "        headers = [\n",
    "            \"Model\", \"Image ID\", \"Image\", \"Original Captions\",\n",
    "            \"Prompt\", \"Output\", \"Inference Time (s)\", \"VRAM Used (GB)\",\n",
    "            \"CIDEr\", \"SPICE\", \"Cosine Similarity\"\n",
    "        ]\n",
    "        ws.append(headers)\n",
    "\n",
    "    start_row = ws.max_row + 1\n",
    "\n",
    "    # Write both runs (2x6 = 12 rows)\n",
    "        # Write both runs (2x6 = 12 rows) — run-wise grouping\n",
    "    for run in range(2):  # 0 = Run 1, 1 = Run 2\n",
    "        row_start = start_row + run * 6\n",
    "        for i in range(6):  # Prompt 1–6\n",
    "            idx = i * 2 + run  # FIXED: Correct index mapping\n",
    "            ws.append([\n",
    "                model_name,\n",
    "                img_id,\n",
    "                \"\",\n",
    "                original_caption_text,\n",
    "                f\"Prompt {i+1} (Run {run+1})\",\n",
    "                inference_outputs[idx],\n",
    "                inference_times[idx],\n",
    "                vram_usages[idx],\n",
    "                metrics[idx][\"CIDEr\"],\n",
    "                metrics[idx][\"SPICE\"],\n",
    "                metrics[idx][\"cosine_similarity\"]\n",
    "            ])\n",
    "\n",
    "        # Merge columns A–D separately for each run\n",
    "        for col in [\"A\", \"B\", \"C\", \"D\"]:\n",
    "            ws.merge_cells(f\"{col}{row_start}:{col}{row_start + 5}\")\n",
    "\n",
    "    # Apply formatting\n",
    "    align_top_wrap = Alignment(wrap_text=True, vertical=\"top\")\n",
    "    align_top = Alignment(vertical=\"top\")\n",
    "\n",
    "    for row in range(start_row, start_row + 12):\n",
    "        for col_letter in [\"A\", \"B\", \"C\", \"E\"]:\n",
    "            ws[f\"{col_letter}{row}\"].alignment = align_top\n",
    "        for col_letter in [\"D\", \"F\"]:\n",
    "            ws[f\"{col_letter}{row}\"].alignment = align_top_wrap\n",
    "        ws.row_dimensions[row].height = 120\n",
    "\n",
    "    # Set column widths\n",
    "    ws.column_dimensions[\"D\"].width = 50  # Captions\n",
    "    ws.column_dimensions[\"F\"].width = 50  # Output\n",
    "\n",
    "    # Insert image once (in first run)\n",
    "        # Embed image in first run row\n",
    "    if os.path.exists(image_path):\n",
    "        try:\n",
    "            print(f\"[INFO] Embedding image from path: {image_path}\")\n",
    "            pil_img = PILImage.open(image_path)\n",
    "            pil_img.thumbnail((300, 300))  # Resize for better fit\n",
    "\n",
    "            excel_img = ExcelImage(image_path)\n",
    "            excel_img.width = 150\n",
    "            excel_img.height = 150\n",
    "            excel_img.anchor = f\"C{start_row}\"  # Image embedded in first run row\n",
    "            ws.add_image(excel_img)\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Could not embed image for {img_id}: {e}\")\n",
    "    else:\n",
    "        print(f\"[WARNING] Image path does not exist: {image_path}\")\n",
    "\n",
    "    wb.save(output_excel_path)\n",
    "    print(f\"✅ Logged both runs for image {img_id} to {output_excel_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb947f87-7707-46c5-9edb-946600d699a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Embedding image from path: /workspace/data/filtered_dataset/182169366.jpg\n",
      "✅ Logged both runs for image 2500 to prompt_tuning_results_flickr_pixtral.xlsx\n",
      "[INFO] Embedding image from path: /workspace/data/filtered_dataset/182184279.jpg\n",
      "✅ Logged both runs for image 2501 to prompt_tuning_results_flickr_pixtral.xlsx\n",
      "[INFO] Embedding image from path: /workspace/data/filtered_dataset/182246705.jpg\n",
      "✅ Logged both runs for image 2502 to prompt_tuning_results_flickr_pixtral.xlsx\n",
      "[INFO] Embedding image from path: /workspace/data/filtered_dataset/182396080.jpg\n",
      "✅ Logged both runs for image 2503 to prompt_tuning_results_flickr_pixtral.xlsx\n",
      "[INFO] Embedding image from path: /workspace/data/filtered_dataset/182493240.jpg\n",
      "✅ Logged both runs for image 2504 to prompt_tuning_results_flickr_pixtral.xlsx\n",
      "[INFO] Embedding image from path: /workspace/data/filtered_dataset/182503906.jpg\n",
      "✅ Logged both runs for image 2505 to prompt_tuning_results_flickr_pixtral.xlsx\n",
      "[INFO] Embedding image from path: /workspace/data/filtered_dataset/1827287777.jpg\n",
      "✅ Logged both runs for image 2506 to prompt_tuning_results_flickr_pixtral.xlsx\n",
      "[INFO] Embedding image from path: /workspace/data/filtered_dataset/1827560917.jpg\n",
      "✅ Logged both runs for image 2507 to prompt_tuning_results_flickr_pixtral.xlsx\n",
      "[INFO] Embedding image from path: /workspace/data/filtered_dataset/182825639.jpg\n",
      "✅ Logged both runs for image 2508 to prompt_tuning_results_flickr_pixtral.xlsx\n",
      "[INFO] Embedding image from path: /workspace/data/filtered_dataset/18284727.jpg\n",
      "✅ Logged both runs for image 2509 to prompt_tuning_results_flickr_pixtral.xlsx\n"
     ]
    }
   ],
   "source": [
    "for img_id in all_outputs.keys():\n",
    "    log_prompt_metrics_to_excel(\n",
    "        img_id=img_id,\n",
    "        model_name=model_id,\n",
    "        inference_outputs=all_outputs[img_id],\n",
    "        metrics=all_metrics_scores[img_id],\n",
    "        inference_times=all_times[img_id],\n",
    "        vram_usages=all_vram[img_id],\n",
    "        df=df,\n",
    "        test_dataset=test_dataset,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63bd375-8987-423e-aa9e-6831b8a85844",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
